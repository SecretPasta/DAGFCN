{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SecretPasta/DAGFCN/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-IjW5iWDv5j"
      },
      "source": [
        "# Prerequisites\n",
        "Clean installing pytorch depenedencies for Node2Vec, and doing Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ptX90PqAoPj",
        "outputId": "c35bf4a1-b1a7-49bc-f430-164c2a95d054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-spline-conv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch-scatter torch-sparse torch-cluster torch-spline-conv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkLyGwH5Arus",
        "outputId": "8f390d34-0a1e-4fee-f662-f65f3f5fa242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)  # Should match the version in the installation instructions\n",
        "print(torch.version.cuda)  # Ensure this matches the target version (e.g., '11.8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W497zhfqYLH",
        "outputId": "0120057b-5eb7-4af4-cccb-bd5ca47bae73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m991.6/991.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Required installations for PyTorch Geometric\n",
        "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.5.1+cu121.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2cVZ31UBtpk",
        "outputId": "c9868b40-fd9f-4c3d-e926-60aa81d4bf12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All required libraries are installed and working!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import torch_cluster\n",
        "    import torch_spline_conv\n",
        "    print(\"All required libraries are installed and working!\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8oAkfbaA6xO",
        "outputId": "2cb8d49b-3141-4581-f337-fc17d7a6e43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA version: 12.1\n",
            "PyTorch Geometric is successfully installed!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import Node2Vec\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(\"PyTorch Geometric is successfully installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SBuwTE68qYIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d18e8c-6a10-4745-994d-2e616a13d203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.datasets import CoraFull\n",
        "from torch_geometric.nn import Node2Vec\n",
        "from torch_geometric.utils import to_torch_csr_tensor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(torch.cuda.is_available())  # Should return True\n",
        "print(torch.cuda.get_device_name(0))  # Should display T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lWG090XtqYGb"
      },
      "outputs": [],
      "source": [
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl_CYE9BEEbN"
      },
      "source": [
        "# Datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpHAhR4B2uZc"
      },
      "source": [
        "Loading CoraFull dataset from torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6-9cR6NZdFT",
        "outputId": "436e9033-7476-4af1-f2e2-1ecb5100e118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xfkPghvPqYDy"
      },
      "outputs": [],
      "source": [
        "def load_cora_dataset(save_path=\"/content/drive/My Drive/Dataset/CoraFull_saved.pt\"):\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = CoraFull(root='./data/CoraFull')\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Specify the save path in Google Drive\n",
        "save_path = \"/content/drive/My Drive/Dataset/CoraFull_saved.pt\"\n",
        "\n",
        "# Load and save the dataset\n",
        "#data = load_cora_dataset(save_path=save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAY4sSJe2vwX"
      },
      "source": [
        "Loading Pubmed dataset from torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PgKQIWjiaW6M"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "def load_and_save_pubmed(save_path=\"/content/drive/My Drive/Dataset/Pubmed_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the Pubmed dataset, print its statistics, and save it to Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        save_path (str): The file path to save the dataset in Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded dataset.\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the Pubmed dataset\n",
        "    dataset = Planetoid(root='./data/Pubmed', name='Pubmed')\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Specify the save path in Google Drive\n",
        "save_path = \"/content/drive/My Drive/Dataset/Pubmed_saved.pt\"\n",
        "\n",
        "# Load and save the Pubmed dataset\n",
        "#data = load_and_save_pubmed(save_path=save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading CiteSeer from torch.geometric"
      ],
      "metadata": {
        "id": "mWpWIXPE7BLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_save_citeseer(save_path=\"/content/drive/My Drive/Dataset/CiteSeer_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the Pubmed dataset, print its statistics, and save it to Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        save_path (str): The file path to save the dataset in Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded dataset.\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the Pubmed dataset\n",
        "    dataset = Planetoid(root='./data/CiteSeer', name='CiteSeer')\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Specify the save path in Google Drive\n",
        "save_path = \"/content/drive/My Drive/Dataset/CiteSeer_saved.pt\"\n",
        "\n",
        "# Load and save the Pubmed dataset\n",
        "#data = load_and_save_citeseer(save_path=save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX2M6XGX2-xU",
        "outputId": "83e975ab-f3d1-44c0-e2a5-d196b1ac3ccc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: CiteSeer()\n",
            "Number of nodes: 3327\n",
            "Number of edges: 9104\n",
            "Number of features: 3703\n",
            "Number of classes: 6\n",
            "Dataset size: 0.0461 GB\n",
            "Dataset saved to: /content/drive/My Drive/Dataset/CiteSeer_saved.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThmjywToAB9i"
      },
      "source": [
        "Loading SANP from torch.geometric\n",
        "\n",
        "Available datasets are: ['ego-facebook', 'ego-gplus', 'ego-twitter', 'soc-ca-astroph', 'soc-ca-grqc', 'soc-epinions1', 'soc-livejournal1', 'soc-pokec', 'soc-slashdot0811', 'soc-slashdot0922', 'wiki-vote']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBOj8xHw7yFB",
        "outputId": "8224f096-83fe-42e6-e8e9-0f7a466190fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://snap.stanford.edu/data/ca-AstroPh.txt.gz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: SNAP-soc-ca-astroph(1)\n",
            "Number of nodes: 133280\n",
            "Number of edges: 396160\n",
            "Number of features: N/A\n",
            "Number of classes: 0\n",
            "Dataset size: 0.0059 GB\n",
            "Dataset saved to: /content/drive/My Drive/Dataset/SNAP_saved.pt\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "def load_and_save_snap(save_path=\"/content/drive/My Drive/Dataset/SNAP_saved.pt\", dataset_name=None):\n",
        "    \"\"\"\n",
        "    Load a SNAP dataset, print its statistics, and save it to Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        save_path (str): The file path to save the dataset in Google Drive.\n",
        "        dataset_name (str): The name of the SNAP dataset to load.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded dataset.\n",
        "    \"\"\"\n",
        "    # Check available datasets\n",
        "    available_datasets = SNAPDataset.available_datasets.keys()\n",
        "    if dataset_name is None or dataset_name.lower() not in available_datasets:\n",
        "        print(f\"Invalid or missing dataset name! Available datasets are: {list(available_datasets)}\")\n",
        "        return None\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the SNAP dataset\n",
        "    dataset = SNAPDataset(root='./data/SNAP', name=dataset_name)\n",
        "    data = dataset[0]\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features if 'x' in data else 'N/A'}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes if hasattr(dataset, 'num_classes') else 'N/A'}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "#data = load_and_save_snap(dataset_name=\"soc-ca-astroph\")  # Choose Dataset from the list above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SauxG-2z2zSS"
      },
      "source": [
        "Load the datasets from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yjTE4oo1bXZ_"
      },
      "outputs": [],
      "source": [
        "def load_cora_from_drive(load_path=\"/content/drive/My Drive/Dataset/CoraFull_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the saved Cora dataset from Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        load_path (str): The file path to load the Cora dataset from Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded Cora dataset.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"Cora dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "#data = load_cora_from_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MLhGD16YbXTd"
      },
      "outputs": [],
      "source": [
        "def load_pubmed_from_drive(load_path=\"/content/drive/My Drive/Dataset/Pubmed_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the saved Pubmed dataset from Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        load_path (str): The file path to load the Pubmed dataset from Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded Pubmed dataset.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"Pubmed dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "\n",
        "#data = load_pubmed_from_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_citeseer_from_drive(load_path=\"/content/drive/My Drive/Dataset/CiteSeer_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the saved CiteSeer dataset from Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        load_path (str): The file path to load the CiteSeer dataset from Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded CiteSeer dataset.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"CiteSeer dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "\n",
        "data = load_citeseer_from_drive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gU5Sx2S3Qgq",
        "outputId": "42bd38a0-fac2-4b15-ef18-d2046878b9fb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CiteSeer dataset loaded successfully from /content/drive/My Drive/Dataset/CiteSeer_saved.pt.\n",
            "Number of nodes: 3327\n",
            "Number of edges: 9104\n",
            "Number of features: 3703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-0be661a40b06>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(load_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yOc9J9Ke3184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040ca8aa-293f-419a-ef31-b427d41a0159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SNAP dataset loaded successfully from /content/drive/My Drive/Dataset/SNAP_saved.pt.\n",
            "Number of nodes: 133280\n",
            "Number of edges: 396160\n",
            "Number of features: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-7f29df68b002>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(load_path)\n"
          ]
        }
      ],
      "source": [
        "def load_snap_from_drive(load_path=\"/content/drive/My Drive/Dataset/SNAP_saved.pt\", name=\"CiteSeer\"):\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"SNAP dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "\n",
        "#data = load_snap_from_drive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsUpRlrHERzf"
      },
      "source": [
        "# Node2Vec\n",
        "\n",
        "Passing in the dataset to generate node embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "z1DDkT46CuOv"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 128\n",
        "walk_length = 20\n",
        "context_size = 10\n",
        "walks_per_node=10\n",
        "num_negative_samples=1\n",
        "p=0.5\n",
        "q=0.25\n",
        "sparse=True\n",
        "n2v_lr=0.01 #learning rate\n",
        "n2v_bs=128 #batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJmfZ4OVqYAw",
        "outputId": "db44bb3a-d0a6-4789-ca64-9428950f9265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 7.5066\n",
            "Epoch 2/10, Loss: 5.3555\n",
            "Epoch 3/10, Loss: 4.4240\n",
            "Epoch 4/10, Loss: 3.7596\n",
            "Epoch 5/10, Loss: 3.2028\n",
            "Epoch 6/10, Loss: 2.7561\n",
            "Epoch 7/10, Loss: 2.3884\n",
            "Epoch 8/10, Loss: 2.0904\n",
            "Epoch 9/10, Loss: 1.8456\n",
            "Epoch 10/10, Loss: 1.6499\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Node2Vec for Embedding Initialization\n",
        "node2vec = Node2Vec(\n",
        "    edge_index=data.edge_index,\n",
        "    embedding_dim=embedding_dim,\n",
        "    walk_length=walk_length,\n",
        "    context_size=context_size,\n",
        "    walks_per_node=walks_per_node,\n",
        "    num_negative_samples=num_negative_samples,\n",
        "    p=p, q=q,\n",
        "    sparse=sparse\n",
        ").to(device)\n",
        "\n",
        "node2vec_optimizer = torch.optim.SparseAdam(node2vec.parameters(), lr=n2v_lr)\n",
        "node2vec_loader = node2vec.loader(batch_size=n2v_bs, shuffle=True)\n",
        "\n",
        "def train_node2vec(epochs=10):\n",
        "    node2vec.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for pos_rw, neg_rw in node2vec_loader:\n",
        "            node2vec_optimizer.zero_grad()\n",
        "            loss = node2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "            loss.backward()\n",
        "            node2vec_optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(node2vec_loader):.4f}\")\n",
        "\n",
        "train_node2vec(epochs=10)\n",
        "\n",
        "# Extract embeddings\n",
        "node_embeddings = node2vec().detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4G8jl30E3Qj"
      },
      "source": [
        "# Isolation Forest\n",
        "\n",
        "Passing in the Node Embeddings into the Isolation forest to isolate anamolies within the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v8Au4MYYE_ql"
      },
      "outputs": [],
      "source": [
        "def isolation_forest(node_embeddings, n_estimators=150, contamination=0.2):\n",
        "    \"\"\"\n",
        "    Detect anomalies in node embeddings using Isolation Forest.\n",
        "\n",
        "    Parameters:\n",
        "        node_embeddings (numpy.ndarray): A 2D array where each row represents the embedding of a node.\n",
        "        n_estimators (int): Number of trees in the Isolation Forest. Default is 100.\n",
        "        contamination (float): The proportion of anomalies in the data. Default is 0.1.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            numpy.ndarray: Labels array where 1 indicates an anomaly and 0 indicates normal.\n",
        "            numpy.ndarray: Anomaly mask where True indicates an anomaly and False indicates normal.\n",
        "    \"\"\"\n",
        "    # Initialize the Isolation Forest model\n",
        "    isolation_model = IsolationForest(\n",
        "        n_estimators=n_estimators,\n",
        "        contamination=contamination,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit the model to the node embeddings\n",
        "    isolation_model.fit(node_embeddings)\n",
        "\n",
        "    # Predict anomaly labels: 1 for normal, -1 for anomaly\n",
        "    labels = isolation_model.predict(node_embeddings)\n",
        "\n",
        "    # Create an anomaly mask: True for anomalies, False for normal points\n",
        "    anomaly_mask = labels == -1\n",
        "\n",
        "    # Adjust labels to binary format: -1 (anomaly) -> 1, 1 (normal) -> 0\n",
        "    labels = anomaly_mask.astype(int)\n",
        "\n",
        "    return labels, anomaly_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MHcQkuvFAUC"
      },
      "source": [
        "# GFCN\n",
        "\n",
        "Defining the Graph Fairing Convolutional Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eDn2mcddtxZx"
      },
      "outputs": [],
      "source": [
        "# Step 3: Graph Fairing Convolutional Network (GFCN)\n",
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.FloatTensor(out_features)) if bias else None\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        support = torch.mm(x, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output += self.bias\n",
        "        return output\n",
        "\n",
        "class GFCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "        super(GFCN, self).__init__()\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nhid)\n",
        "        self.gc3 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu(self.gc2(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc3(x, adj)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xo7s8MYFIYRT"
      },
      "outputs": [],
      "source": [
        "def gfcn(data, node_embeddings, anomaly_mask, device='cuda', epochs=150, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Trains a Graph Fairing Convolutional Network (GFCN) on the given data and returns node labels.\n",
        "\n",
        "    Parameters:\n",
        "        data (torch_geometric.data.Data): The graph data containing edge_index and num_nodes.\n",
        "        node_embeddings (numpy.ndarray): Node embeddings as input features.\n",
        "        anomaly_mask (numpy.ndarray): Boolean mask indicating anomalies (True = anomaly).\n",
        "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
        "        epochs (int): Number of training epochs. Default is 100.\n",
        "        train_ratio (float): Ratio of training nodes to total nodes. Default is 0.8.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Predicted labels for all nodes (0 = normal, 1 = anomaly).\n",
        "    \"\"\"\n",
        "    # Convert node_embeddings and anomaly_mask to PyTorch tensors\n",
        "    features = torch.tensor(node_embeddings, dtype=torch.float32, device=device)\n",
        "    labels = torch.tensor(anomaly_mask.astype(int), dtype=torch.long, device=device)\n",
        "\n",
        "    # Convert edge_index to a PyTorch sparse tensor\n",
        "    adj = to_torch_csr_tensor(data.edge_index, size=(data.num_nodes, data.num_nodes)).to(device)\n",
        "\n",
        "    # Train/Test split\n",
        "    num_nodes = data.num_nodes\n",
        "    num_train = int(train_ratio * num_nodes)\n",
        "    idx_train = torch.arange(num_train, device=device)\n",
        "    idx_test = torch.arange(num_train, num_nodes, device=device)\n",
        "\n",
        "    # Define the GFCN model\n",
        "    class GFCN(nn.Module):\n",
        "        def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "            super(GFCN, self).__init__()\n",
        "            self.gc1 = nn.Linear(nfeat, nhid)\n",
        "            self.gc2 = nn.Linear(nhid, nclass)\n",
        "            self.dropout = dropout\n",
        "\n",
        "        def forward(self, x, adj):\n",
        "            x = torch.relu(self.gc1(x))\n",
        "            x = torch.dropout(x, p=self.dropout, train=self.training)\n",
        "            x = self.gc2(x)\n",
        "            return x\n",
        "\n",
        "    # Model and optimizer\n",
        "    gcn = GFCN(nfeat=features.shape[1], nhid=64, nclass=2, dropout=0.5).to(device)\n",
        "    optimizer = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training the model\n",
        "    def train_gfcn(epochs):\n",
        "        gcn.train()\n",
        "        for epoch in range(epochs):\n",
        "            optimizer.zero_grad()\n",
        "            output = gcn(features, adj)\n",
        "            loss = criterion(output[idx_train], labels[idx_train])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_gfcn(epochs)\n",
        "\n",
        "    # Evaluation: Predict labels for all nodes\n",
        "    gcn.eval()\n",
        "    with torch.no_grad():\n",
        "        output = gcn(features, adj)\n",
        "        predictions = torch.argmax(output, dim=1)  # Predicted labels\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OWXMrJK0BH1n"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(data, node_embeddings, true_labels, predicted_labels, iteration):\n",
        "    \"\"\"\n",
        "    Evaluate the model at the end of each iteration.\n",
        "\n",
        "    Parameters:\n",
        "        data (torch_geometric.data.Data): The graph data containing edge_index and num_nodes.\n",
        "        node_embeddings (numpy.ndarray): Current node embeddings.\n",
        "        true_labels (numpy.ndarray): True labels of the nodes (1 for anomaly, 0 for normal).\n",
        "        predicted_labels (numpy.ndarray): Predicted labels from the GFCN (1 for anomaly, 0 for normal).\n",
        "        iteration (int): The current iteration number.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing evaluation metrics.\n",
        "    \"\"\"\n",
        "    print(f\"Evaluating model at iteration {iteration}...\")\n",
        "\n",
        "    # Calculate evaluation metrics manually\n",
        "    true_positives = np.sum((true_labels == 1) & (predicted_labels == 1))\n",
        "    true_negatives = np.sum((true_labels == 0) & (predicted_labels == 0))\n",
        "    false_positives = np.sum((true_labels == 0) & (predicted_labels == 1))\n",
        "    false_negatives = np.sum((true_labels == 1) & (predicted_labels == 0))\n",
        "\n",
        "    accuracy = (true_positives + true_negatives) / len(true_labels)\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    print(f\"Iteration {iteration} - Evaluation Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vX8UBAccBH8x"
      },
      "outputs": [],
      "source": [
        "def remove_nodes(data, node_indices):\n",
        "    \"\"\"\n",
        "    Remove nodes from graph data.\n",
        "\n",
        "    Parameters:\n",
        "        data (torch_geometric.data.Data): The graph data containing edge_index and num_nodes.\n",
        "        node_indices (numpy.ndarray): Indices of nodes to remove.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: Updated graph data with specified nodes removed.\n",
        "    \"\"\"\n",
        "    mask = np.ones(data.num_nodes, dtype=bool)\n",
        "    mask[node_indices[node_indices < data.num_nodes]] = False  # Ensure indices are within bounds\n",
        "\n",
        "    data.x = data.x[mask]\n",
        "\n",
        "    # Filter edges based on the updated node mask\n",
        "    edge_index_cpu = data.edge_index.cpu().numpy()\n",
        "    edge_index_cpu = edge_index_cpu[:, (edge_index_cpu[0] < mask.size) & (edge_index_cpu[1] < mask.size)]  # Ensure edge indices are within bounds\n",
        "    edge_mask = mask[edge_index_cpu[0]] & mask[edge_index_cpu[1]]\n",
        "    data.edge_index = torch.tensor(edge_index_cpu[:, edge_mask], dtype=torch.long, device=data.edge_index.device)\n",
        "\n",
        "    data.num_nodes = mask.sum()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "INIb4MVnKG2m"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def iterative_anomaly_detection(data, node_embeddings, K, device='cuda'):\n",
        "    \"\"\"\n",
        "    Iteratively detect and remove anomalies using Isolation Forest and GFCN.\n",
        "\n",
        "    Parameters:\n",
        "        data (torch_geometric.data.Data): The graph data containing edge_index and num_nodes.\n",
        "        node_embeddings (numpy.ndarray): Initial node embeddings.\n",
        "        K (int): Number of iterations to run the anomaly detection and removal process.\n",
        "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - numpy.ndarray: Node embeddings after K iterations of anomaly detection and removal.\n",
        "            - list: A list of lists, where each inner list contains the indices of nodes removed in that iteration.\n",
        "    \"\"\"\n",
        "    evaluation_scores = []\n",
        "    removed_nodes_per_iteration = []  # Track nodes removed in each iteration\n",
        "\n",
        "    print(f\"Initial Number of Nodes: {data.num_nodes}\")\n",
        "    for iteration in range(K):\n",
        "        # Step 1: Apply Isolation Forest to detect anomalies\n",
        "        labels, anomaly_mask = isolation_forest(node_embeddings, 50, 0.3)\n",
        "        num_anomalies_iforest = np.sum(anomaly_mask)\n",
        "        print(f\"Iteration {iteration + 1}/{K}: {num_anomalies_iforest} anomalies detected by Isolation Forest.\")\n",
        "\n",
        "        # Step 2: Apply GFCN to classify anomalies\n",
        "        predictions = gfcn(data, node_embeddings, anomaly_mask, device=device)\n",
        "        anomaly_indices = np.where(predictions.cpu().numpy() == 1)[0]\n",
        "        num_anomalies_gfcn = len(anomaly_indices)\n",
        "        print(f\"Iteration {iteration + 1}/{K}: {num_anomalies_gfcn} anomalies detected by GFCN.\")\n",
        "\n",
        "        # Step 3: Remove anomalous nodes from the data and embeddings\n",
        "        if num_anomalies_gfcn == 0:\n",
        "            print(\"No anomalies detected by GFCN. Stopping iteration.\")\n",
        "            break\n",
        "\n",
        "        # Update the embeddings and data by removing anomalies\n",
        "        anomaly_indices = anomaly_indices[anomaly_indices < node_embeddings.shape[0]]  # Ensure indices are within bounds\n",
        "        removed_nodes_per_iteration.append(anomaly_indices.tolist())  # Log the removed nodes\n",
        "        node_embeddings = np.delete(node_embeddings, anomaly_indices, axis=0)\n",
        "        data = remove_nodes(data, anomaly_indices)\n",
        "\n",
        "        # Print the updated number of nodes\n",
        "        print(f\"Iteration {iteration + 1}/{K}: Number of Nodes after anomaly removal: {data.num_nodes}\")\n",
        "\n",
        "        # Step 4: Evaluate the model\n",
        "        scores = evaluate_model(data, node_embeddings, labels, predictions.cpu().numpy(), iteration + 1)\n",
        "        evaluation_scores.append(scores)\n",
        "\n",
        "    # Plot the final evaluation scores\n",
        "    iterations = range(1, len(evaluation_scores) + 1)\n",
        "    accuracies = [score[\"accuracy\"] for score in evaluation_scores]\n",
        "    f1_scores = [score[\"f1\"] for score in evaluation_scores]\n",
        "    precisions = [score[\"precision\"] for score in evaluation_scores]\n",
        "    recalls = [score[\"recall\"] for score in evaluation_scores]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(iterations, accuracies, label='Accuracy', marker='o')\n",
        "    plt.plot(iterations, f1_scores, label='F1 Score', marker='o')\n",
        "    plt.plot(iterations, precisions, label='Precision', marker='o')\n",
        "    plt.plot(iterations, recalls, label='Recall', marker='o')\n",
        "\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Evaluation Scores Across Iterations')\n",
        "    plt.xticks(iterations)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print all evaluation scores at the end\n",
        "    print(\"\\nFinal Evaluation Scores:\")\n",
        "    for i, scores in enumerate(evaluation_scores, 1):\n",
        "        print(f\"Iteration {i} - Accuracy: {scores['accuracy']:.4f}, F1 Score: {scores['f1']:.4f}, Precision: {scores['precision']:.4f}, Recall: {scores['recall']:.4f}\")\n",
        "\n",
        "    return node_embeddings, removed_nodes_per_iteration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iwamUqhKKJsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "656dbaaa-86a2-4c6b-abdb-17b066973ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-0be661a40b06>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(load_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CiteSeer dataset loaded successfully from /content/drive/My Drive/Dataset/CiteSeer_saved.pt.\n",
            "Number of nodes: 3327\n",
            "Number of edges: 9104\n",
            "Number of features: 3703\n",
            "Initial Number of Nodes: 3327\n",
            "Iteration 1/10: 998 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7367\n",
            "Epoch 2/150, Loss: 0.6855\n",
            "Epoch 3/150, Loss: 0.6540\n",
            "Epoch 4/150, Loss: 0.6420\n",
            "Epoch 5/150, Loss: 0.6246\n",
            "Epoch 6/150, Loss: 0.6048\n",
            "Epoch 7/150, Loss: 0.5942\n",
            "Epoch 8/150, Loss: 0.5781\n",
            "Epoch 9/150, Loss: 0.5635\n",
            "Epoch 10/150, Loss: 0.5482\n",
            "Epoch 11/150, Loss: 0.5382\n",
            "Epoch 12/150, Loss: 0.5337\n",
            "Epoch 13/150, Loss: 0.5262\n",
            "Epoch 14/150, Loss: 0.5061\n",
            "Epoch 15/150, Loss: 0.4923\n",
            "Epoch 16/150, Loss: 0.4840\n",
            "Epoch 17/150, Loss: 0.4668\n",
            "Epoch 18/150, Loss: 0.4613\n",
            "Epoch 19/150, Loss: 0.4459\n",
            "Epoch 20/150, Loss: 0.4275\n",
            "Epoch 21/150, Loss: 0.4173\n",
            "Epoch 22/150, Loss: 0.3985\n",
            "Epoch 23/150, Loss: 0.3868\n",
            "Epoch 24/150, Loss: 0.3769\n",
            "Epoch 25/150, Loss: 0.3764\n",
            "Epoch 26/150, Loss: 0.3588\n",
            "Epoch 27/150, Loss: 0.3327\n",
            "Epoch 28/150, Loss: 0.3365\n",
            "Epoch 29/150, Loss: 0.3263\n",
            "Epoch 30/150, Loss: 0.3159\n",
            "Epoch 31/150, Loss: 0.3118\n",
            "Epoch 32/150, Loss: 0.2959\n",
            "Epoch 33/150, Loss: 0.2928\n",
            "Epoch 34/150, Loss: 0.2986\n",
            "Epoch 35/150, Loss: 0.2864\n",
            "Epoch 36/150, Loss: 0.2739\n",
            "Epoch 37/150, Loss: 0.2681\n",
            "Epoch 38/150, Loss: 0.2603\n",
            "Epoch 39/150, Loss: 0.2603\n",
            "Epoch 40/150, Loss: 0.2534\n",
            "Epoch 41/150, Loss: 0.2500\n",
            "Epoch 42/150, Loss: 0.2407\n",
            "Epoch 43/150, Loss: 0.2546\n",
            "Epoch 44/150, Loss: 0.2390\n",
            "Epoch 45/150, Loss: 0.2351\n",
            "Epoch 46/150, Loss: 0.2376\n",
            "Epoch 47/150, Loss: 0.2223\n",
            "Epoch 48/150, Loss: 0.2215\n",
            "Epoch 49/150, Loss: 0.2418\n",
            "Epoch 50/150, Loss: 0.2319\n",
            "Epoch 51/150, Loss: 0.2278\n",
            "Epoch 52/150, Loss: 0.2232\n",
            "Epoch 53/150, Loss: 0.2111\n",
            "Epoch 54/150, Loss: 0.2260\n",
            "Epoch 55/150, Loss: 0.2111\n",
            "Epoch 56/150, Loss: 0.2118\n",
            "Epoch 57/150, Loss: 0.1998\n",
            "Epoch 58/150, Loss: 0.2240\n",
            "Epoch 59/150, Loss: 0.2074\n",
            "Epoch 60/150, Loss: 0.2010\n",
            "Epoch 61/150, Loss: 0.2014\n",
            "Epoch 62/150, Loss: 0.1919\n",
            "Epoch 63/150, Loss: 0.2016\n",
            "Epoch 64/150, Loss: 0.1817\n",
            "Epoch 65/150, Loss: 0.1959\n",
            "Epoch 66/150, Loss: 0.1971\n",
            "Epoch 67/150, Loss: 0.1825\n",
            "Epoch 68/150, Loss: 0.1762\n",
            "Epoch 69/150, Loss: 0.1913\n",
            "Epoch 70/150, Loss: 0.1848\n",
            "Epoch 71/150, Loss: 0.1834\n",
            "Epoch 72/150, Loss: 0.1715\n",
            "Epoch 73/150, Loss: 0.1863\n",
            "Epoch 74/150, Loss: 0.1800\n",
            "Epoch 75/150, Loss: 0.1574\n",
            "Epoch 76/150, Loss: 0.1680\n",
            "Epoch 77/150, Loss: 0.1749\n",
            "Epoch 78/150, Loss: 0.1726\n",
            "Epoch 79/150, Loss: 0.1701\n",
            "Epoch 80/150, Loss: 0.1777\n",
            "Epoch 81/150, Loss: 0.1720\n",
            "Epoch 82/150, Loss: 0.1696\n",
            "Epoch 83/150, Loss: 0.1724\n",
            "Epoch 84/150, Loss: 0.1550\n",
            "Epoch 85/150, Loss: 0.1657\n",
            "Epoch 86/150, Loss: 0.1645\n",
            "Epoch 87/150, Loss: 0.1615\n",
            "Epoch 88/150, Loss: 0.1678\n",
            "Epoch 89/150, Loss: 0.1495\n",
            "Epoch 90/150, Loss: 0.1478\n",
            "Epoch 91/150, Loss: 0.1499\n",
            "Epoch 92/150, Loss: 0.1516\n",
            "Epoch 93/150, Loss: 0.1473\n",
            "Epoch 94/150, Loss: 0.1492\n",
            "Epoch 95/150, Loss: 0.1444\n",
            "Epoch 96/150, Loss: 0.1504\n",
            "Epoch 97/150, Loss: 0.1463\n",
            "Epoch 98/150, Loss: 0.1578\n",
            "Epoch 99/150, Loss: 0.1364\n",
            "Epoch 100/150, Loss: 0.1396\n",
            "Epoch 101/150, Loss: 0.1384\n",
            "Epoch 102/150, Loss: 0.1378\n",
            "Epoch 103/150, Loss: 0.1456\n",
            "Epoch 104/150, Loss: 0.1304\n",
            "Epoch 105/150, Loss: 0.1432\n",
            "Epoch 106/150, Loss: 0.1264\n",
            "Epoch 107/150, Loss: 0.1431\n",
            "Epoch 108/150, Loss: 0.1393\n",
            "Epoch 109/150, Loss: 0.1339\n",
            "Epoch 110/150, Loss: 0.1267\n",
            "Epoch 111/150, Loss: 0.1392\n",
            "Epoch 112/150, Loss: 0.1332\n",
            "Epoch 113/150, Loss: 0.1231\n",
            "Epoch 114/150, Loss: 0.1268\n",
            "Epoch 115/150, Loss: 0.1297\n",
            "Epoch 116/150, Loss: 0.1237\n",
            "Epoch 117/150, Loss: 0.1372\n",
            "Epoch 118/150, Loss: 0.1275\n",
            "Epoch 119/150, Loss: 0.1394\n",
            "Epoch 120/150, Loss: 0.1147\n",
            "Epoch 121/150, Loss: 0.1247\n",
            "Epoch 122/150, Loss: 0.1379\n",
            "Epoch 123/150, Loss: 0.1145\n",
            "Epoch 124/150, Loss: 0.1223\n",
            "Epoch 125/150, Loss: 0.1306\n",
            "Epoch 126/150, Loss: 0.1138\n",
            "Epoch 127/150, Loss: 0.1161\n",
            "Epoch 128/150, Loss: 0.1254\n",
            "Epoch 129/150, Loss: 0.1203\n",
            "Epoch 130/150, Loss: 0.1120\n",
            "Epoch 131/150, Loss: 0.1028\n",
            "Epoch 132/150, Loss: 0.1041\n",
            "Epoch 133/150, Loss: 0.1190\n",
            "Epoch 134/150, Loss: 0.1277\n",
            "Epoch 135/150, Loss: 0.1205\n",
            "Epoch 136/150, Loss: 0.1190\n",
            "Epoch 137/150, Loss: 0.1020\n",
            "Epoch 138/150, Loss: 0.1273\n",
            "Epoch 139/150, Loss: 0.1345\n",
            "Epoch 140/150, Loss: 0.1086\n",
            "Epoch 141/150, Loss: 0.1109\n",
            "Epoch 142/150, Loss: 0.1107\n",
            "Epoch 143/150, Loss: 0.1257\n",
            "Epoch 144/150, Loss: 0.1161\n",
            "Epoch 145/150, Loss: 0.1167\n",
            "Epoch 146/150, Loss: 0.1131\n",
            "Epoch 147/150, Loss: 0.1037\n",
            "Epoch 148/150, Loss: 0.1165\n",
            "Epoch 149/150, Loss: 0.1090\n",
            "Epoch 150/150, Loss: 0.1156\n",
            "Iteration 1/10: 1010 anomalies detected by GFCN.\n",
            "Iteration 1/10: Number of Nodes after anomaly removal: 2317\n",
            "Evaluating model at iteration 1...\n",
            "Iteration 1 - Evaluation Metrics:\n",
            "Accuracy: 0.9681\n",
            "F1 Score: 0.9472\n",
            "Precision: 0.9416\n",
            "Recall: 0.9529\n",
            "Iteration 2/10: 695 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7437\n",
            "Epoch 2/150, Loss: 0.6953\n",
            "Epoch 3/150, Loss: 0.6643\n",
            "Epoch 4/150, Loss: 0.6388\n",
            "Epoch 5/150, Loss: 0.6207\n",
            "Epoch 6/150, Loss: 0.6061\n",
            "Epoch 7/150, Loss: 0.5978\n",
            "Epoch 8/150, Loss: 0.5872\n",
            "Epoch 9/150, Loss: 0.5827\n",
            "Epoch 10/150, Loss: 0.5679\n",
            "Epoch 11/150, Loss: 0.5528\n",
            "Epoch 12/150, Loss: 0.5415\n",
            "Epoch 13/150, Loss: 0.5248\n",
            "Epoch 14/150, Loss: 0.5149\n",
            "Epoch 15/150, Loss: 0.5128\n",
            "Epoch 16/150, Loss: 0.5032\n",
            "Epoch 17/150, Loss: 0.4909\n",
            "Epoch 18/150, Loss: 0.4838\n",
            "Epoch 19/150, Loss: 0.4724\n",
            "Epoch 20/150, Loss: 0.4729\n",
            "Epoch 21/150, Loss: 0.4589\n",
            "Epoch 22/150, Loss: 0.4425\n",
            "Epoch 23/150, Loss: 0.4302\n",
            "Epoch 24/150, Loss: 0.4277\n",
            "Epoch 25/150, Loss: 0.4157\n",
            "Epoch 26/150, Loss: 0.4126\n",
            "Epoch 27/150, Loss: 0.3863\n",
            "Epoch 28/150, Loss: 0.3773\n",
            "Epoch 29/150, Loss: 0.3660\n",
            "Epoch 30/150, Loss: 0.3696\n",
            "Epoch 31/150, Loss: 0.3560\n",
            "Epoch 32/150, Loss: 0.3453\n",
            "Epoch 33/150, Loss: 0.3364\n",
            "Epoch 34/150, Loss: 0.3239\n",
            "Epoch 35/150, Loss: 0.3339\n",
            "Epoch 36/150, Loss: 0.3281\n",
            "Epoch 37/150, Loss: 0.2973\n",
            "Epoch 38/150, Loss: 0.2971\n",
            "Epoch 39/150, Loss: 0.2899\n",
            "Epoch 40/150, Loss: 0.2876\n",
            "Epoch 41/150, Loss: 0.2773\n",
            "Epoch 42/150, Loss: 0.2784\n",
            "Epoch 43/150, Loss: 0.2877\n",
            "Epoch 44/150, Loss: 0.2740\n",
            "Epoch 45/150, Loss: 0.2604\n",
            "Epoch 46/150, Loss: 0.2654\n",
            "Epoch 47/150, Loss: 0.2668\n",
            "Epoch 48/150, Loss: 0.2517\n",
            "Epoch 49/150, Loss: 0.2331\n",
            "Epoch 50/150, Loss: 0.2565\n",
            "Epoch 51/150, Loss: 0.2571\n",
            "Epoch 52/150, Loss: 0.2414\n",
            "Epoch 53/150, Loss: 0.2284\n",
            "Epoch 54/150, Loss: 0.2322\n",
            "Epoch 55/150, Loss: 0.2212\n",
            "Epoch 56/150, Loss: 0.2193\n",
            "Epoch 57/150, Loss: 0.2163\n",
            "Epoch 58/150, Loss: 0.2036\n",
            "Epoch 59/150, Loss: 0.2128\n",
            "Epoch 60/150, Loss: 0.2075\n",
            "Epoch 61/150, Loss: 0.2296\n",
            "Epoch 62/150, Loss: 0.2158\n",
            "Epoch 63/150, Loss: 0.2133\n",
            "Epoch 64/150, Loss: 0.2089\n",
            "Epoch 65/150, Loss: 0.2039\n",
            "Epoch 66/150, Loss: 0.1902\n",
            "Epoch 67/150, Loss: 0.1950\n",
            "Epoch 68/150, Loss: 0.1986\n",
            "Epoch 69/150, Loss: 0.2035\n",
            "Epoch 70/150, Loss: 0.1633\n",
            "Epoch 71/150, Loss: 0.2004\n",
            "Epoch 72/150, Loss: 0.1929\n",
            "Epoch 73/150, Loss: 0.1764\n",
            "Epoch 74/150, Loss: 0.1948\n",
            "Epoch 75/150, Loss: 0.1622\n",
            "Epoch 76/150, Loss: 0.1699\n",
            "Epoch 77/150, Loss: 0.1687\n",
            "Epoch 78/150, Loss: 0.1764\n",
            "Epoch 79/150, Loss: 0.1858\n",
            "Epoch 80/150, Loss: 0.1894\n",
            "Epoch 81/150, Loss: 0.1695\n",
            "Epoch 82/150, Loss: 0.1546\n",
            "Epoch 83/150, Loss: 0.1589\n",
            "Epoch 84/150, Loss: 0.1634\n",
            "Epoch 85/150, Loss: 0.1658\n",
            "Epoch 86/150, Loss: 0.1514\n",
            "Epoch 87/150, Loss: 0.1743\n",
            "Epoch 88/150, Loss: 0.1651\n",
            "Epoch 89/150, Loss: 0.1793\n",
            "Epoch 90/150, Loss: 0.1552\n",
            "Epoch 91/150, Loss: 0.1596\n",
            "Epoch 92/150, Loss: 0.1559\n",
            "Epoch 93/150, Loss: 0.1534\n",
            "Epoch 94/150, Loss: 0.1497\n",
            "Epoch 95/150, Loss: 0.1474\n",
            "Epoch 96/150, Loss: 0.1518\n",
            "Epoch 97/150, Loss: 0.1450\n",
            "Epoch 98/150, Loss: 0.1284\n",
            "Epoch 99/150, Loss: 0.1476\n",
            "Epoch 100/150, Loss: 0.1480\n",
            "Epoch 101/150, Loss: 0.1381\n",
            "Epoch 102/150, Loss: 0.1505\n",
            "Epoch 103/150, Loss: 0.1463\n",
            "Epoch 104/150, Loss: 0.1508\n",
            "Epoch 105/150, Loss: 0.1190\n",
            "Epoch 106/150, Loss: 0.1350\n",
            "Epoch 107/150, Loss: 0.1300\n",
            "Epoch 108/150, Loss: 0.1381\n",
            "Epoch 109/150, Loss: 0.1348\n",
            "Epoch 110/150, Loss: 0.1359\n",
            "Epoch 111/150, Loss: 0.1228\n",
            "Epoch 112/150, Loss: 0.1357\n",
            "Epoch 113/150, Loss: 0.1232\n",
            "Epoch 114/150, Loss: 0.1136\n",
            "Epoch 115/150, Loss: 0.1399\n",
            "Epoch 116/150, Loss: 0.1400\n",
            "Epoch 117/150, Loss: 0.1336\n",
            "Epoch 118/150, Loss: 0.1238\n",
            "Epoch 119/150, Loss: 0.1371\n",
            "Epoch 120/150, Loss: 0.1287\n",
            "Epoch 121/150, Loss: 0.1190\n",
            "Epoch 122/150, Loss: 0.1156\n",
            "Epoch 123/150, Loss: 0.1258\n",
            "Epoch 124/150, Loss: 0.1039\n",
            "Epoch 125/150, Loss: 0.1065\n",
            "Epoch 126/150, Loss: 0.1235\n",
            "Epoch 127/150, Loss: 0.1183\n",
            "Epoch 128/150, Loss: 0.1136\n",
            "Epoch 129/150, Loss: 0.1153\n",
            "Epoch 130/150, Loss: 0.1038\n",
            "Epoch 131/150, Loss: 0.1094\n",
            "Epoch 132/150, Loss: 0.1138\n",
            "Epoch 133/150, Loss: 0.1065\n",
            "Epoch 134/150, Loss: 0.1239\n",
            "Epoch 135/150, Loss: 0.1187\n",
            "Epoch 136/150, Loss: 0.1140\n",
            "Epoch 137/150, Loss: 0.1293\n",
            "Epoch 138/150, Loss: 0.0923\n",
            "Epoch 139/150, Loss: 0.1060\n",
            "Epoch 140/150, Loss: 0.0998\n",
            "Epoch 141/150, Loss: 0.1074\n",
            "Epoch 142/150, Loss: 0.1001\n",
            "Epoch 143/150, Loss: 0.1206\n",
            "Epoch 144/150, Loss: 0.0927\n",
            "Epoch 145/150, Loss: 0.1303\n",
            "Epoch 146/150, Loss: 0.1105\n",
            "Epoch 147/150, Loss: 0.0994\n",
            "Epoch 148/150, Loss: 0.1026\n",
            "Epoch 149/150, Loss: 0.1105\n",
            "Epoch 150/150, Loss: 0.1091\n",
            "Iteration 2/10: 691 anomalies detected by GFCN.\n",
            "Iteration 2/10: Number of Nodes after anomaly removal: 1626\n",
            "Evaluating model at iteration 2...\n",
            "Iteration 2 - Evaluation Metrics:\n",
            "Accuracy: 0.9543\n",
            "F1 Score: 0.9235\n",
            "Precision: 0.9262\n",
            "Recall: 0.9209\n",
            "Iteration 3/10: 488 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7191\n",
            "Epoch 2/150, Loss: 0.6775\n",
            "Epoch 3/150, Loss: 0.6429\n",
            "Epoch 4/150, Loss: 0.6215\n",
            "Epoch 5/150, Loss: 0.5935\n",
            "Epoch 6/150, Loss: 0.5702\n",
            "Epoch 7/150, Loss: 0.5561\n",
            "Epoch 8/150, Loss: 0.5446\n",
            "Epoch 9/150, Loss: 0.5296\n",
            "Epoch 10/150, Loss: 0.5139\n",
            "Epoch 11/150, Loss: 0.5100\n",
            "Epoch 12/150, Loss: 0.4927\n",
            "Epoch 13/150, Loss: 0.4802\n",
            "Epoch 14/150, Loss: 0.4671\n",
            "Epoch 15/150, Loss: 0.4585\n",
            "Epoch 16/150, Loss: 0.4452\n",
            "Epoch 17/150, Loss: 0.4328\n",
            "Epoch 18/150, Loss: 0.4328\n",
            "Epoch 19/150, Loss: 0.4228\n",
            "Epoch 20/150, Loss: 0.4087\n",
            "Epoch 21/150, Loss: 0.4070\n",
            "Epoch 22/150, Loss: 0.3828\n",
            "Epoch 23/150, Loss: 0.3686\n",
            "Epoch 24/150, Loss: 0.3642\n",
            "Epoch 25/150, Loss: 0.3678\n",
            "Epoch 26/150, Loss: 0.3392\n",
            "Epoch 27/150, Loss: 0.3146\n",
            "Epoch 28/150, Loss: 0.3245\n",
            "Epoch 29/150, Loss: 0.2999\n",
            "Epoch 30/150, Loss: 0.2995\n",
            "Epoch 31/150, Loss: 0.2738\n",
            "Epoch 32/150, Loss: 0.2892\n",
            "Epoch 33/150, Loss: 0.2651\n",
            "Epoch 34/150, Loss: 0.2505\n",
            "Epoch 35/150, Loss: 0.2494\n",
            "Epoch 36/150, Loss: 0.2353\n",
            "Epoch 37/150, Loss: 0.2297\n",
            "Epoch 38/150, Loss: 0.2308\n",
            "Epoch 39/150, Loss: 0.2144\n",
            "Epoch 40/150, Loss: 0.2141\n",
            "Epoch 41/150, Loss: 0.1996\n",
            "Epoch 42/150, Loss: 0.2045\n",
            "Epoch 43/150, Loss: 0.1840\n",
            "Epoch 44/150, Loss: 0.1877\n",
            "Epoch 45/150, Loss: 0.1769\n",
            "Epoch 46/150, Loss: 0.1756\n",
            "Epoch 47/150, Loss: 0.1801\n",
            "Epoch 48/150, Loss: 0.1913\n",
            "Epoch 49/150, Loss: 0.1722\n",
            "Epoch 50/150, Loss: 0.1583\n",
            "Epoch 51/150, Loss: 0.1645\n",
            "Epoch 52/150, Loss: 0.1396\n",
            "Epoch 53/150, Loss: 0.1519\n",
            "Epoch 54/150, Loss: 0.1529\n",
            "Epoch 55/150, Loss: 0.1524\n",
            "Epoch 56/150, Loss: 0.1224\n",
            "Epoch 57/150, Loss: 0.1482\n",
            "Epoch 58/150, Loss: 0.1433\n",
            "Epoch 59/150, Loss: 0.1330\n",
            "Epoch 60/150, Loss: 0.1382\n",
            "Epoch 61/150, Loss: 0.1192\n",
            "Epoch 62/150, Loss: 0.1258\n",
            "Epoch 63/150, Loss: 0.1280\n",
            "Epoch 64/150, Loss: 0.1188\n",
            "Epoch 65/150, Loss: 0.1372\n",
            "Epoch 66/150, Loss: 0.1315\n",
            "Epoch 67/150, Loss: 0.1142\n",
            "Epoch 68/150, Loss: 0.0992\n",
            "Epoch 69/150, Loss: 0.1260\n",
            "Epoch 70/150, Loss: 0.1096\n",
            "Epoch 71/150, Loss: 0.1043\n",
            "Epoch 72/150, Loss: 0.0931\n",
            "Epoch 73/150, Loss: 0.0963\n",
            "Epoch 74/150, Loss: 0.1000\n",
            "Epoch 75/150, Loss: 0.1006\n",
            "Epoch 76/150, Loss: 0.1077\n",
            "Epoch 77/150, Loss: 0.1003\n",
            "Epoch 78/150, Loss: 0.1000\n",
            "Epoch 79/150, Loss: 0.1014\n",
            "Epoch 80/150, Loss: 0.0979\n",
            "Epoch 81/150, Loss: 0.0906\n",
            "Epoch 82/150, Loss: 0.0978\n",
            "Epoch 83/150, Loss: 0.0943\n",
            "Epoch 84/150, Loss: 0.0875\n",
            "Epoch 85/150, Loss: 0.0849\n",
            "Epoch 86/150, Loss: 0.0770\n",
            "Epoch 87/150, Loss: 0.0784\n",
            "Epoch 88/150, Loss: 0.0994\n",
            "Epoch 89/150, Loss: 0.0848\n",
            "Epoch 90/150, Loss: 0.1033\n",
            "Epoch 91/150, Loss: 0.0945\n",
            "Epoch 92/150, Loss: 0.0953\n",
            "Epoch 93/150, Loss: 0.0818\n",
            "Epoch 94/150, Loss: 0.0755\n",
            "Epoch 95/150, Loss: 0.0831\n",
            "Epoch 96/150, Loss: 0.0859\n",
            "Epoch 97/150, Loss: 0.0781\n",
            "Epoch 98/150, Loss: 0.0776\n",
            "Epoch 99/150, Loss: 0.0814\n",
            "Epoch 100/150, Loss: 0.0874\n",
            "Epoch 101/150, Loss: 0.0710\n",
            "Epoch 102/150, Loss: 0.0808\n",
            "Epoch 103/150, Loss: 0.0830\n",
            "Epoch 104/150, Loss: 0.0931\n",
            "Epoch 105/150, Loss: 0.0836\n",
            "Epoch 106/150, Loss: 0.0866\n",
            "Epoch 107/150, Loss: 0.0697\n",
            "Epoch 108/150, Loss: 0.0699\n",
            "Epoch 109/150, Loss: 0.0670\n",
            "Epoch 110/150, Loss: 0.0670\n",
            "Epoch 111/150, Loss: 0.0693\n",
            "Epoch 112/150, Loss: 0.0629\n",
            "Epoch 113/150, Loss: 0.0700\n",
            "Epoch 114/150, Loss: 0.0618\n",
            "Epoch 115/150, Loss: 0.0648\n",
            "Epoch 116/150, Loss: 0.0835\n",
            "Epoch 117/150, Loss: 0.0660\n",
            "Epoch 118/150, Loss: 0.0636\n",
            "Epoch 119/150, Loss: 0.0641\n",
            "Epoch 120/150, Loss: 0.0618\n",
            "Epoch 121/150, Loss: 0.0574\n",
            "Epoch 122/150, Loss: 0.0658\n",
            "Epoch 123/150, Loss: 0.0614\n",
            "Epoch 124/150, Loss: 0.0573\n",
            "Epoch 125/150, Loss: 0.0509\n",
            "Epoch 126/150, Loss: 0.0726\n",
            "Epoch 127/150, Loss: 0.0600\n",
            "Epoch 128/150, Loss: 0.0708\n",
            "Epoch 129/150, Loss: 0.0593\n",
            "Epoch 130/150, Loss: 0.0636\n",
            "Epoch 131/150, Loss: 0.0579\n",
            "Epoch 132/150, Loss: 0.0619\n",
            "Epoch 133/150, Loss: 0.0500\n",
            "Epoch 134/150, Loss: 0.0447\n",
            "Epoch 135/150, Loss: 0.0491\n",
            "Epoch 136/150, Loss: 0.0532\n",
            "Epoch 137/150, Loss: 0.0626\n",
            "Epoch 138/150, Loss: 0.0489\n",
            "Epoch 139/150, Loss: 0.0590\n",
            "Epoch 140/150, Loss: 0.0714\n",
            "Epoch 141/150, Loss: 0.0607\n",
            "Epoch 142/150, Loss: 0.0496\n",
            "Epoch 143/150, Loss: 0.0627\n",
            "Epoch 144/150, Loss: 0.0481\n",
            "Epoch 145/150, Loss: 0.0579\n",
            "Epoch 146/150, Loss: 0.0513\n",
            "Epoch 147/150, Loss: 0.0457\n",
            "Epoch 148/150, Loss: 0.0548\n",
            "Epoch 149/150, Loss: 0.0339\n",
            "Epoch 150/150, Loss: 0.0424\n",
            "Iteration 3/10: 445 anomalies detected by GFCN.\n",
            "Iteration 3/10: Number of Nodes after anomaly removal: 1181\n",
            "Evaluating model at iteration 3...\n",
            "Iteration 3 - Evaluation Metrics:\n",
            "Accuracy: 0.9440\n",
            "F1 Score: 0.9025\n",
            "Precision: 0.9461\n",
            "Recall: 0.8627\n",
            "Iteration 4/10: 354 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7077\n",
            "Epoch 2/150, Loss: 0.6561\n",
            "Epoch 3/150, Loss: 0.6265\n",
            "Epoch 4/150, Loss: 0.5946\n",
            "Epoch 5/150, Loss: 0.5718\n",
            "Epoch 6/150, Loss: 0.5611\n",
            "Epoch 7/150, Loss: 0.5394\n",
            "Epoch 8/150, Loss: 0.5268\n",
            "Epoch 9/150, Loss: 0.5190\n",
            "Epoch 10/150, Loss: 0.5025\n",
            "Epoch 11/150, Loss: 0.4919\n",
            "Epoch 12/150, Loss: 0.4677\n",
            "Epoch 13/150, Loss: 0.4632\n",
            "Epoch 14/150, Loss: 0.4518\n",
            "Epoch 15/150, Loss: 0.4365\n",
            "Epoch 16/150, Loss: 0.4294\n",
            "Epoch 17/150, Loss: 0.4016\n",
            "Epoch 18/150, Loss: 0.3876\n",
            "Epoch 19/150, Loss: 0.3947\n",
            "Epoch 20/150, Loss: 0.3749\n",
            "Epoch 21/150, Loss: 0.3638\n",
            "Epoch 22/150, Loss: 0.3518\n",
            "Epoch 23/150, Loss: 0.3374\n",
            "Epoch 24/150, Loss: 0.3302\n",
            "Epoch 25/150, Loss: 0.3063\n",
            "Epoch 26/150, Loss: 0.2990\n",
            "Epoch 27/150, Loss: 0.2850\n",
            "Epoch 28/150, Loss: 0.2749\n",
            "Epoch 29/150, Loss: 0.2568\n",
            "Epoch 30/150, Loss: 0.2555\n",
            "Epoch 31/150, Loss: 0.2456\n",
            "Epoch 32/150, Loss: 0.2325\n",
            "Epoch 33/150, Loss: 0.2110\n",
            "Epoch 34/150, Loss: 0.2071\n",
            "Epoch 35/150, Loss: 0.2082\n",
            "Epoch 36/150, Loss: 0.1953\n",
            "Epoch 37/150, Loss: 0.1799\n",
            "Epoch 38/150, Loss: 0.1893\n",
            "Epoch 39/150, Loss: 0.1743\n",
            "Epoch 40/150, Loss: 0.1718\n",
            "Epoch 41/150, Loss: 0.1774\n",
            "Epoch 42/150, Loss: 0.1351\n",
            "Epoch 43/150, Loss: 0.1500\n",
            "Epoch 44/150, Loss: 0.1439\n",
            "Epoch 45/150, Loss: 0.1313\n",
            "Epoch 46/150, Loss: 0.1451\n",
            "Epoch 47/150, Loss: 0.1295\n",
            "Epoch 48/150, Loss: 0.1097\n",
            "Epoch 49/150, Loss: 0.1150\n",
            "Epoch 50/150, Loss: 0.1203\n",
            "Epoch 51/150, Loss: 0.1251\n",
            "Epoch 52/150, Loss: 0.1072\n",
            "Epoch 53/150, Loss: 0.1120\n",
            "Epoch 54/150, Loss: 0.1027\n",
            "Epoch 55/150, Loss: 0.0954\n",
            "Epoch 56/150, Loss: 0.1037\n",
            "Epoch 57/150, Loss: 0.1104\n",
            "Epoch 58/150, Loss: 0.0961\n",
            "Epoch 59/150, Loss: 0.0888\n",
            "Epoch 60/150, Loss: 0.1022\n",
            "Epoch 61/150, Loss: 0.0829\n",
            "Epoch 62/150, Loss: 0.0901\n",
            "Epoch 63/150, Loss: 0.0798\n",
            "Epoch 64/150, Loss: 0.0878\n",
            "Epoch 65/150, Loss: 0.0793\n",
            "Epoch 66/150, Loss: 0.0710\n",
            "Epoch 67/150, Loss: 0.0775\n",
            "Epoch 68/150, Loss: 0.0809\n",
            "Epoch 69/150, Loss: 0.0754\n",
            "Epoch 70/150, Loss: 0.0691\n",
            "Epoch 71/150, Loss: 0.0639\n",
            "Epoch 72/150, Loss: 0.0600\n",
            "Epoch 73/150, Loss: 0.0710\n",
            "Epoch 74/150, Loss: 0.0698\n",
            "Epoch 75/150, Loss: 0.0661\n",
            "Epoch 76/150, Loss: 0.0574\n",
            "Epoch 77/150, Loss: 0.0595\n",
            "Epoch 78/150, Loss: 0.0650\n",
            "Epoch 79/150, Loss: 0.0656\n",
            "Epoch 80/150, Loss: 0.0597\n",
            "Epoch 81/150, Loss: 0.0552\n",
            "Epoch 82/150, Loss: 0.0550\n",
            "Epoch 83/150, Loss: 0.0603\n",
            "Epoch 84/150, Loss: 0.0583\n",
            "Epoch 85/150, Loss: 0.0520\n",
            "Epoch 86/150, Loss: 0.0528\n",
            "Epoch 87/150, Loss: 0.0476\n",
            "Epoch 88/150, Loss: 0.0450\n",
            "Epoch 89/150, Loss: 0.0388\n",
            "Epoch 90/150, Loss: 0.0493\n",
            "Epoch 91/150, Loss: 0.0507\n",
            "Epoch 92/150, Loss: 0.0429\n",
            "Epoch 93/150, Loss: 0.0508\n",
            "Epoch 94/150, Loss: 0.0494\n",
            "Epoch 95/150, Loss: 0.0378\n",
            "Epoch 96/150, Loss: 0.0445\n",
            "Epoch 97/150, Loss: 0.0457\n",
            "Epoch 98/150, Loss: 0.0618\n",
            "Epoch 99/150, Loss: 0.0513\n",
            "Epoch 100/150, Loss: 0.0365\n",
            "Epoch 101/150, Loss: 0.0454\n",
            "Epoch 102/150, Loss: 0.0467\n",
            "Epoch 103/150, Loss: 0.0395\n",
            "Epoch 104/150, Loss: 0.0516\n",
            "Epoch 105/150, Loss: 0.0382\n",
            "Epoch 106/150, Loss: 0.0296\n",
            "Epoch 107/150, Loss: 0.0464\n",
            "Epoch 108/150, Loss: 0.0427\n",
            "Epoch 109/150, Loss: 0.0431\n",
            "Epoch 110/150, Loss: 0.0511\n",
            "Epoch 111/150, Loss: 0.0442\n",
            "Epoch 112/150, Loss: 0.0447\n",
            "Epoch 113/150, Loss: 0.0391\n",
            "Epoch 114/150, Loss: 0.0305\n",
            "Epoch 115/150, Loss: 0.0397\n",
            "Epoch 116/150, Loss: 0.0328\n",
            "Epoch 117/150, Loss: 0.0480\n",
            "Epoch 118/150, Loss: 0.0430\n",
            "Epoch 119/150, Loss: 0.0383\n",
            "Epoch 120/150, Loss: 0.0394\n",
            "Epoch 121/150, Loss: 0.0402\n",
            "Epoch 122/150, Loss: 0.0337\n",
            "Epoch 123/150, Loss: 0.0501\n",
            "Epoch 124/150, Loss: 0.0513\n",
            "Epoch 125/150, Loss: 0.0265\n",
            "Epoch 126/150, Loss: 0.0289\n",
            "Epoch 127/150, Loss: 0.0410\n",
            "Epoch 128/150, Loss: 0.0318\n",
            "Epoch 129/150, Loss: 0.0324\n",
            "Epoch 130/150, Loss: 0.0305\n",
            "Epoch 131/150, Loss: 0.0453\n",
            "Epoch 132/150, Loss: 0.0399\n",
            "Epoch 133/150, Loss: 0.0281\n",
            "Epoch 134/150, Loss: 0.0325\n",
            "Epoch 135/150, Loss: 0.0296\n",
            "Epoch 136/150, Loss: 0.0313\n",
            "Epoch 137/150, Loss: 0.0476\n",
            "Epoch 138/150, Loss: 0.0381\n",
            "Epoch 139/150, Loss: 0.0412\n",
            "Epoch 140/150, Loss: 0.0283\n",
            "Epoch 141/150, Loss: 0.0346\n",
            "Epoch 142/150, Loss: 0.0361\n",
            "Epoch 143/150, Loss: 0.0280\n",
            "Epoch 144/150, Loss: 0.0308\n",
            "Epoch 145/150, Loss: 0.0320\n",
            "Epoch 146/150, Loss: 0.0257\n",
            "Epoch 147/150, Loss: 0.0192\n",
            "Epoch 148/150, Loss: 0.0297\n",
            "Epoch 149/150, Loss: 0.0316\n",
            "Epoch 150/150, Loss: 0.0264\n",
            "Iteration 4/10: 311 anomalies detected by GFCN.\n",
            "Iteration 4/10: Number of Nodes after anomaly removal: 870\n",
            "Evaluating model at iteration 4...\n",
            "Iteration 4 - Evaluation Metrics:\n",
            "Accuracy: 0.9263\n",
            "F1 Score: 0.8692\n",
            "Precision: 0.9293\n",
            "Recall: 0.8164\n",
            "Iteration 5/10: 261 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7057\n",
            "Epoch 2/150, Loss: 0.6490\n",
            "Epoch 3/150, Loss: 0.6098\n",
            "Epoch 4/150, Loss: 0.5744\n",
            "Epoch 5/150, Loss: 0.5446\n",
            "Epoch 6/150, Loss: 0.5204\n",
            "Epoch 7/150, Loss: 0.4930\n",
            "Epoch 8/150, Loss: 0.4786\n",
            "Epoch 9/150, Loss: 0.4661\n",
            "Epoch 10/150, Loss: 0.4524\n",
            "Epoch 11/150, Loss: 0.4381\n",
            "Epoch 12/150, Loss: 0.4100\n",
            "Epoch 13/150, Loss: 0.3874\n",
            "Epoch 14/150, Loss: 0.3825\n",
            "Epoch 15/150, Loss: 0.3635\n",
            "Epoch 16/150, Loss: 0.3559\n",
            "Epoch 17/150, Loss: 0.3175\n",
            "Epoch 18/150, Loss: 0.3167\n",
            "Epoch 19/150, Loss: 0.3069\n",
            "Epoch 20/150, Loss: 0.2776\n",
            "Epoch 21/150, Loss: 0.2665\n",
            "Epoch 22/150, Loss: 0.2600\n",
            "Epoch 23/150, Loss: 0.2541\n",
            "Epoch 24/150, Loss: 0.2445\n",
            "Epoch 25/150, Loss: 0.2255\n",
            "Epoch 26/150, Loss: 0.2086\n",
            "Epoch 27/150, Loss: 0.2002\n",
            "Epoch 28/150, Loss: 0.1994\n",
            "Epoch 29/150, Loss: 0.1879\n",
            "Epoch 30/150, Loss: 0.1713\n",
            "Epoch 31/150, Loss: 0.1573\n",
            "Epoch 32/150, Loss: 0.1433\n",
            "Epoch 33/150, Loss: 0.1448\n",
            "Epoch 34/150, Loss: 0.1293\n",
            "Epoch 35/150, Loss: 0.1230\n",
            "Epoch 36/150, Loss: 0.1196\n",
            "Epoch 37/150, Loss: 0.1087\n",
            "Epoch 38/150, Loss: 0.1093\n",
            "Epoch 39/150, Loss: 0.1002\n",
            "Epoch 40/150, Loss: 0.0947\n",
            "Epoch 41/150, Loss: 0.0993\n",
            "Epoch 42/150, Loss: 0.1024\n",
            "Epoch 43/150, Loss: 0.0863\n",
            "Epoch 44/150, Loss: 0.0891\n",
            "Epoch 45/150, Loss: 0.0813\n",
            "Epoch 46/150, Loss: 0.0786\n",
            "Epoch 47/150, Loss: 0.0691\n",
            "Epoch 48/150, Loss: 0.0642\n",
            "Epoch 49/150, Loss: 0.0630\n",
            "Epoch 50/150, Loss: 0.0777\n",
            "Epoch 51/150, Loss: 0.0599\n",
            "Epoch 52/150, Loss: 0.0622\n",
            "Epoch 53/150, Loss: 0.0561\n",
            "Epoch 54/150, Loss: 0.0600\n",
            "Epoch 55/150, Loss: 0.0459\n",
            "Epoch 56/150, Loss: 0.0532\n",
            "Epoch 57/150, Loss: 0.0515\n",
            "Epoch 58/150, Loss: 0.0546\n",
            "Epoch 59/150, Loss: 0.0430\n",
            "Epoch 60/150, Loss: 0.0534\n",
            "Epoch 61/150, Loss: 0.0524\n",
            "Epoch 62/150, Loss: 0.0436\n",
            "Epoch 63/150, Loss: 0.0343\n",
            "Epoch 64/150, Loss: 0.0395\n",
            "Epoch 65/150, Loss: 0.0475\n",
            "Epoch 66/150, Loss: 0.0436\n",
            "Epoch 67/150, Loss: 0.0452\n",
            "Epoch 68/150, Loss: 0.0502\n",
            "Epoch 69/150, Loss: 0.0321\n",
            "Epoch 70/150, Loss: 0.0415\n",
            "Epoch 71/150, Loss: 0.0268\n",
            "Epoch 72/150, Loss: 0.0335\n",
            "Epoch 73/150, Loss: 0.0319\n",
            "Epoch 74/150, Loss: 0.0280\n",
            "Epoch 75/150, Loss: 0.0296\n",
            "Epoch 76/150, Loss: 0.0288\n",
            "Epoch 77/150, Loss: 0.0268\n",
            "Epoch 78/150, Loss: 0.0242\n",
            "Epoch 79/150, Loss: 0.0322\n",
            "Epoch 80/150, Loss: 0.0348\n",
            "Epoch 81/150, Loss: 0.0364\n",
            "Epoch 82/150, Loss: 0.0226\n",
            "Epoch 83/150, Loss: 0.0277\n",
            "Epoch 84/150, Loss: 0.0417\n",
            "Epoch 85/150, Loss: 0.0199\n",
            "Epoch 86/150, Loss: 0.0230\n",
            "Epoch 87/150, Loss: 0.0250\n",
            "Epoch 88/150, Loss: 0.0251\n",
            "Epoch 89/150, Loss: 0.0206\n",
            "Epoch 90/150, Loss: 0.0204\n",
            "Epoch 91/150, Loss: 0.0311\n",
            "Epoch 92/150, Loss: 0.0249\n",
            "Epoch 93/150, Loss: 0.0198\n",
            "Epoch 94/150, Loss: 0.0226\n",
            "Epoch 95/150, Loss: 0.0236\n",
            "Epoch 96/150, Loss: 0.0150\n",
            "Epoch 97/150, Loss: 0.0198\n",
            "Epoch 98/150, Loss: 0.0230\n",
            "Epoch 99/150, Loss: 0.0206\n",
            "Epoch 100/150, Loss: 0.0232\n",
            "Epoch 101/150, Loss: 0.0310\n",
            "Epoch 102/150, Loss: 0.0227\n",
            "Epoch 103/150, Loss: 0.0200\n",
            "Epoch 104/150, Loss: 0.0187\n",
            "Epoch 105/150, Loss: 0.0205\n",
            "Epoch 106/150, Loss: 0.0299\n",
            "Epoch 107/150, Loss: 0.0219\n",
            "Epoch 108/150, Loss: 0.0179\n",
            "Epoch 109/150, Loss: 0.0230\n",
            "Epoch 110/150, Loss: 0.0174\n",
            "Epoch 111/150, Loss: 0.0205\n",
            "Epoch 112/150, Loss: 0.0244\n",
            "Epoch 113/150, Loss: 0.0160\n",
            "Epoch 114/150, Loss: 0.0248\n",
            "Epoch 115/150, Loss: 0.0147\n",
            "Epoch 116/150, Loss: 0.0143\n",
            "Epoch 117/150, Loss: 0.0306\n",
            "Epoch 118/150, Loss: 0.0207\n",
            "Epoch 119/150, Loss: 0.0246\n",
            "Epoch 120/150, Loss: 0.0283\n",
            "Epoch 121/150, Loss: 0.0242\n",
            "Epoch 122/150, Loss: 0.0138\n",
            "Epoch 123/150, Loss: 0.0251\n",
            "Epoch 124/150, Loss: 0.0154\n",
            "Epoch 125/150, Loss: 0.0214\n",
            "Epoch 126/150, Loss: 0.0152\n",
            "Epoch 127/150, Loss: 0.0180\n",
            "Epoch 128/150, Loss: 0.0186\n",
            "Epoch 129/150, Loss: 0.0139\n",
            "Epoch 130/150, Loss: 0.0353\n",
            "Epoch 131/150, Loss: 0.0152\n",
            "Epoch 132/150, Loss: 0.0181\n",
            "Epoch 133/150, Loss: 0.0125\n",
            "Epoch 134/150, Loss: 0.0147\n",
            "Epoch 135/150, Loss: 0.0150\n",
            "Epoch 136/150, Loss: 0.0237\n",
            "Epoch 137/150, Loss: 0.0163\n",
            "Epoch 138/150, Loss: 0.0201\n",
            "Epoch 139/150, Loss: 0.0132\n",
            "Epoch 140/150, Loss: 0.0147\n",
            "Epoch 141/150, Loss: 0.0159\n",
            "Epoch 142/150, Loss: 0.0192\n",
            "Epoch 143/150, Loss: 0.0317\n",
            "Epoch 144/150, Loss: 0.0125\n",
            "Epoch 145/150, Loss: 0.0153\n",
            "Epoch 146/150, Loss: 0.0111\n",
            "Epoch 147/150, Loss: 0.0342\n",
            "Epoch 148/150, Loss: 0.0172\n",
            "Epoch 149/150, Loss: 0.0202\n",
            "Epoch 150/150, Loss: 0.0077\n",
            "Iteration 5/10: 215 anomalies detected by GFCN.\n",
            "Iteration 5/10: Number of Nodes after anomaly removal: 655\n",
            "Evaluating model at iteration 5...\n",
            "Iteration 5 - Evaluation Metrics:\n",
            "Accuracy: 0.9149\n",
            "F1 Score: 0.8445\n",
            "Precision: 0.9349\n",
            "Recall: 0.7701\n",
            "Iteration 6/10: 197 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6752\n",
            "Epoch 2/150, Loss: 0.6319\n",
            "Epoch 3/150, Loss: 0.5982\n",
            "Epoch 4/150, Loss: 0.5628\n",
            "Epoch 5/150, Loss: 0.5337\n",
            "Epoch 6/150, Loss: 0.5051\n",
            "Epoch 7/150, Loss: 0.4819\n",
            "Epoch 8/150, Loss: 0.4605\n",
            "Epoch 9/150, Loss: 0.4427\n",
            "Epoch 10/150, Loss: 0.4158\n",
            "Epoch 11/150, Loss: 0.3976\n",
            "Epoch 12/150, Loss: 0.3787\n",
            "Epoch 13/150, Loss: 0.3566\n",
            "Epoch 14/150, Loss: 0.3292\n",
            "Epoch 15/150, Loss: 0.3162\n",
            "Epoch 16/150, Loss: 0.2857\n",
            "Epoch 17/150, Loss: 0.2690\n",
            "Epoch 18/150, Loss: 0.2684\n",
            "Epoch 19/150, Loss: 0.2410\n",
            "Epoch 20/150, Loss: 0.2353\n",
            "Epoch 21/150, Loss: 0.2201\n",
            "Epoch 22/150, Loss: 0.1995\n",
            "Epoch 23/150, Loss: 0.1829\n",
            "Epoch 24/150, Loss: 0.1760\n",
            "Epoch 25/150, Loss: 0.1781\n",
            "Epoch 26/150, Loss: 0.1599\n",
            "Epoch 27/150, Loss: 0.1538\n",
            "Epoch 28/150, Loss: 0.1391\n",
            "Epoch 29/150, Loss: 0.1261\n",
            "Epoch 30/150, Loss: 0.1097\n",
            "Epoch 31/150, Loss: 0.1001\n",
            "Epoch 32/150, Loss: 0.0913\n",
            "Epoch 33/150, Loss: 0.0942\n",
            "Epoch 34/150, Loss: 0.0879\n",
            "Epoch 35/150, Loss: 0.0867\n",
            "Epoch 36/150, Loss: 0.0719\n",
            "Epoch 37/150, Loss: 0.0663\n",
            "Epoch 38/150, Loss: 0.0785\n",
            "Epoch 39/150, Loss: 0.0638\n",
            "Epoch 40/150, Loss: 0.0490\n",
            "Epoch 41/150, Loss: 0.0501\n",
            "Epoch 42/150, Loss: 0.0435\n",
            "Epoch 43/150, Loss: 0.0482\n",
            "Epoch 44/150, Loss: 0.0453\n",
            "Epoch 45/150, Loss: 0.0621\n",
            "Epoch 46/150, Loss: 0.0421\n",
            "Epoch 47/150, Loss: 0.0488\n",
            "Epoch 48/150, Loss: 0.0375\n",
            "Epoch 49/150, Loss: 0.0382\n",
            "Epoch 50/150, Loss: 0.0514\n",
            "Epoch 51/150, Loss: 0.0342\n",
            "Epoch 52/150, Loss: 0.0270\n",
            "Epoch 53/150, Loss: 0.0285\n",
            "Epoch 54/150, Loss: 0.0292\n",
            "Epoch 55/150, Loss: 0.0362\n",
            "Epoch 56/150, Loss: 0.0241\n",
            "Epoch 57/150, Loss: 0.0266\n",
            "Epoch 58/150, Loss: 0.0253\n",
            "Epoch 59/150, Loss: 0.0273\n",
            "Epoch 60/150, Loss: 0.0251\n",
            "Epoch 61/150, Loss: 0.0286\n",
            "Epoch 62/150, Loss: 0.0248\n",
            "Epoch 63/150, Loss: 0.0159\n",
            "Epoch 64/150, Loss: 0.0269\n",
            "Epoch 65/150, Loss: 0.0219\n",
            "Epoch 66/150, Loss: 0.0213\n",
            "Epoch 67/150, Loss: 0.0275\n",
            "Epoch 68/150, Loss: 0.0201\n",
            "Epoch 69/150, Loss: 0.0179\n",
            "Epoch 70/150, Loss: 0.0188\n",
            "Epoch 71/150, Loss: 0.0206\n",
            "Epoch 72/150, Loss: 0.0230\n",
            "Epoch 73/150, Loss: 0.0169\n",
            "Epoch 74/150, Loss: 0.0159\n",
            "Epoch 75/150, Loss: 0.0220\n",
            "Epoch 76/150, Loss: 0.0161\n",
            "Epoch 77/150, Loss: 0.0177\n",
            "Epoch 78/150, Loss: 0.0239\n",
            "Epoch 79/150, Loss: 0.0282\n",
            "Epoch 80/150, Loss: 0.0173\n",
            "Epoch 81/150, Loss: 0.0150\n",
            "Epoch 82/150, Loss: 0.0233\n",
            "Epoch 83/150, Loss: 0.0228\n",
            "Epoch 84/150, Loss: 0.0163\n",
            "Epoch 85/150, Loss: 0.0173\n",
            "Epoch 86/150, Loss: 0.0257\n",
            "Epoch 87/150, Loss: 0.0178\n",
            "Epoch 88/150, Loss: 0.0231\n",
            "Epoch 89/150, Loss: 0.0178\n",
            "Epoch 90/150, Loss: 0.0163\n",
            "Epoch 91/150, Loss: 0.0124\n",
            "Epoch 92/150, Loss: 0.0148\n",
            "Epoch 93/150, Loss: 0.0129\n",
            "Epoch 94/150, Loss: 0.0147\n",
            "Epoch 95/150, Loss: 0.0102\n",
            "Epoch 96/150, Loss: 0.0101\n",
            "Epoch 97/150, Loss: 0.0114\n",
            "Epoch 98/150, Loss: 0.0153\n",
            "Epoch 99/150, Loss: 0.0094\n",
            "Epoch 100/150, Loss: 0.0117\n",
            "Epoch 101/150, Loss: 0.0062\n",
            "Epoch 102/150, Loss: 0.0111\n",
            "Epoch 103/150, Loss: 0.0122\n",
            "Epoch 104/150, Loss: 0.0107\n",
            "Epoch 105/150, Loss: 0.0183\n",
            "Epoch 106/150, Loss: 0.0143\n",
            "Epoch 107/150, Loss: 0.0105\n",
            "Epoch 108/150, Loss: 0.0166\n",
            "Epoch 109/150, Loss: 0.0112\n",
            "Epoch 110/150, Loss: 0.0091\n",
            "Epoch 111/150, Loss: 0.0118\n",
            "Epoch 112/150, Loss: 0.0201\n",
            "Epoch 113/150, Loss: 0.0153\n",
            "Epoch 114/150, Loss: 0.0101\n",
            "Epoch 115/150, Loss: 0.0142\n",
            "Epoch 116/150, Loss: 0.0090\n",
            "Epoch 117/150, Loss: 0.0081\n",
            "Epoch 118/150, Loss: 0.0090\n",
            "Epoch 119/150, Loss: 0.0066\n",
            "Epoch 120/150, Loss: 0.0081\n",
            "Epoch 121/150, Loss: 0.0104\n",
            "Epoch 122/150, Loss: 0.0098\n",
            "Epoch 123/150, Loss: 0.0090\n",
            "Epoch 124/150, Loss: 0.0091\n",
            "Epoch 125/150, Loss: 0.0075\n",
            "Epoch 126/150, Loss: 0.0124\n",
            "Epoch 127/150, Loss: 0.0097\n",
            "Epoch 128/150, Loss: 0.0079\n",
            "Epoch 129/150, Loss: 0.0151\n",
            "Epoch 130/150, Loss: 0.0112\n",
            "Epoch 131/150, Loss: 0.0090\n",
            "Epoch 132/150, Loss: 0.0088\n",
            "Epoch 133/150, Loss: 0.0085\n",
            "Epoch 134/150, Loss: 0.0118\n",
            "Epoch 135/150, Loss: 0.0049\n",
            "Epoch 136/150, Loss: 0.0062\n",
            "Epoch 137/150, Loss: 0.0075\n",
            "Epoch 138/150, Loss: 0.0076\n",
            "Epoch 139/150, Loss: 0.0074\n",
            "Epoch 140/150, Loss: 0.0085\n",
            "Epoch 141/150, Loss: 0.0076\n",
            "Epoch 142/150, Loss: 0.0059\n",
            "Epoch 143/150, Loss: 0.0061\n",
            "Epoch 144/150, Loss: 0.0068\n",
            "Epoch 145/150, Loss: 0.0073\n",
            "Epoch 146/150, Loss: 0.0103\n",
            "Epoch 147/150, Loss: 0.0072\n",
            "Epoch 148/150, Loss: 0.0127\n",
            "Epoch 149/150, Loss: 0.0057\n",
            "Epoch 150/150, Loss: 0.0072\n",
            "Iteration 6/10: 153 anomalies detected by GFCN.\n",
            "Iteration 6/10: Number of Nodes after anomaly removal: 502\n",
            "Evaluating model at iteration 6...\n",
            "Iteration 6 - Evaluation Metrics:\n",
            "Accuracy: 0.9145\n",
            "F1 Score: 0.8400\n",
            "Precision: 0.9608\n",
            "Recall: 0.7462\n",
            "Iteration 7/10: 151 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6993\n",
            "Epoch 2/150, Loss: 0.6451\n",
            "Epoch 3/150, Loss: 0.5999\n",
            "Epoch 4/150, Loss: 0.5643\n",
            "Epoch 5/150, Loss: 0.5209\n",
            "Epoch 6/150, Loss: 0.4863\n",
            "Epoch 7/150, Loss: 0.4603\n",
            "Epoch 8/150, Loss: 0.4335\n",
            "Epoch 9/150, Loss: 0.4111\n",
            "Epoch 10/150, Loss: 0.3859\n",
            "Epoch 11/150, Loss: 0.3536\n",
            "Epoch 12/150, Loss: 0.3305\n",
            "Epoch 13/150, Loss: 0.3165\n",
            "Epoch 14/150, Loss: 0.2967\n",
            "Epoch 15/150, Loss: 0.2716\n",
            "Epoch 16/150, Loss: 0.2562\n",
            "Epoch 17/150, Loss: 0.2365\n",
            "Epoch 18/150, Loss: 0.2232\n",
            "Epoch 19/150, Loss: 0.2042\n",
            "Epoch 20/150, Loss: 0.2037\n",
            "Epoch 21/150, Loss: 0.1679\n",
            "Epoch 22/150, Loss: 0.1790\n",
            "Epoch 23/150, Loss: 0.1571\n",
            "Epoch 24/150, Loss: 0.1380\n",
            "Epoch 25/150, Loss: 0.1263\n",
            "Epoch 26/150, Loss: 0.1199\n",
            "Epoch 27/150, Loss: 0.1224\n",
            "Epoch 28/150, Loss: 0.0940\n",
            "Epoch 29/150, Loss: 0.0815\n",
            "Epoch 30/150, Loss: 0.0840\n",
            "Epoch 31/150, Loss: 0.0721\n",
            "Epoch 32/150, Loss: 0.0694\n",
            "Epoch 33/150, Loss: 0.0670\n",
            "Epoch 34/150, Loss: 0.0620\n",
            "Epoch 35/150, Loss: 0.0588\n",
            "Epoch 36/150, Loss: 0.0502\n",
            "Epoch 37/150, Loss: 0.0614\n",
            "Epoch 38/150, Loss: 0.0499\n",
            "Epoch 39/150, Loss: 0.0420\n",
            "Epoch 40/150, Loss: 0.0494\n",
            "Epoch 41/150, Loss: 0.0501\n",
            "Epoch 42/150, Loss: 0.0360\n",
            "Epoch 43/150, Loss: 0.0364\n",
            "Epoch 44/150, Loss: 0.0368\n",
            "Epoch 45/150, Loss: 0.0343\n",
            "Epoch 46/150, Loss: 0.0201\n",
            "Epoch 47/150, Loss: 0.0334\n",
            "Epoch 48/150, Loss: 0.0339\n",
            "Epoch 49/150, Loss: 0.0243\n",
            "Epoch 50/150, Loss: 0.0274\n",
            "Epoch 51/150, Loss: 0.0234\n",
            "Epoch 52/150, Loss: 0.0218\n",
            "Epoch 53/150, Loss: 0.0209\n",
            "Epoch 54/150, Loss: 0.0191\n",
            "Epoch 55/150, Loss: 0.0304\n",
            "Epoch 56/150, Loss: 0.0191\n",
            "Epoch 57/150, Loss: 0.0241\n",
            "Epoch 58/150, Loss: 0.0173\n",
            "Epoch 59/150, Loss: 0.0203\n",
            "Epoch 60/150, Loss: 0.0121\n",
            "Epoch 61/150, Loss: 0.0169\n",
            "Epoch 62/150, Loss: 0.0144\n",
            "Epoch 63/150, Loss: 0.0159\n",
            "Epoch 64/150, Loss: 0.0114\n",
            "Epoch 65/150, Loss: 0.0201\n",
            "Epoch 66/150, Loss: 0.0214\n",
            "Epoch 67/150, Loss: 0.0177\n",
            "Epoch 68/150, Loss: 0.0142\n",
            "Epoch 69/150, Loss: 0.0129\n",
            "Epoch 70/150, Loss: 0.0132\n",
            "Epoch 71/150, Loss: 0.0154\n",
            "Epoch 72/150, Loss: 0.0171\n",
            "Epoch 73/150, Loss: 0.0170\n",
            "Epoch 74/150, Loss: 0.0114\n",
            "Epoch 75/150, Loss: 0.0143\n",
            "Epoch 76/150, Loss: 0.0141\n",
            "Epoch 77/150, Loss: 0.0157\n",
            "Epoch 78/150, Loss: 0.0093\n",
            "Epoch 79/150, Loss: 0.0103\n",
            "Epoch 80/150, Loss: 0.0108\n",
            "Epoch 81/150, Loss: 0.0117\n",
            "Epoch 82/150, Loss: 0.0088\n",
            "Epoch 83/150, Loss: 0.0127\n",
            "Epoch 84/150, Loss: 0.0068\n",
            "Epoch 85/150, Loss: 0.0067\n",
            "Epoch 86/150, Loss: 0.0089\n",
            "Epoch 87/150, Loss: 0.0093\n",
            "Epoch 88/150, Loss: 0.0155\n",
            "Epoch 89/150, Loss: 0.0094\n",
            "Epoch 90/150, Loss: 0.0114\n",
            "Epoch 91/150, Loss: 0.0129\n",
            "Epoch 92/150, Loss: 0.0073\n",
            "Epoch 93/150, Loss: 0.0130\n",
            "Epoch 94/150, Loss: 0.0078\n",
            "Epoch 95/150, Loss: 0.0070\n",
            "Epoch 96/150, Loss: 0.0113\n",
            "Epoch 97/150, Loss: 0.0148\n",
            "Epoch 98/150, Loss: 0.0095\n",
            "Epoch 99/150, Loss: 0.0065\n",
            "Epoch 100/150, Loss: 0.0091\n",
            "Epoch 101/150, Loss: 0.0108\n",
            "Epoch 102/150, Loss: 0.0056\n",
            "Epoch 103/150, Loss: 0.0082\n",
            "Epoch 104/150, Loss: 0.0083\n",
            "Epoch 105/150, Loss: 0.0092\n",
            "Epoch 106/150, Loss: 0.0128\n",
            "Epoch 107/150, Loss: 0.0099\n",
            "Epoch 108/150, Loss: 0.0074\n",
            "Epoch 109/150, Loss: 0.0103\n",
            "Epoch 110/150, Loss: 0.0082\n",
            "Epoch 111/150, Loss: 0.0081\n",
            "Epoch 112/150, Loss: 0.0048\n",
            "Epoch 113/150, Loss: 0.0079\n",
            "Epoch 114/150, Loss: 0.0092\n",
            "Epoch 115/150, Loss: 0.0060\n",
            "Epoch 116/150, Loss: 0.0064\n",
            "Epoch 117/150, Loss: 0.0082\n",
            "Epoch 118/150, Loss: 0.0087\n",
            "Epoch 119/150, Loss: 0.0077\n",
            "Epoch 120/150, Loss: 0.0056\n",
            "Epoch 121/150, Loss: 0.0103\n",
            "Epoch 122/150, Loss: 0.0042\n",
            "Epoch 123/150, Loss: 0.0051\n",
            "Epoch 124/150, Loss: 0.0083\n",
            "Epoch 125/150, Loss: 0.0052\n",
            "Epoch 126/150, Loss: 0.0076\n",
            "Epoch 127/150, Loss: 0.0051\n",
            "Epoch 128/150, Loss: 0.0093\n",
            "Epoch 129/150, Loss: 0.0088\n",
            "Epoch 130/150, Loss: 0.0061\n",
            "Epoch 131/150, Loss: 0.0043\n",
            "Epoch 132/150, Loss: 0.0049\n",
            "Epoch 133/150, Loss: 0.0056\n",
            "Epoch 134/150, Loss: 0.0051\n",
            "Epoch 135/150, Loss: 0.0080\n",
            "Epoch 136/150, Loss: 0.0074\n",
            "Epoch 137/150, Loss: 0.0064\n",
            "Epoch 138/150, Loss: 0.0048\n",
            "Epoch 139/150, Loss: 0.0045\n",
            "Epoch 140/150, Loss: 0.0054\n",
            "Epoch 141/150, Loss: 0.0041\n",
            "Epoch 142/150, Loss: 0.0093\n",
            "Epoch 143/150, Loss: 0.0065\n",
            "Epoch 144/150, Loss: 0.0073\n",
            "Epoch 145/150, Loss: 0.0077\n",
            "Epoch 146/150, Loss: 0.0074\n",
            "Epoch 147/150, Loss: 0.0070\n",
            "Epoch 148/150, Loss: 0.0054\n",
            "Epoch 149/150, Loss: 0.0082\n",
            "Epoch 150/150, Loss: 0.0043\n",
            "Iteration 7/10: 118 anomalies detected by GFCN.\n",
            "Iteration 7/10: Number of Nodes after anomaly removal: 384\n",
            "Evaluating model at iteration 7...\n",
            "Iteration 7 - Evaluation Metrics:\n",
            "Accuracy: 0.9104\n",
            "F1 Score: 0.8327\n",
            "Precision: 0.9492\n",
            "Recall: 0.7417\n",
            "Iteration 8/10: 115 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7143\n",
            "Epoch 2/150, Loss: 0.6470\n",
            "Epoch 3/150, Loss: 0.6065\n",
            "Epoch 4/150, Loss: 0.5646\n",
            "Epoch 5/150, Loss: 0.5233\n",
            "Epoch 6/150, Loss: 0.4847\n",
            "Epoch 7/150, Loss: 0.4587\n",
            "Epoch 8/150, Loss: 0.4353\n",
            "Epoch 9/150, Loss: 0.3980\n",
            "Epoch 10/150, Loss: 0.3889\n",
            "Epoch 11/150, Loss: 0.3676\n",
            "Epoch 12/150, Loss: 0.3184\n",
            "Epoch 13/150, Loss: 0.3117\n",
            "Epoch 14/150, Loss: 0.2949\n",
            "Epoch 15/150, Loss: 0.2651\n",
            "Epoch 16/150, Loss: 0.2439\n",
            "Epoch 17/150, Loss: 0.2208\n",
            "Epoch 18/150, Loss: 0.1891\n",
            "Epoch 19/150, Loss: 0.1897\n",
            "Epoch 20/150, Loss: 0.1584\n",
            "Epoch 21/150, Loss: 0.1489\n",
            "Epoch 22/150, Loss: 0.1290\n",
            "Epoch 23/150, Loss: 0.1173\n",
            "Epoch 24/150, Loss: 0.1107\n",
            "Epoch 25/150, Loss: 0.1064\n",
            "Epoch 26/150, Loss: 0.0929\n",
            "Epoch 27/150, Loss: 0.0907\n",
            "Epoch 28/150, Loss: 0.0708\n",
            "Epoch 29/150, Loss: 0.0649\n",
            "Epoch 30/150, Loss: 0.0524\n",
            "Epoch 31/150, Loss: 0.0604\n",
            "Epoch 32/150, Loss: 0.0456\n",
            "Epoch 33/150, Loss: 0.0578\n",
            "Epoch 34/150, Loss: 0.0346\n",
            "Epoch 35/150, Loss: 0.0309\n",
            "Epoch 36/150, Loss: 0.0398\n",
            "Epoch 37/150, Loss: 0.0308\n",
            "Epoch 38/150, Loss: 0.0259\n",
            "Epoch 39/150, Loss: 0.0230\n",
            "Epoch 40/150, Loss: 0.0278\n",
            "Epoch 41/150, Loss: 0.0196\n",
            "Epoch 42/150, Loss: 0.0271\n",
            "Epoch 43/150, Loss: 0.0206\n",
            "Epoch 44/150, Loss: 0.0184\n",
            "Epoch 45/150, Loss: 0.0196\n",
            "Epoch 46/150, Loss: 0.0180\n",
            "Epoch 47/150, Loss: 0.0150\n",
            "Epoch 48/150, Loss: 0.0168\n",
            "Epoch 49/150, Loss: 0.0155\n",
            "Epoch 50/150, Loss: 0.0150\n",
            "Epoch 51/150, Loss: 0.0145\n",
            "Epoch 52/150, Loss: 0.0137\n",
            "Epoch 53/150, Loss: 0.0072\n",
            "Epoch 54/150, Loss: 0.0209\n",
            "Epoch 55/150, Loss: 0.0142\n",
            "Epoch 56/150, Loss: 0.0112\n",
            "Epoch 57/150, Loss: 0.0058\n",
            "Epoch 58/150, Loss: 0.0136\n",
            "Epoch 59/150, Loss: 0.0107\n",
            "Epoch 60/150, Loss: 0.0101\n",
            "Epoch 61/150, Loss: 0.0152\n",
            "Epoch 62/150, Loss: 0.0081\n",
            "Epoch 63/150, Loss: 0.0055\n",
            "Epoch 64/150, Loss: 0.0080\n",
            "Epoch 65/150, Loss: 0.0072\n",
            "Epoch 66/150, Loss: 0.0100\n",
            "Epoch 67/150, Loss: 0.0076\n",
            "Epoch 68/150, Loss: 0.0113\n",
            "Epoch 69/150, Loss: 0.0094\n",
            "Epoch 70/150, Loss: 0.0131\n",
            "Epoch 71/150, Loss: 0.0067\n",
            "Epoch 72/150, Loss: 0.0070\n",
            "Epoch 73/150, Loss: 0.0083\n",
            "Epoch 74/150, Loss: 0.0064\n",
            "Epoch 75/150, Loss: 0.0073\n",
            "Epoch 76/150, Loss: 0.0102\n",
            "Epoch 77/150, Loss: 0.0050\n",
            "Epoch 78/150, Loss: 0.0095\n",
            "Epoch 79/150, Loss: 0.0060\n",
            "Epoch 80/150, Loss: 0.0062\n",
            "Epoch 81/150, Loss: 0.0085\n",
            "Epoch 82/150, Loss: 0.0061\n",
            "Epoch 83/150, Loss: 0.0112\n",
            "Epoch 84/150, Loss: 0.0064\n",
            "Epoch 85/150, Loss: 0.0068\n",
            "Epoch 86/150, Loss: 0.0050\n",
            "Epoch 87/150, Loss: 0.0049\n",
            "Epoch 88/150, Loss: 0.0087\n",
            "Epoch 89/150, Loss: 0.0039\n",
            "Epoch 90/150, Loss: 0.0048\n",
            "Epoch 91/150, Loss: 0.0053\n",
            "Epoch 92/150, Loss: 0.0115\n",
            "Epoch 93/150, Loss: 0.0034\n",
            "Epoch 94/150, Loss: 0.0065\n",
            "Epoch 95/150, Loss: 0.0046\n",
            "Epoch 96/150, Loss: 0.0055\n",
            "Epoch 97/150, Loss: 0.0040\n",
            "Epoch 98/150, Loss: 0.0033\n",
            "Epoch 99/150, Loss: 0.0063\n",
            "Epoch 100/150, Loss: 0.0051\n",
            "Epoch 101/150, Loss: 0.0029\n",
            "Epoch 102/150, Loss: 0.0024\n",
            "Epoch 103/150, Loss: 0.0032\n",
            "Epoch 104/150, Loss: 0.0034\n",
            "Epoch 105/150, Loss: 0.0038\n",
            "Epoch 106/150, Loss: 0.0023\n",
            "Epoch 107/150, Loss: 0.0043\n",
            "Epoch 108/150, Loss: 0.0044\n",
            "Epoch 109/150, Loss: 0.0076\n",
            "Epoch 110/150, Loss: 0.0044\n",
            "Epoch 111/150, Loss: 0.0053\n",
            "Epoch 112/150, Loss: 0.0030\n",
            "Epoch 113/150, Loss: 0.0052\n",
            "Epoch 114/150, Loss: 0.0028\n",
            "Epoch 115/150, Loss: 0.0035\n",
            "Epoch 116/150, Loss: 0.0026\n",
            "Epoch 117/150, Loss: 0.0053\n",
            "Epoch 118/150, Loss: 0.0029\n",
            "Epoch 119/150, Loss: 0.0059\n",
            "Epoch 120/150, Loss: 0.0051\n",
            "Epoch 121/150, Loss: 0.0044\n",
            "Epoch 122/150, Loss: 0.0038\n",
            "Epoch 123/150, Loss: 0.0066\n",
            "Epoch 124/150, Loss: 0.0035\n",
            "Epoch 125/150, Loss: 0.0068\n",
            "Epoch 126/150, Loss: 0.0039\n",
            "Epoch 127/150, Loss: 0.0055\n",
            "Epoch 128/150, Loss: 0.0022\n",
            "Epoch 129/150, Loss: 0.0034\n",
            "Epoch 130/150, Loss: 0.0031\n",
            "Epoch 131/150, Loss: 0.0021\n",
            "Epoch 132/150, Loss: 0.0033\n",
            "Epoch 133/150, Loss: 0.0037\n",
            "Epoch 134/150, Loss: 0.0026\n",
            "Epoch 135/150, Loss: 0.0035\n",
            "Epoch 136/150, Loss: 0.0031\n",
            "Epoch 137/150, Loss: 0.0036\n",
            "Epoch 138/150, Loss: 0.0017\n",
            "Epoch 139/150, Loss: 0.0018\n",
            "Epoch 140/150, Loss: 0.0051\n",
            "Epoch 141/150, Loss: 0.0044\n",
            "Epoch 142/150, Loss: 0.0020\n",
            "Epoch 143/150, Loss: 0.0034\n",
            "Epoch 144/150, Loss: 0.0035\n",
            "Epoch 145/150, Loss: 0.0057\n",
            "Epoch 146/150, Loss: 0.0049\n",
            "Epoch 147/150, Loss: 0.0023\n",
            "Epoch 148/150, Loss: 0.0037\n",
            "Epoch 149/150, Loss: 0.0032\n",
            "Epoch 150/150, Loss: 0.0057\n",
            "Iteration 8/10: 83 anomalies detected by GFCN.\n",
            "Iteration 8/10: Number of Nodes after anomaly removal: 301\n",
            "Evaluating model at iteration 8...\n",
            "Iteration 8 - Evaluation Metrics:\n",
            "Accuracy: 0.8906\n",
            "F1 Score: 0.7879\n",
            "Precision: 0.9398\n",
            "Recall: 0.6783\n",
            "Iteration 9/10: 90 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7295\n",
            "Epoch 2/150, Loss: 0.6680\n",
            "Epoch 3/150, Loss: 0.6167\n",
            "Epoch 4/150, Loss: 0.5639\n",
            "Epoch 5/150, Loss: 0.5218\n",
            "Epoch 6/150, Loss: 0.4826\n",
            "Epoch 7/150, Loss: 0.4277\n",
            "Epoch 8/150, Loss: 0.3973\n",
            "Epoch 9/150, Loss: 0.3778\n",
            "Epoch 10/150, Loss: 0.3431\n",
            "Epoch 11/150, Loss: 0.3272\n",
            "Epoch 12/150, Loss: 0.3012\n",
            "Epoch 13/150, Loss: 0.2664\n",
            "Epoch 14/150, Loss: 0.2549\n",
            "Epoch 15/150, Loss: 0.2172\n",
            "Epoch 16/150, Loss: 0.2032\n",
            "Epoch 17/150, Loss: 0.1773\n",
            "Epoch 18/150, Loss: 0.1607\n",
            "Epoch 19/150, Loss: 0.1458\n",
            "Epoch 20/150, Loss: 0.1312\n",
            "Epoch 21/150, Loss: 0.1172\n",
            "Epoch 22/150, Loss: 0.0964\n",
            "Epoch 23/150, Loss: 0.1025\n",
            "Epoch 24/150, Loss: 0.0844\n",
            "Epoch 25/150, Loss: 0.0700\n",
            "Epoch 26/150, Loss: 0.0762\n",
            "Epoch 27/150, Loss: 0.0633\n",
            "Epoch 28/150, Loss: 0.0527\n",
            "Epoch 29/150, Loss: 0.0496\n",
            "Epoch 30/150, Loss: 0.0401\n",
            "Epoch 31/150, Loss: 0.0356\n",
            "Epoch 32/150, Loss: 0.0305\n",
            "Epoch 33/150, Loss: 0.0317\n",
            "Epoch 34/150, Loss: 0.0190\n",
            "Epoch 35/150, Loss: 0.0311\n",
            "Epoch 36/150, Loss: 0.0340\n",
            "Epoch 37/150, Loss: 0.0305\n",
            "Epoch 38/150, Loss: 0.0220\n",
            "Epoch 39/150, Loss: 0.0156\n",
            "Epoch 40/150, Loss: 0.0197\n",
            "Epoch 41/150, Loss: 0.0237\n",
            "Epoch 42/150, Loss: 0.0143\n",
            "Epoch 43/150, Loss: 0.0107\n",
            "Epoch 44/150, Loss: 0.0184\n",
            "Epoch 45/150, Loss: 0.0181\n",
            "Epoch 46/150, Loss: 0.0105\n",
            "Epoch 47/150, Loss: 0.0131\n",
            "Epoch 48/150, Loss: 0.0123\n",
            "Epoch 49/150, Loss: 0.0169\n",
            "Epoch 50/150, Loss: 0.0125\n",
            "Epoch 51/150, Loss: 0.0077\n",
            "Epoch 52/150, Loss: 0.0066\n",
            "Epoch 53/150, Loss: 0.0128\n",
            "Epoch 54/150, Loss: 0.0092\n",
            "Epoch 55/150, Loss: 0.0105\n",
            "Epoch 56/150, Loss: 0.0159\n",
            "Epoch 57/150, Loss: 0.0119\n",
            "Epoch 58/150, Loss: 0.0056\n",
            "Epoch 59/150, Loss: 0.0068\n",
            "Epoch 60/150, Loss: 0.0075\n",
            "Epoch 61/150, Loss: 0.0069\n",
            "Epoch 62/150, Loss: 0.0035\n",
            "Epoch 63/150, Loss: 0.0141\n",
            "Epoch 64/150, Loss: 0.0079\n",
            "Epoch 65/150, Loss: 0.0072\n",
            "Epoch 66/150, Loss: 0.0099\n",
            "Epoch 67/150, Loss: 0.0037\n",
            "Epoch 68/150, Loss: 0.0062\n",
            "Epoch 69/150, Loss: 0.0101\n",
            "Epoch 70/150, Loss: 0.0041\n",
            "Epoch 71/150, Loss: 0.0074\n",
            "Epoch 72/150, Loss: 0.0055\n",
            "Epoch 73/150, Loss: 0.0041\n",
            "Epoch 74/150, Loss: 0.0082\n",
            "Epoch 75/150, Loss: 0.0038\n",
            "Epoch 76/150, Loss: 0.0036\n",
            "Epoch 77/150, Loss: 0.0039\n",
            "Epoch 78/150, Loss: 0.0046\n",
            "Epoch 79/150, Loss: 0.0061\n",
            "Epoch 80/150, Loss: 0.0032\n",
            "Epoch 81/150, Loss: 0.0056\n",
            "Epoch 82/150, Loss: 0.0050\n",
            "Epoch 83/150, Loss: 0.0061\n",
            "Epoch 84/150, Loss: 0.0043\n",
            "Epoch 85/150, Loss: 0.0064\n",
            "Epoch 86/150, Loss: 0.0035\n",
            "Epoch 87/150, Loss: 0.0057\n",
            "Epoch 88/150, Loss: 0.0079\n",
            "Epoch 89/150, Loss: 0.0050\n",
            "Epoch 90/150, Loss: 0.0027\n",
            "Epoch 91/150, Loss: 0.0059\n",
            "Epoch 92/150, Loss: 0.0026\n",
            "Epoch 93/150, Loss: 0.0066\n",
            "Epoch 94/150, Loss: 0.0065\n",
            "Epoch 95/150, Loss: 0.0055\n",
            "Epoch 96/150, Loss: 0.0089\n",
            "Epoch 97/150, Loss: 0.0049\n",
            "Epoch 98/150, Loss: 0.0036\n",
            "Epoch 99/150, Loss: 0.0050\n",
            "Epoch 100/150, Loss: 0.0098\n",
            "Epoch 101/150, Loss: 0.0031\n",
            "Epoch 102/150, Loss: 0.0022\n",
            "Epoch 103/150, Loss: 0.0071\n",
            "Epoch 104/150, Loss: 0.0029\n",
            "Epoch 105/150, Loss: 0.0065\n",
            "Epoch 106/150, Loss: 0.0059\n",
            "Epoch 107/150, Loss: 0.0110\n",
            "Epoch 108/150, Loss: 0.0058\n",
            "Epoch 109/150, Loss: 0.0061\n",
            "Epoch 110/150, Loss: 0.0046\n",
            "Epoch 111/150, Loss: 0.0022\n",
            "Epoch 112/150, Loss: 0.0060\n",
            "Epoch 113/150, Loss: 0.0021\n",
            "Epoch 114/150, Loss: 0.0070\n",
            "Epoch 115/150, Loss: 0.0020\n",
            "Epoch 116/150, Loss: 0.0015\n",
            "Epoch 117/150, Loss: 0.0040\n",
            "Epoch 118/150, Loss: 0.0039\n",
            "Epoch 119/150, Loss: 0.0019\n",
            "Epoch 120/150, Loss: 0.0050\n",
            "Epoch 121/150, Loss: 0.0050\n",
            "Epoch 122/150, Loss: 0.0055\n",
            "Epoch 123/150, Loss: 0.0025\n",
            "Epoch 124/150, Loss: 0.0063\n",
            "Epoch 125/150, Loss: 0.0060\n",
            "Epoch 126/150, Loss: 0.0043\n",
            "Epoch 127/150, Loss: 0.0038\n",
            "Epoch 128/150, Loss: 0.0076\n",
            "Epoch 129/150, Loss: 0.0015\n",
            "Epoch 130/150, Loss: 0.0059\n",
            "Epoch 131/150, Loss: 0.0023\n",
            "Epoch 132/150, Loss: 0.0039\n",
            "Epoch 133/150, Loss: 0.0033\n",
            "Epoch 134/150, Loss: 0.0020\n",
            "Epoch 135/150, Loss: 0.0026\n",
            "Epoch 136/150, Loss: 0.0041\n",
            "Epoch 137/150, Loss: 0.0023\n",
            "Epoch 138/150, Loss: 0.0046\n",
            "Epoch 139/150, Loss: 0.0033\n",
            "Epoch 140/150, Loss: 0.0033\n",
            "Epoch 141/150, Loss: 0.0020\n",
            "Epoch 142/150, Loss: 0.0085\n",
            "Epoch 143/150, Loss: 0.0054\n",
            "Epoch 144/150, Loss: 0.0020\n",
            "Epoch 145/150, Loss: 0.0038\n",
            "Epoch 146/150, Loss: 0.0015\n",
            "Epoch 147/150, Loss: 0.0048\n",
            "Epoch 148/150, Loss: 0.0008\n",
            "Epoch 149/150, Loss: 0.0021\n",
            "Epoch 150/150, Loss: 0.0016\n",
            "Iteration 9/10: 64 anomalies detected by GFCN.\n",
            "Iteration 9/10: Number of Nodes after anomaly removal: 237\n",
            "Evaluating model at iteration 9...\n",
            "Iteration 9 - Evaluation Metrics:\n",
            "Accuracy: 0.9003\n",
            "F1 Score: 0.8052\n",
            "Precision: 0.9688\n",
            "Recall: 0.6889\n",
            "Iteration 10/10: 71 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6521\n",
            "Epoch 2/150, Loss: 0.5938\n",
            "Epoch 3/150, Loss: 0.5517\n",
            "Epoch 4/150, Loss: 0.5111\n",
            "Epoch 5/150, Loss: 0.4651\n",
            "Epoch 6/150, Loss: 0.4246\n",
            "Epoch 7/150, Loss: 0.3770\n",
            "Epoch 8/150, Loss: 0.3484\n",
            "Epoch 9/150, Loss: 0.3221\n",
            "Epoch 10/150, Loss: 0.2925\n",
            "Epoch 11/150, Loss: 0.2734\n",
            "Epoch 12/150, Loss: 0.2466\n",
            "Epoch 13/150, Loss: 0.2101\n",
            "Epoch 14/150, Loss: 0.1945\n",
            "Epoch 15/150, Loss: 0.1823\n",
            "Epoch 16/150, Loss: 0.1584\n",
            "Epoch 17/150, Loss: 0.1473\n",
            "Epoch 18/150, Loss: 0.1246\n",
            "Epoch 19/150, Loss: 0.0989\n",
            "Epoch 20/150, Loss: 0.0876\n",
            "Epoch 21/150, Loss: 0.0830\n",
            "Epoch 22/150, Loss: 0.0750\n",
            "Epoch 23/150, Loss: 0.0662\n",
            "Epoch 24/150, Loss: 0.0586\n",
            "Epoch 25/150, Loss: 0.0372\n",
            "Epoch 26/150, Loss: 0.0311\n",
            "Epoch 27/150, Loss: 0.0271\n",
            "Epoch 28/150, Loss: 0.0294\n",
            "Epoch 29/150, Loss: 0.0263\n",
            "Epoch 30/150, Loss: 0.0285\n",
            "Epoch 31/150, Loss: 0.0234\n",
            "Epoch 32/150, Loss: 0.0167\n",
            "Epoch 33/150, Loss: 0.0230\n",
            "Epoch 34/150, Loss: 0.0153\n",
            "Epoch 35/150, Loss: 0.0214\n",
            "Epoch 36/150, Loss: 0.0109\n",
            "Epoch 37/150, Loss: 0.0167\n",
            "Epoch 38/150, Loss: 0.0238\n",
            "Epoch 39/150, Loss: 0.0136\n",
            "Epoch 40/150, Loss: 0.0176\n",
            "Epoch 41/150, Loss: 0.0149\n",
            "Epoch 42/150, Loss: 0.0171\n",
            "Epoch 43/150, Loss: 0.0084\n",
            "Epoch 44/150, Loss: 0.0106\n",
            "Epoch 45/150, Loss: 0.0144\n",
            "Epoch 46/150, Loss: 0.0111\n",
            "Epoch 47/150, Loss: 0.0078\n",
            "Epoch 48/150, Loss: 0.0057\n",
            "Epoch 49/150, Loss: 0.0066\n",
            "Epoch 50/150, Loss: 0.0111\n",
            "Epoch 51/150, Loss: 0.0085\n",
            "Epoch 52/150, Loss: 0.0055\n",
            "Epoch 53/150, Loss: 0.0096\n",
            "Epoch 54/150, Loss: 0.0052\n",
            "Epoch 55/150, Loss: 0.0055\n",
            "Epoch 56/150, Loss: 0.0036\n",
            "Epoch 57/150, Loss: 0.0037\n",
            "Epoch 58/150, Loss: 0.0046\n",
            "Epoch 59/150, Loss: 0.0050\n",
            "Epoch 60/150, Loss: 0.0056\n",
            "Epoch 61/150, Loss: 0.0049\n",
            "Epoch 62/150, Loss: 0.0043\n",
            "Epoch 63/150, Loss: 0.0028\n",
            "Epoch 64/150, Loss: 0.0064\n",
            "Epoch 65/150, Loss: 0.0053\n",
            "Epoch 66/150, Loss: 0.0031\n",
            "Epoch 67/150, Loss: 0.0039\n",
            "Epoch 68/150, Loss: 0.0040\n",
            "Epoch 69/150, Loss: 0.0037\n",
            "Epoch 70/150, Loss: 0.0043\n",
            "Epoch 71/150, Loss: 0.0033\n",
            "Epoch 72/150, Loss: 0.0022\n",
            "Epoch 73/150, Loss: 0.0033\n",
            "Epoch 74/150, Loss: 0.0026\n",
            "Epoch 75/150, Loss: 0.0032\n",
            "Epoch 76/150, Loss: 0.0065\n",
            "Epoch 77/150, Loss: 0.0046\n",
            "Epoch 78/150, Loss: 0.0017\n",
            "Epoch 79/150, Loss: 0.0013\n",
            "Epoch 80/150, Loss: 0.0045\n",
            "Epoch 81/150, Loss: 0.0024\n",
            "Epoch 82/150, Loss: 0.0034\n",
            "Epoch 83/150, Loss: 0.0018\n",
            "Epoch 84/150, Loss: 0.0035\n",
            "Epoch 85/150, Loss: 0.0028\n",
            "Epoch 86/150, Loss: 0.0026\n",
            "Epoch 87/150, Loss: 0.0099\n",
            "Epoch 88/150, Loss: 0.0037\n",
            "Epoch 89/150, Loss: 0.0019\n",
            "Epoch 90/150, Loss: 0.0017\n",
            "Epoch 91/150, Loss: 0.0023\n",
            "Epoch 92/150, Loss: 0.0014\n",
            "Epoch 93/150, Loss: 0.0009\n",
            "Epoch 94/150, Loss: 0.0011\n",
            "Epoch 95/150, Loss: 0.0037\n",
            "Epoch 96/150, Loss: 0.0014\n",
            "Epoch 97/150, Loss: 0.0012\n",
            "Epoch 98/150, Loss: 0.0009\n",
            "Epoch 99/150, Loss: 0.0022\n",
            "Epoch 100/150, Loss: 0.0021\n",
            "Epoch 101/150, Loss: 0.0015\n",
            "Epoch 102/150, Loss: 0.0024\n",
            "Epoch 103/150, Loss: 0.0020\n",
            "Epoch 104/150, Loss: 0.0018\n",
            "Epoch 105/150, Loss: 0.0058\n",
            "Epoch 106/150, Loss: 0.0014\n",
            "Epoch 107/150, Loss: 0.0017\n",
            "Epoch 108/150, Loss: 0.0019\n",
            "Epoch 109/150, Loss: 0.0010\n",
            "Epoch 110/150, Loss: 0.0017\n",
            "Epoch 111/150, Loss: 0.0014\n",
            "Epoch 112/150, Loss: 0.0011\n",
            "Epoch 113/150, Loss: 0.0038\n",
            "Epoch 114/150, Loss: 0.0053\n",
            "Epoch 115/150, Loss: 0.0020\n",
            "Epoch 116/150, Loss: 0.0007\n",
            "Epoch 117/150, Loss: 0.0009\n",
            "Epoch 118/150, Loss: 0.0016\n",
            "Epoch 119/150, Loss: 0.0030\n",
            "Epoch 120/150, Loss: 0.0013\n",
            "Epoch 121/150, Loss: 0.0011\n",
            "Epoch 122/150, Loss: 0.0009\n",
            "Epoch 123/150, Loss: 0.0012\n",
            "Epoch 124/150, Loss: 0.0019\n",
            "Epoch 125/150, Loss: 0.0009\n",
            "Epoch 126/150, Loss: 0.0011\n",
            "Epoch 127/150, Loss: 0.0021\n",
            "Epoch 128/150, Loss: 0.0017\n",
            "Epoch 129/150, Loss: 0.0012\n",
            "Epoch 130/150, Loss: 0.0025\n",
            "Epoch 131/150, Loss: 0.0017\n",
            "Epoch 132/150, Loss: 0.0006\n",
            "Epoch 133/150, Loss: 0.0019\n",
            "Epoch 134/150, Loss: 0.0022\n",
            "Epoch 135/150, Loss: 0.0023\n",
            "Epoch 136/150, Loss: 0.0011\n",
            "Epoch 137/150, Loss: 0.0008\n",
            "Epoch 138/150, Loss: 0.0025\n",
            "Epoch 139/150, Loss: 0.0007\n",
            "Epoch 140/150, Loss: 0.0006\n",
            "Epoch 141/150, Loss: 0.0012\n",
            "Epoch 142/150, Loss: 0.0013\n",
            "Epoch 143/150, Loss: 0.0025\n",
            "Epoch 144/150, Loss: 0.0021\n",
            "Epoch 145/150, Loss: 0.0012\n",
            "Epoch 146/150, Loss: 0.0012\n",
            "Epoch 147/150, Loss: 0.0028\n",
            "Epoch 148/150, Loss: 0.0019\n",
            "Epoch 149/150, Loss: 0.0014\n",
            "Epoch 150/150, Loss: 0.0020\n",
            "Iteration 10/10: 50 anomalies detected by GFCN.\n",
            "Iteration 10/10: Number of Nodes after anomaly removal: 187\n",
            "Evaluating model at iteration 10...\n",
            "Iteration 10 - Evaluation Metrics:\n",
            "Accuracy: 0.8776\n",
            "F1 Score: 0.7603\n",
            "Precision: 0.9200\n",
            "Recall: 0.6479\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Evaluation Scores:\n",
            "Iteration 1 - Accuracy: 0.9681, F1 Score: 0.9472, Precision: 0.9416, Recall: 0.9529\n",
            "Iteration 2 - Accuracy: 0.9543, F1 Score: 0.9235, Precision: 0.9262, Recall: 0.9209\n",
            "Iteration 3 - Accuracy: 0.9440, F1 Score: 0.9025, Precision: 0.9461, Recall: 0.8627\n",
            "Iteration 4 - Accuracy: 0.9263, F1 Score: 0.8692, Precision: 0.9293, Recall: 0.8164\n",
            "Iteration 5 - Accuracy: 0.9149, F1 Score: 0.8445, Precision: 0.9349, Recall: 0.7701\n",
            "Iteration 6 - Accuracy: 0.9145, F1 Score: 0.8400, Precision: 0.9608, Recall: 0.7462\n",
            "Iteration 7 - Accuracy: 0.9104, F1 Score: 0.8327, Precision: 0.9492, Recall: 0.7417\n",
            "Iteration 8 - Accuracy: 0.8906, F1 Score: 0.7879, Precision: 0.9398, Recall: 0.6783\n",
            "Iteration 9 - Accuracy: 0.9003, F1 Score: 0.8052, Precision: 0.9688, Recall: 0.6889\n",
            "Iteration 10 - Accuracy: 0.8776, F1 Score: 0.7603, Precision: 0.9200, Recall: 0.6479\n"
          ]
        }
      ],
      "source": [
        "#print(f\"Initial Number of Nodes: {cora_data.num_nodes}\")\n",
        "#node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_cora_from_drive(),node_embeddings, 10)\n",
        "#node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_pubmed_from_drive(),node_embeddings, 10)\n",
        "node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_citeseer_from_drive(),node_embeddings, 10)\n",
        "#node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_snap_from_drive(),node_embeddings, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyzQGdmtDPV2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}