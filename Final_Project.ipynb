{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SecretPasta/DAGFCN/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-IjW5iWDv5j"
      },
      "source": [
        "# Prerequisites\n",
        "Clean installing pytorch depenedencies for Node2Vec, and doing Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ptX90PqAoPj",
        "outputId": "2fd5be08-c7df-4d14-8ba2-cf3aadd926e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-spline-conv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch-scatter torch-sparse torch-cluster torch-spline-conv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkLyGwH5Arus",
        "outputId": "6e96db49-7e8a-4884-b9b0-5f9cbac86267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)  # Should match the version in the installation instructions\n",
        "print(torch.version.cuda)  # Ensure this matches the target version (e.g., '11.8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W497zhfqYLH",
        "outputId": "53ec4e2f-1eaf-4db0-84d2-48f898bf5212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m991.6/991.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Required installations for PyTorch Geometric\n",
        "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.5.1+cu121.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2cVZ31UBtpk",
        "outputId": "3bc06d30-e01d-4d57-abfd-965fc40ac240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All required libraries are installed and working!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import torch_cluster\n",
        "    import torch_spline_conv\n",
        "    print(\"All required libraries are installed and working!\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8oAkfbaA6xO",
        "outputId": "3dfba399-cca1-4824-c987-84e2c32b988f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA version: 12.1\n",
            "PyTorch Geometric is successfully installed!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import Node2Vec\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(\"PyTorch Geometric is successfully installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SBuwTE68qYIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488ae3dc-8ca3-48fb-986a-88cf4ddb4949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.datasets import CoraFull\n",
        "from torch_geometric.nn import Node2Vec\n",
        "from torch_geometric.utils import to_torch_csr_tensor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(torch.cuda.is_available())  # Should return True\n",
        "print(torch.cuda.get_device_name(0))  # Should display T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lWG090XtqYGb"
      },
      "outputs": [],
      "source": [
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl_CYE9BEEbN"
      },
      "source": [
        "# Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6-9cR6NZdFT",
        "outputId": "7ad088c8-3a51-452f-8acf-3bce446759fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpHAhR4B2uZc"
      },
      "source": [
        "Loading CoraFull dataset from torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xfkPghvPqYDy"
      },
      "outputs": [],
      "source": [
        "def load_cora_dataset(save_path=\"/content/drive/My Drive/Dataset/CoraFull_saved.pt\"):\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = CoraFull(root='./data/CoraFull')\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Specify the save path in Google Drive\n",
        "save_path = \"/content/drive/My Drive/Dataset/CoraFull_saved.pt\"\n",
        "\n",
        "# Load and save the dataset\n",
        "#data = load_cora_dataset(save_path=save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAY4sSJe2vwX"
      },
      "source": [
        "Loading Pubmed dataset from torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PgKQIWjiaW6M"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "def load_and_save_pubmed(save_path=\"/content/drive/My Drive/Dataset/Pubmed_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the Pubmed dataset, print its statistics, and save it to Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        save_path (str): The file path to save the dataset in Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded dataset.\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the Pubmed dataset\n",
        "    dataset = Planetoid(root='./data/Pubmed', name='Pubmed')\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Specify the save path in Google Drive\n",
        "save_path = \"/content/drive/My Drive/Dataset/Pubmed_saved.pt\"\n",
        "\n",
        "# Load and save the Pubmed dataset\n",
        "#data = load_and_save_pubmed(save_path=save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading CiteSeer from torch.geometric"
      ],
      "metadata": {
        "id": "mWpWIXPE7BLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_save_citeseer(save_path=\"/content/drive/My Drive/Dataset/CiteSeer_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the Pubmed dataset, print its statistics, and save it to Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        save_path (str): The file path to save the dataset in Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded dataset.\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the Pubmed dataset\n",
        "    dataset = Planetoid(root='./data/CiteSeer', name='CiteSeer')\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Specify the save path in Google Drive\n",
        "save_path = \"/content/drive/My Drive/Dataset/CiteSeer_saved.pt\"\n",
        "\n",
        "# Load and save the Pubmed dataset\n",
        "data = load_and_save_citeseer(save_path=save_path)"
      ],
      "metadata": {
        "id": "dX2M6XGX2-xU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4d3c8e-b235-4f3e-a3b1-b7d3a890558e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: CiteSeer()\n",
            "Number of nodes: 3327\n",
            "Number of edges: 9104\n",
            "Number of features: 3703\n",
            "Number of classes: 6\n",
            "Dataset size: 0.0461 GB\n",
            "Dataset saved to: /content/drive/My Drive/Dataset/CiteSeer_saved.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThmjywToAB9i"
      },
      "source": [
        "Loading SANP from torch.geometric\n",
        "\n",
        "Available datasets are: ['ego-facebook', 'ego-gplus', 'ego-twitter', 'soc-ca-astroph', 'soc-ca-grqc', 'soc-epinions1', 'soc-livejournal1', 'soc-pokec', 'soc-slashdot0811', 'soc-slashdot0922', 'wiki-vote']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NBOj8xHw7yFB"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "def load_and_save_snap(save_path=\"/content/drive/My Drive/Dataset/SNAP_saved.pt\", dataset_name=None):\n",
        "    \"\"\"\n",
        "    Load a SNAP dataset, print its statistics, and save it to Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        save_path (str): The file path to save the dataset in Google Drive.\n",
        "        dataset_name (str): The name of the SNAP dataset to load.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded dataset.\n",
        "    \"\"\"\n",
        "    # Check available datasets\n",
        "    available_datasets = SNAPDataset.available_datasets.keys()\n",
        "    if dataset_name is None or dataset_name.lower() not in available_datasets:\n",
        "        print(f\"Invalid or missing dataset name! Available datasets are: {list(available_datasets)}\")\n",
        "        return None\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Load the SNAP dataset\n",
        "    dataset = SNAPDataset(root='./data/SNAP', name=dataset_name)\n",
        "    data = dataset[0]\n",
        "\n",
        "    # Calculate the memory usage of the dataset in bytes\n",
        "    memory_usage = 0\n",
        "    for key, value in data:\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            memory_usage += value.element_size() * value.numel()\n",
        "\n",
        "    # Convert memory usage to GB\n",
        "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
        "\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features if 'x' in data else 'N/A'}\")\n",
        "    print(f\"Number of classes: {dataset.num_classes if hasattr(dataset, 'num_classes') else 'N/A'}\")\n",
        "    print(f\"Dataset size: {memory_usage_gb:.4f} GB\")\n",
        "\n",
        "    # Save the dataset to the specified path in Google Drive\n",
        "    torch.save(data, save_path)\n",
        "    print(f\"Dataset saved to: {save_path}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "#data = load_and_save_snap(dataset_name=\"soc-ca-astroph\")  # Choose Dataset from the list above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SauxG-2z2zSS"
      },
      "source": [
        "Load the datasets from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yjTE4oo1bXZ_"
      },
      "outputs": [],
      "source": [
        "def load_cora_from_drive(load_path=\"/content/drive/My Drive/Dataset/CoraFull_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the saved Cora dataset from Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        load_path (str): The file path to load the Cora dataset from Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded Cora dataset.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"Cora dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "#data = load_cora_from_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MLhGD16YbXTd"
      },
      "outputs": [],
      "source": [
        "def load_pubmed_from_drive(load_path=\"/content/drive/My Drive/Dataset/Pubmed_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the saved Pubmed dataset from Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        load_path (str): The file path to load the Pubmed dataset from Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded Pubmed dataset.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"Pubmed dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "\n",
        "#data = load_pubmed_from_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_citeseer_from_drive(load_path=\"/content/drive/My Drive/Dataset/CiteSeer_saved.pt\"):\n",
        "    \"\"\"\n",
        "    Load the saved CiteSeer dataset from Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        load_path (str): The file path to load the CiteSeer dataset from Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: The loaded CiteSeer dataset.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"CiteSeer dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "\n",
        "data = load_citeseer_from_drive()"
      ],
      "metadata": {
        "id": "2gU5Sx2S3Qgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b090619-b332-4fc1-95e4-32868d4b5da2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CiteSeer dataset loaded successfully from /content/drive/My Drive/Dataset/CiteSeer_saved.pt.\n",
            "Number of nodes: 3327\n",
            "Number of edges: 9104\n",
            "Number of features: 3703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-0be661a40b06>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(load_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yOc9J9Ke3184"
      },
      "outputs": [],
      "source": [
        "def load_snap_from_drive(load_path=\"/content/drive/My Drive/Dataset/SNAP_saved.pt\", name=\"CiteSeer\"):\n",
        "    if not os.path.exists(load_path):\n",
        "        raise FileNotFoundError(f\"The file at {load_path} does not exist. Please ensure it is saved correctly.\")\n",
        "\n",
        "    data = torch.load(load_path)\n",
        "    print(f\"SNAP dataset loaded successfully from {load_path}.\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.num_edges}\")\n",
        "    print(f\"Number of features: {data.num_features}\")\n",
        "    return data\n",
        "\n",
        "#data = load_snap_from_drive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsUpRlrHERzf"
      },
      "source": [
        "# Node2Vec\n",
        "\n",
        "Passing in the dataset to generate node embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "z1DDkT46CuOv"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 128\n",
        "walk_length = 20\n",
        "context_size = 10\n",
        "walks_per_node=10\n",
        "num_negative_samples=1\n",
        "p=0.5\n",
        "q=0.25\n",
        "sparse=True\n",
        "n2v_lr=0.01 #learning rate\n",
        "n2v_bs=128 #batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJmfZ4OVqYAw",
        "outputId": "836d98c4-e49c-4a81-c74c-32a3413bbd8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 7.5758\n",
            "Epoch 2/10, Loss: 5.4070\n",
            "Epoch 3/10, Loss: 4.4689\n",
            "Epoch 4/10, Loss: 3.7879\n",
            "Epoch 5/10, Loss: 3.2319\n",
            "Epoch 6/10, Loss: 2.7796\n",
            "Epoch 7/10, Loss: 2.4111\n",
            "Epoch 8/10, Loss: 2.1057\n",
            "Epoch 9/10, Loss: 1.8598\n",
            "Epoch 10/10, Loss: 1.6633\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Node2Vec for Embedding Initialization\n",
        "node2vec = Node2Vec(\n",
        "    edge_index=data.edge_index,\n",
        "    embedding_dim=embedding_dim,\n",
        "    walk_length=walk_length,\n",
        "    context_size=context_size,\n",
        "    walks_per_node=walks_per_node,\n",
        "    num_negative_samples=num_negative_samples,\n",
        "    p=p, q=q,\n",
        "    sparse=sparse\n",
        ").to(device)\n",
        "\n",
        "node2vec_optimizer = torch.optim.SparseAdam(node2vec.parameters(), lr=n2v_lr)\n",
        "node2vec_loader = node2vec.loader(batch_size=n2v_bs, shuffle=True)\n",
        "\n",
        "def train_node2vec(epochs=10):\n",
        "    node2vec.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for pos_rw, neg_rw in node2vec_loader:\n",
        "            node2vec_optimizer.zero_grad()\n",
        "            loss = node2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "            loss.backward()\n",
        "            node2vec_optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(node2vec_loader):.4f}\")\n",
        "\n",
        "train_node2vec(epochs=10)\n",
        "\n",
        "# Extract embeddings\n",
        "node_embeddings = node2vec().detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4G8jl30E3Qj"
      },
      "source": [
        "# Isolation Forest\n",
        "\n",
        "Passing in the Node Embeddings into the Isolation forest to isolate anamolies within the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "v8Au4MYYE_ql"
      },
      "outputs": [],
      "source": [
        "def isolation_forest(node_embeddings, n_estimators=150, contamination=0.2):\n",
        "    \"\"\"\n",
        "    Detect anomalies in node embeddings using Isolation Forest.\n",
        "\n",
        "    Parameters:\n",
        "        node_embeddings (numpy.ndarray): A 2D array where each row represents the embedding of a node.\n",
        "        n_estimators (int): Number of trees in the Isolation Forest. Default is 100.\n",
        "        contamination (float): The proportion of anomalies in the data. Default is 0.1.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            numpy.ndarray: Labels array where 1 indicates an anomaly and 0 indicates normal.\n",
        "            numpy.ndarray: Anomaly mask where True indicates an anomaly and False indicates normal.\n",
        "    \"\"\"\n",
        "    # Initialize the Isolation Forest model\n",
        "    isolation_model = IsolationForest(\n",
        "        n_estimators=n_estimators,\n",
        "        contamination=contamination,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit the model to the node embeddings\n",
        "    isolation_model.fit(node_embeddings)\n",
        "\n",
        "    # Predict anomaly labels: 1 for normal, -1 for anomaly\n",
        "    labels = isolation_model.predict(node_embeddings)\n",
        "\n",
        "    # Create an anomaly mask: True for anomalies, False for normal points\n",
        "    anomaly_mask = labels == -1\n",
        "\n",
        "    # Adjust labels to binary format: -1 (anomaly) -> 1, 1 (normal) -> 0\n",
        "    labels = anomaly_mask.astype(int)\n",
        "\n",
        "    return labels, anomaly_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MHcQkuvFAUC"
      },
      "source": [
        "# GFCN\n",
        "\n",
        "Defining the Graph Fairing Convolutional Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eDn2mcddtxZx"
      },
      "outputs": [],
      "source": [
        "# Step 3: Graph Fairing Convolutional Network (GFCN)\n",
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.FloatTensor(out_features)) if bias else None\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        support = torch.mm(x, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output += self.bias\n",
        "        return output\n",
        "\n",
        "class GFCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "        super(GFCN, self).__init__()\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nhid)\n",
        "        self.gc3 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu(self.gc2(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc3(x, adj)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xo7s8MYFIYRT"
      },
      "outputs": [],
      "source": [
        "def gfcn(data, node_embeddings, anomaly_mask, device='cuda', epochs=150, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Trains a Graph Fairing Convolutional Network (GFCN) on the given data and returns node labels.\n",
        "\n",
        "    Parameters:\n",
        "        data (torch_geometric.data.Data): The graph data containing edge_index and num_nodes.\n",
        "        node_embeddings (numpy.ndarray): Node embeddings as input features.\n",
        "        anomaly_mask (numpy.ndarray): Boolean mask indicating anomalies (True = anomaly).\n",
        "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
        "        epochs (int): Number of training epochs. Default is 100.\n",
        "        train_ratio (float): Ratio of training nodes to total nodes. Default is 0.8.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Predicted labels for all nodes (0 = normal, 1 = anomaly).\n",
        "    \"\"\"\n",
        "    # Convert node_embeddings and anomaly_mask to PyTorch tensors\n",
        "    features = torch.tensor(node_embeddings, dtype=torch.float32, device=device)\n",
        "    labels = torch.tensor(anomaly_mask.astype(int), dtype=torch.long, device=device)\n",
        "\n",
        "    # Convert edge_index to a PyTorch sparse tensor\n",
        "    adj = to_torch_csr_tensor(data.edge_index, size=(data.num_nodes, data.num_nodes)).to(device)\n",
        "\n",
        "    # Train/Test split\n",
        "    num_nodes = data.num_nodes\n",
        "    num_train = int(train_ratio * num_nodes)\n",
        "    idx_train = torch.arange(num_train, device=device)\n",
        "    idx_test = torch.arange(num_train, num_nodes, device=device)\n",
        "\n",
        "    # Define the GFCN model\n",
        "    class GFCN(nn.Module):\n",
        "        def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "            super(GFCN, self).__init__()\n",
        "            self.gc1 = nn.Linear(nfeat, nhid)\n",
        "            self.gc2 = nn.Linear(nhid, nclass)\n",
        "            self.dropout = dropout\n",
        "\n",
        "        def forward(self, x, adj):\n",
        "            x = torch.relu(self.gc1(x))\n",
        "            x = torch.dropout(x, p=self.dropout, train=self.training)\n",
        "            x = self.gc2(x)\n",
        "            return x\n",
        "\n",
        "    # Model and optimizer\n",
        "    gcn = GFCN(nfeat=features.shape[1], nhid=64, nclass=2, dropout=0.5).to(device)\n",
        "    optimizer = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training the model\n",
        "    def train_gfcn(epochs):\n",
        "        gcn.train()\n",
        "        for epoch in range(epochs):\n",
        "            optimizer.zero_grad()\n",
        "            output = gcn(features, adj)\n",
        "            loss = criterion(output[idx_train], labels[idx_train])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_gfcn(epochs)\n",
        "\n",
        "    # Evaluation: Predict labels for all nodes\n",
        "    gcn.eval()\n",
        "    with torch.no_grad():\n",
        "        output = gcn(features, adj)\n",
        "        predictions = torch.argmax(output, dim=1)  # Predicted labels\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OWXMrJK0BH1n"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(data, node_embeddings, true_labels, predicted_labels, iteration):\n",
        "    \"\"\"\n",
        "    Evaluate the model at the end of each iteration.\n",
        "\n",
        "    Parameters:\n",
        "        data (torch_geometric.data.Data): The graph data containing edge_index and num_nodes.\n",
        "        node_embeddings (numpy.ndarray): Current node embeddings.\n",
        "        true_labels (numpy.ndarray): True labels of the nodes (1 for anomaly, 0 for normal).\n",
        "        predicted_labels (numpy.ndarray): Predicted labels from the GFCN (1 for anomaly, 0 for normal).\n",
        "        iteration (int): The current iteration number.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing evaluation metrics.\n",
        "    \"\"\"\n",
        "    print(f\"Evaluating model at iteration {iteration}...\")\n",
        "\n",
        "    # Calculate evaluation metrics manually\n",
        "    true_positives = np.sum((true_labels == 1) & (predicted_labels == 1))\n",
        "    true_negatives = np.sum((true_labels == 0) & (predicted_labels == 0))\n",
        "    false_positives = np.sum((true_labels == 0) & (predicted_labels == 1))\n",
        "    false_negatives = np.sum((true_labels == 1) & (predicted_labels == 0))\n",
        "\n",
        "    accuracy = (true_positives + true_negatives) / len(true_labels)\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    print(f\"Iteration {iteration} - Evaluation Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vX8UBAccBH8x"
      },
      "outputs": [],
      "source": [
        "def remove_nodes(data, node_indices):\n",
        "    \"\"\"\n",
        "    Remove nodes from graph data.\n",
        "\n",
        "    Parameters:\n",
        "        data (torch_geometric.data.Data): The graph data containing edge_index and num_nodes.\n",
        "        node_indices (numpy.ndarray): Indices of nodes to remove.\n",
        "\n",
        "    Returns:\n",
        "        torch_geometric.data.Data: Updated graph data with specified nodes removed.\n",
        "    \"\"\"\n",
        "    mask = np.ones(data.num_nodes, dtype=bool)\n",
        "    mask[node_indices[node_indices < data.num_nodes]] = False  # Ensure indices are within bounds\n",
        "\n",
        "    data.x = data.x[mask]\n",
        "\n",
        "    # Filter edges based on the updated node mask\n",
        "    edge_index_cpu = data.edge_index.cpu().numpy()\n",
        "    edge_index_cpu = edge_index_cpu[:, (edge_index_cpu[0] < mask.size) & (edge_index_cpu[1] < mask.size)]  # Ensure edge indices are within bounds\n",
        "    edge_mask = mask[edge_index_cpu[0]] & mask[edge_index_cpu[1]]\n",
        "    data.edge_index = torch.tensor(edge_index_cpu[:, edge_mask], dtype=torch.long, device=data.edge_index.device)\n",
        "\n",
        "    data.num_nodes = mask.sum()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXCz_Kzv7Pxw",
        "outputId": "660e421c-3c95-4cd2-90fc-5c8231d2c978"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a Folder for the experiments"
      ],
      "metadata": {
        "id": "LT-64kBz6b7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a folder\n",
        "def create_folder_in_drive(base_path, folder_name):\n",
        "    \"\"\"\n",
        "    Create a folder in a specified path in Google Drive.\n",
        "\n",
        "    :param base_path: The base path where the folder will be created (str)\n",
        "    :param folder_name: The name of the folder to create (str)\n",
        "    :return: Full path of the created folder (str)\n",
        "    \"\"\"\n",
        "    # Combine base path and folder name\n",
        "    folder_path = os.path.join(base_path, folder_name)\n",
        "\n",
        "    # Create the folder if it doesn't exist\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "        print(f\"Folder created: {folder_path}\")\n",
        "    else:\n",
        "        print(f\"Folder already exists: {folder_path}\")\n",
        "\n",
        "    return folder_path\n",
        "\n",
        "# Specify the base path in Google Drive\n",
        "base_path = '/content/drive/MyDrive/Final Project - Boris & Omri/Experiments'\n",
        "\n",
        "# Specify the folder name\n",
        "folder_name = 'CiteSeer'\n",
        "\n",
        "# Create the folder\n",
        "output_folder  = create_folder_in_drive(base_path, folder_name)\n",
        "print(f\"Folder path: {output_folder }\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3hPEVq6eiv",
        "outputId": "8bf58e07-a6f9-41ff-ed25-55880da47109"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder already exists: /content/drive/MyDrive/Final Project - Boris & Omri/Experiments/CiteSeer\n",
            "Folder path: /content/drive/MyDrive/Final Project - Boris & Omri/Experiments/CiteSeer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "INIb4MVnKG2m"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def iterative_anomaly_detection(data, node_embeddings, K, device='cuda'):\n",
        "    evaluation_scores = []\n",
        "    removed_nodes_per_iteration = []  # Track nodes removed in each iteration\n",
        "\n",
        "    print(f\"Initial Number of Nodes: {data.num_nodes}\")\n",
        "    for iteration in range(K):\n",
        "        # Step 1: Apply Isolation Forest to detect anomalies\n",
        "        labels, anomaly_mask = isolation_forest(node_embeddings, 50, 0.3)\n",
        "        num_anomalies_iforest = np.sum(anomaly_mask)\n",
        "        print(f\"Iteration {iteration + 1}/{K}: {num_anomalies_iforest} anomalies detected by Isolation Forest.\")\n",
        "\n",
        "        # Step 2: Apply GFCN to classify anomalies\n",
        "        predictions = gfcn(data, node_embeddings, anomaly_mask, device=device)\n",
        "        anomaly_indices = np.where(predictions.cpu().numpy() == 1)[0]\n",
        "        num_anomalies_gfcn = len(anomaly_indices)\n",
        "        print(f\"Iteration {iteration + 1}/{K}: {num_anomalies_gfcn} anomalies detected by GFCN.\")\n",
        "\n",
        "        if num_anomalies_gfcn == 0:\n",
        "            print(\"No anomalies detected by GFCN. Stopping iteration.\")\n",
        "            break\n",
        "\n",
        "        anomaly_indices = anomaly_indices[anomaly_indices < node_embeddings.shape[0]]\n",
        "        removed_nodes_per_iteration.append(anomaly_indices.tolist())\n",
        "        node_embeddings = np.delete(node_embeddings, anomaly_indices, axis=0)\n",
        "        data = remove_nodes(data, anomaly_indices)\n",
        "        print(f\"Iteration {iteration + 1}/{K}: Number of Nodes after anomaly removal: {data.num_nodes}\")\n",
        "\n",
        "        scores = evaluate_model(data, node_embeddings, labels, predictions.cpu().numpy(), iteration + 1)\n",
        "        evaluation_scores.append(scores)\n",
        "\n",
        "    # Plot the final evaluation scores\n",
        "    iterations = range(1, len(evaluation_scores) + 1)\n",
        "    accuracies = [score[\"accuracy\"] for score in evaluation_scores]\n",
        "    f1_scores = [score[\"f1\"] for score in evaluation_scores]\n",
        "    precisions = [score[\"precision\"] for score in evaluation_scores]\n",
        "    recalls = [score[\"recall\"] for score in evaluation_scores]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(iterations, accuracies, label='Accuracy', marker='o')\n",
        "    plt.plot(iterations, f1_scores, label='F1 Score', marker='o')\n",
        "    plt.plot(iterations, precisions, label='Precision', marker='o')\n",
        "    plt.plot(iterations, recalls, label='Recall', marker='o')\n",
        "\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Evaluation Scores Across Iterations')\n",
        "    plt.xticks(iterations)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save the plot to the output folder\n",
        "    plot_path = os.path.join(output_folder, 'evaluation_scores_plot.png')\n",
        "    plt.savefig(plot_path)\n",
        "    print(f\"Plot saved to {plot_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Save removed nodes per iteration to a CSV file\n",
        "    csv_path = os.path.join(output_folder, 'removed_nodes_per_iteration.csv')\n",
        "    removed_nodes_df = pd.DataFrame({'Iteration': range(1, len(removed_nodes_per_iteration) + 1),\n",
        "                                     'RemovedNodes': removed_nodes_per_iteration})\n",
        "    removed_nodes_df.to_csv(csv_path, index=False)\n",
        "    print(f\"Removed nodes saved to {csv_path}\")\n",
        "\n",
        "    # Print final evaluation scores\n",
        "    print(\"\\nFinal Evaluation Scores:\")\n",
        "    for i, scores in enumerate(evaluation_scores, 1):\n",
        "        print(f\"Iteration {i} - Accuracy: {scores['accuracy']:.4f}, F1 Score: {scores['f1']:.4f}, Precision: {scores['precision']:.4f}, Recall: {scores['recall']:.4f}\")\n",
        "\n",
        "    return node_embeddings, removed_nodes_per_iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iwamUqhKKJsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "011d4a8e-63c4-4456-8215-12ecee588294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-0be661a40b06>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(load_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CiteSeer dataset loaded successfully from /content/drive/My Drive/Dataset/CiteSeer_saved.pt.\n",
            "Number of nodes: 3327\n",
            "Number of edges: 9104\n",
            "Number of features: 3703\n",
            "Initial Number of Nodes: 3327\n",
            "Iteration 1/10: 998 anomalies detected by Isolation Forest.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/sparse.py:277: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  adj = torch.sparse_csr_tensor(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150, Loss: 0.7016\n",
            "Epoch 2/150, Loss: 0.6574\n",
            "Epoch 3/150, Loss: 0.6258\n",
            "Epoch 4/150, Loss: 0.6051\n",
            "Epoch 5/150, Loss: 0.5854\n",
            "Epoch 6/150, Loss: 0.5779\n",
            "Epoch 7/150, Loss: 0.5538\n",
            "Epoch 8/150, Loss: 0.5414\n",
            "Epoch 9/150, Loss: 0.5327\n",
            "Epoch 10/150, Loss: 0.5150\n",
            "Epoch 11/150, Loss: 0.5112\n",
            "Epoch 12/150, Loss: 0.4915\n",
            "Epoch 13/150, Loss: 0.4801\n",
            "Epoch 14/150, Loss: 0.4645\n",
            "Epoch 15/150, Loss: 0.4516\n",
            "Epoch 16/150, Loss: 0.4315\n",
            "Epoch 17/150, Loss: 0.4174\n",
            "Epoch 18/150, Loss: 0.4014\n",
            "Epoch 19/150, Loss: 0.3899\n",
            "Epoch 20/150, Loss: 0.3727\n",
            "Epoch 21/150, Loss: 0.3569\n",
            "Epoch 22/150, Loss: 0.3419\n",
            "Epoch 23/150, Loss: 0.3368\n",
            "Epoch 24/150, Loss: 0.3219\n",
            "Epoch 25/150, Loss: 0.3283\n",
            "Epoch 26/150, Loss: 0.3024\n",
            "Epoch 27/150, Loss: 0.2928\n",
            "Epoch 28/150, Loss: 0.2852\n",
            "Epoch 29/150, Loss: 0.2797\n",
            "Epoch 30/150, Loss: 0.2871\n",
            "Epoch 31/150, Loss: 0.2485\n",
            "Epoch 32/150, Loss: 0.2517\n",
            "Epoch 33/150, Loss: 0.2379\n",
            "Epoch 34/150, Loss: 0.2373\n",
            "Epoch 35/150, Loss: 0.2428\n",
            "Epoch 36/150, Loss: 0.2378\n",
            "Epoch 37/150, Loss: 0.2315\n",
            "Epoch 38/150, Loss: 0.2303\n",
            "Epoch 39/150, Loss: 0.2222\n",
            "Epoch 40/150, Loss: 0.2034\n",
            "Epoch 41/150, Loss: 0.2028\n",
            "Epoch 42/150, Loss: 0.1958\n",
            "Epoch 43/150, Loss: 0.2044\n",
            "Epoch 44/150, Loss: 0.1918\n",
            "Epoch 45/150, Loss: 0.1895\n",
            "Epoch 46/150, Loss: 0.1998\n",
            "Epoch 47/150, Loss: 0.1946\n",
            "Epoch 48/150, Loss: 0.1751\n",
            "Epoch 49/150, Loss: 0.1835\n",
            "Epoch 50/150, Loss: 0.1913\n",
            "Epoch 51/150, Loss: 0.1867\n",
            "Epoch 52/150, Loss: 0.1729\n",
            "Epoch 53/150, Loss: 0.1785\n",
            "Epoch 54/150, Loss: 0.1712\n",
            "Epoch 55/150, Loss: 0.1699\n",
            "Epoch 56/150, Loss: 0.1694\n",
            "Epoch 57/150, Loss: 0.1637\n",
            "Epoch 58/150, Loss: 0.1588\n",
            "Epoch 59/150, Loss: 0.1578\n",
            "Epoch 60/150, Loss: 0.1579\n",
            "Epoch 61/150, Loss: 0.1528\n",
            "Epoch 62/150, Loss: 0.1503\n",
            "Epoch 63/150, Loss: 0.1590\n",
            "Epoch 64/150, Loss: 0.1460\n",
            "Epoch 65/150, Loss: 0.1544\n",
            "Epoch 66/150, Loss: 0.1431\n",
            "Epoch 67/150, Loss: 0.1358\n",
            "Epoch 68/150, Loss: 0.1536\n",
            "Epoch 69/150, Loss: 0.1446\n",
            "Epoch 70/150, Loss: 0.1383\n",
            "Epoch 71/150, Loss: 0.1450\n",
            "Epoch 72/150, Loss: 0.1432\n",
            "Epoch 73/150, Loss: 0.1547\n",
            "Epoch 74/150, Loss: 0.1411\n",
            "Epoch 75/150, Loss: 0.1421\n",
            "Epoch 76/150, Loss: 0.1223\n",
            "Epoch 77/150, Loss: 0.1263\n",
            "Epoch 78/150, Loss: 0.1317\n",
            "Epoch 79/150, Loss: 0.1345\n",
            "Epoch 80/150, Loss: 0.1239\n",
            "Epoch 81/150, Loss: 0.1271\n",
            "Epoch 82/150, Loss: 0.1335\n",
            "Epoch 83/150, Loss: 0.1210\n",
            "Epoch 84/150, Loss: 0.1140\n",
            "Epoch 85/150, Loss: 0.1154\n",
            "Epoch 86/150, Loss: 0.1187\n",
            "Epoch 87/150, Loss: 0.1225\n",
            "Epoch 88/150, Loss: 0.1203\n",
            "Epoch 89/150, Loss: 0.1298\n",
            "Epoch 90/150, Loss: 0.1109\n",
            "Epoch 91/150, Loss: 0.1188\n",
            "Epoch 92/150, Loss: 0.1189\n",
            "Epoch 93/150, Loss: 0.1075\n",
            "Epoch 94/150, Loss: 0.1176\n",
            "Epoch 95/150, Loss: 0.1073\n",
            "Epoch 96/150, Loss: 0.1141\n",
            "Epoch 97/150, Loss: 0.1122\n",
            "Epoch 98/150, Loss: 0.0973\n",
            "Epoch 99/150, Loss: 0.1078\n",
            "Epoch 100/150, Loss: 0.1020\n",
            "Epoch 101/150, Loss: 0.1074\n",
            "Epoch 102/150, Loss: 0.1101\n",
            "Epoch 103/150, Loss: 0.1000\n",
            "Epoch 104/150, Loss: 0.0988\n",
            "Epoch 105/150, Loss: 0.0968\n",
            "Epoch 106/150, Loss: 0.0990\n",
            "Epoch 107/150, Loss: 0.1061\n",
            "Epoch 108/150, Loss: 0.1053\n",
            "Epoch 109/150, Loss: 0.1054\n",
            "Epoch 110/150, Loss: 0.0986\n",
            "Epoch 111/150, Loss: 0.1156\n",
            "Epoch 112/150, Loss: 0.0954\n",
            "Epoch 113/150, Loss: 0.0967\n",
            "Epoch 114/150, Loss: 0.0891\n",
            "Epoch 115/150, Loss: 0.1059\n",
            "Epoch 116/150, Loss: 0.0944\n",
            "Epoch 117/150, Loss: 0.0846\n",
            "Epoch 118/150, Loss: 0.0962\n",
            "Epoch 119/150, Loss: 0.0910\n",
            "Epoch 120/150, Loss: 0.1086\n",
            "Epoch 121/150, Loss: 0.0780\n",
            "Epoch 122/150, Loss: 0.0944\n",
            "Epoch 123/150, Loss: 0.0899\n",
            "Epoch 124/150, Loss: 0.0824\n",
            "Epoch 125/150, Loss: 0.0898\n",
            "Epoch 126/150, Loss: 0.0847\n",
            "Epoch 127/150, Loss: 0.0955\n",
            "Epoch 128/150, Loss: 0.0919\n",
            "Epoch 129/150, Loss: 0.0875\n",
            "Epoch 130/150, Loss: 0.0821\n",
            "Epoch 131/150, Loss: 0.0769\n",
            "Epoch 132/150, Loss: 0.0888\n",
            "Epoch 133/150, Loss: 0.0934\n",
            "Epoch 134/150, Loss: 0.0810\n",
            "Epoch 135/150, Loss: 0.0844\n",
            "Epoch 136/150, Loss: 0.0711\n",
            "Epoch 137/150, Loss: 0.0884\n",
            "Epoch 138/150, Loss: 0.0809\n",
            "Epoch 139/150, Loss: 0.0885\n",
            "Epoch 140/150, Loss: 0.0825\n",
            "Epoch 141/150, Loss: 0.0821\n",
            "Epoch 142/150, Loss: 0.0781\n",
            "Epoch 143/150, Loss: 0.0873\n",
            "Epoch 144/150, Loss: 0.0729\n",
            "Epoch 145/150, Loss: 0.0694\n",
            "Epoch 146/150, Loss: 0.0796\n",
            "Epoch 147/150, Loss: 0.0844\n",
            "Epoch 148/150, Loss: 0.0745\n",
            "Epoch 149/150, Loss: 0.0885\n",
            "Epoch 150/150, Loss: 0.0732\n",
            "Iteration 1/10: 995 anomalies detected by GFCN.\n",
            "Iteration 1/10: Number of Nodes after anomaly removal: 2332\n",
            "Evaluating model at iteration 1...\n",
            "Iteration 1 - Evaluation Metrics:\n",
            "Accuracy: 0.9684\n",
            "F1 Score: 0.9473\n",
            "Precision: 0.9487\n",
            "Recall: 0.9459\n",
            "Iteration 2/10: 700 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6960\n",
            "Epoch 2/150, Loss: 0.6538\n",
            "Epoch 3/150, Loss: 0.6291\n",
            "Epoch 4/150, Loss: 0.6162\n",
            "Epoch 5/150, Loss: 0.5969\n",
            "Epoch 6/150, Loss: 0.5846\n",
            "Epoch 7/150, Loss: 0.5739\n",
            "Epoch 8/150, Loss: 0.5612\n",
            "Epoch 9/150, Loss: 0.5441\n",
            "Epoch 10/150, Loss: 0.5247\n",
            "Epoch 11/150, Loss: 0.5193\n",
            "Epoch 12/150, Loss: 0.5026\n",
            "Epoch 13/150, Loss: 0.5005\n",
            "Epoch 14/150, Loss: 0.4855\n",
            "Epoch 15/150, Loss: 0.4742\n",
            "Epoch 16/150, Loss: 0.4594\n",
            "Epoch 17/150, Loss: 0.4535\n",
            "Epoch 18/150, Loss: 0.4436\n",
            "Epoch 19/150, Loss: 0.4291\n",
            "Epoch 20/150, Loss: 0.4063\n",
            "Epoch 21/150, Loss: 0.4065\n",
            "Epoch 22/150, Loss: 0.3925\n",
            "Epoch 23/150, Loss: 0.3780\n",
            "Epoch 24/150, Loss: 0.3674\n",
            "Epoch 25/150, Loss: 0.3559\n",
            "Epoch 26/150, Loss: 0.3518\n",
            "Epoch 27/150, Loss: 0.3210\n",
            "Epoch 28/150, Loss: 0.3202\n",
            "Epoch 29/150, Loss: 0.3068\n",
            "Epoch 30/150, Loss: 0.3042\n",
            "Epoch 31/150, Loss: 0.3117\n",
            "Epoch 32/150, Loss: 0.2874\n",
            "Epoch 33/150, Loss: 0.2925\n",
            "Epoch 34/150, Loss: 0.2738\n",
            "Epoch 35/150, Loss: 0.2674\n",
            "Epoch 36/150, Loss: 0.2643\n",
            "Epoch 37/150, Loss: 0.2605\n",
            "Epoch 38/150, Loss: 0.2636\n",
            "Epoch 39/150, Loss: 0.2432\n",
            "Epoch 40/150, Loss: 0.2467\n",
            "Epoch 41/150, Loss: 0.2338\n",
            "Epoch 42/150, Loss: 0.2272\n",
            "Epoch 43/150, Loss: 0.2318\n",
            "Epoch 44/150, Loss: 0.2167\n",
            "Epoch 45/150, Loss: 0.2238\n",
            "Epoch 46/150, Loss: 0.2162\n",
            "Epoch 47/150, Loss: 0.2125\n",
            "Epoch 48/150, Loss: 0.2056\n",
            "Epoch 49/150, Loss: 0.2061\n",
            "Epoch 50/150, Loss: 0.2030\n",
            "Epoch 51/150, Loss: 0.2100\n",
            "Epoch 52/150, Loss: 0.1948\n",
            "Epoch 53/150, Loss: 0.1879\n",
            "Epoch 54/150, Loss: 0.1851\n",
            "Epoch 55/150, Loss: 0.2003\n",
            "Epoch 56/150, Loss: 0.1852\n",
            "Epoch 57/150, Loss: 0.1833\n",
            "Epoch 58/150, Loss: 0.1765\n",
            "Epoch 59/150, Loss: 0.1750\n",
            "Epoch 60/150, Loss: 0.1741\n",
            "Epoch 61/150, Loss: 0.1846\n",
            "Epoch 62/150, Loss: 0.1758\n",
            "Epoch 63/150, Loss: 0.1733\n",
            "Epoch 64/150, Loss: 0.1562\n",
            "Epoch 65/150, Loss: 0.1759\n",
            "Epoch 66/150, Loss: 0.1443\n",
            "Epoch 67/150, Loss: 0.1622\n",
            "Epoch 68/150, Loss: 0.1637\n",
            "Epoch 69/150, Loss: 0.1650\n",
            "Epoch 70/150, Loss: 0.1688\n",
            "Epoch 71/150, Loss: 0.1521\n",
            "Epoch 72/150, Loss: 0.1713\n",
            "Epoch 73/150, Loss: 0.1364\n",
            "Epoch 74/150, Loss: 0.1517\n",
            "Epoch 75/150, Loss: 0.1562\n",
            "Epoch 76/150, Loss: 0.1477\n",
            "Epoch 77/150, Loss: 0.1421\n",
            "Epoch 78/150, Loss: 0.1344\n",
            "Epoch 79/150, Loss: 0.1602\n",
            "Epoch 80/150, Loss: 0.1505\n",
            "Epoch 81/150, Loss: 0.1386\n",
            "Epoch 82/150, Loss: 0.1537\n",
            "Epoch 83/150, Loss: 0.1364\n",
            "Epoch 84/150, Loss: 0.1360\n",
            "Epoch 85/150, Loss: 0.1392\n",
            "Epoch 86/150, Loss: 0.1303\n",
            "Epoch 87/150, Loss: 0.1252\n",
            "Epoch 88/150, Loss: 0.1269\n",
            "Epoch 89/150, Loss: 0.1222\n",
            "Epoch 90/150, Loss: 0.1477\n",
            "Epoch 91/150, Loss: 0.1192\n",
            "Epoch 92/150, Loss: 0.1147\n",
            "Epoch 93/150, Loss: 0.1215\n",
            "Epoch 94/150, Loss: 0.1350\n",
            "Epoch 95/150, Loss: 0.1310\n",
            "Epoch 96/150, Loss: 0.1205\n",
            "Epoch 97/150, Loss: 0.1276\n",
            "Epoch 98/150, Loss: 0.1138\n",
            "Epoch 99/150, Loss: 0.1125\n",
            "Epoch 100/150, Loss: 0.1222\n",
            "Epoch 101/150, Loss: 0.1169\n",
            "Epoch 102/150, Loss: 0.1094\n",
            "Epoch 103/150, Loss: 0.0974\n",
            "Epoch 104/150, Loss: 0.1134\n",
            "Epoch 105/150, Loss: 0.1042\n",
            "Epoch 106/150, Loss: 0.1129\n",
            "Epoch 107/150, Loss: 0.1081\n",
            "Epoch 108/150, Loss: 0.1138\n",
            "Epoch 109/150, Loss: 0.0989\n",
            "Epoch 110/150, Loss: 0.1115\n",
            "Epoch 111/150, Loss: 0.1230\n",
            "Epoch 112/150, Loss: 0.1023\n",
            "Epoch 113/150, Loss: 0.1241\n",
            "Epoch 114/150, Loss: 0.1245\n",
            "Epoch 115/150, Loss: 0.1125\n",
            "Epoch 116/150, Loss: 0.0979\n",
            "Epoch 117/150, Loss: 0.1126\n",
            "Epoch 118/150, Loss: 0.1156\n",
            "Epoch 119/150, Loss: 0.0967\n",
            "Epoch 120/150, Loss: 0.0829\n",
            "Epoch 121/150, Loss: 0.0900\n",
            "Epoch 122/150, Loss: 0.1114\n",
            "Epoch 123/150, Loss: 0.0855\n",
            "Epoch 124/150, Loss: 0.0986\n",
            "Epoch 125/150, Loss: 0.1121\n",
            "Epoch 126/150, Loss: 0.1018\n",
            "Epoch 127/150, Loss: 0.0899\n",
            "Epoch 128/150, Loss: 0.0868\n",
            "Epoch 129/150, Loss: 0.0931\n",
            "Epoch 130/150, Loss: 0.0935\n",
            "Epoch 131/150, Loss: 0.0897\n",
            "Epoch 132/150, Loss: 0.0917\n",
            "Epoch 133/150, Loss: 0.0957\n",
            "Epoch 134/150, Loss: 0.0981\n",
            "Epoch 135/150, Loss: 0.0878\n",
            "Epoch 136/150, Loss: 0.1038\n",
            "Epoch 137/150, Loss: 0.0967\n",
            "Epoch 138/150, Loss: 0.0965\n",
            "Epoch 139/150, Loss: 0.0944\n",
            "Epoch 140/150, Loss: 0.0806\n",
            "Epoch 141/150, Loss: 0.0852\n",
            "Epoch 142/150, Loss: 0.0887\n",
            "Epoch 143/150, Loss: 0.0975\n",
            "Epoch 144/150, Loss: 0.0870\n",
            "Epoch 145/150, Loss: 0.0917\n",
            "Epoch 146/150, Loss: 0.0735\n",
            "Epoch 147/150, Loss: 0.0938\n",
            "Epoch 148/150, Loss: 0.0804\n",
            "Epoch 149/150, Loss: 0.0804\n",
            "Epoch 150/150, Loss: 0.0967\n",
            "Iteration 2/10: 694 anomalies detected by GFCN.\n",
            "Iteration 2/10: Number of Nodes after anomaly removal: 1638\n",
            "Evaluating model at iteration 2...\n",
            "Iteration 2 - Evaluation Metrics:\n",
            "Accuracy: 0.9451\n",
            "F1 Score: 0.9082\n",
            "Precision: 0.9121\n",
            "Recall: 0.9043\n",
            "Iteration 3/10: 492 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6794\n",
            "Epoch 2/150, Loss: 0.6390\n",
            "Epoch 3/150, Loss: 0.6133\n",
            "Epoch 4/150, Loss: 0.5981\n",
            "Epoch 5/150, Loss: 0.5819\n",
            "Epoch 6/150, Loss: 0.5634\n",
            "Epoch 7/150, Loss: 0.5549\n",
            "Epoch 8/150, Loss: 0.5331\n",
            "Epoch 9/150, Loss: 0.5241\n",
            "Epoch 10/150, Loss: 0.5051\n",
            "Epoch 11/150, Loss: 0.4903\n",
            "Epoch 12/150, Loss: 0.4710\n",
            "Epoch 13/150, Loss: 0.4671\n",
            "Epoch 14/150, Loss: 0.4454\n",
            "Epoch 15/150, Loss: 0.4417\n",
            "Epoch 16/150, Loss: 0.4222\n",
            "Epoch 17/150, Loss: 0.4251\n",
            "Epoch 18/150, Loss: 0.4043\n",
            "Epoch 19/150, Loss: 0.4118\n",
            "Epoch 20/150, Loss: 0.3827\n",
            "Epoch 21/150, Loss: 0.3658\n",
            "Epoch 22/150, Loss: 0.3732\n",
            "Epoch 23/150, Loss: 0.3532\n",
            "Epoch 24/150, Loss: 0.3383\n",
            "Epoch 25/150, Loss: 0.3438\n",
            "Epoch 26/150, Loss: 0.3010\n",
            "Epoch 27/150, Loss: 0.2990\n",
            "Epoch 28/150, Loss: 0.2796\n",
            "Epoch 29/150, Loss: 0.2778\n",
            "Epoch 30/150, Loss: 0.2632\n",
            "Epoch 31/150, Loss: 0.2535\n",
            "Epoch 32/150, Loss: 0.2595\n",
            "Epoch 33/150, Loss: 0.2416\n",
            "Epoch 34/150, Loss: 0.2343\n",
            "Epoch 35/150, Loss: 0.2489\n",
            "Epoch 36/150, Loss: 0.2137\n",
            "Epoch 37/150, Loss: 0.1952\n",
            "Epoch 38/150, Loss: 0.2030\n",
            "Epoch 39/150, Loss: 0.1983\n",
            "Epoch 40/150, Loss: 0.1869\n",
            "Epoch 41/150, Loss: 0.1980\n",
            "Epoch 42/150, Loss: 0.1771\n",
            "Epoch 43/150, Loss: 0.1819\n",
            "Epoch 44/150, Loss: 0.1761\n",
            "Epoch 45/150, Loss: 0.1707\n",
            "Epoch 46/150, Loss: 0.1605\n",
            "Epoch 47/150, Loss: 0.1628\n",
            "Epoch 48/150, Loss: 0.1612\n",
            "Epoch 49/150, Loss: 0.1412\n",
            "Epoch 50/150, Loss: 0.1573\n",
            "Epoch 51/150, Loss: 0.1388\n",
            "Epoch 52/150, Loss: 0.1548\n",
            "Epoch 53/150, Loss: 0.1364\n",
            "Epoch 54/150, Loss: 0.1287\n",
            "Epoch 55/150, Loss: 0.1409\n",
            "Epoch 56/150, Loss: 0.1344\n",
            "Epoch 57/150, Loss: 0.1462\n",
            "Epoch 58/150, Loss: 0.1228\n",
            "Epoch 59/150, Loss: 0.1170\n",
            "Epoch 60/150, Loss: 0.1270\n",
            "Epoch 61/150, Loss: 0.1171\n",
            "Epoch 62/150, Loss: 0.1294\n",
            "Epoch 63/150, Loss: 0.1269\n",
            "Epoch 64/150, Loss: 0.1116\n",
            "Epoch 65/150, Loss: 0.1148\n",
            "Epoch 66/150, Loss: 0.1120\n",
            "Epoch 67/150, Loss: 0.1017\n",
            "Epoch 68/150, Loss: 0.1089\n",
            "Epoch 69/150, Loss: 0.0983\n",
            "Epoch 70/150, Loss: 0.1123\n",
            "Epoch 71/150, Loss: 0.1099\n",
            "Epoch 72/150, Loss: 0.1009\n",
            "Epoch 73/150, Loss: 0.1072\n",
            "Epoch 74/150, Loss: 0.1065\n",
            "Epoch 75/150, Loss: 0.1130\n",
            "Epoch 76/150, Loss: 0.1047\n",
            "Epoch 77/150, Loss: 0.1029\n",
            "Epoch 78/150, Loss: 0.1019\n",
            "Epoch 79/150, Loss: 0.1117\n",
            "Epoch 80/150, Loss: 0.0959\n",
            "Epoch 81/150, Loss: 0.0945\n",
            "Epoch 82/150, Loss: 0.0964\n",
            "Epoch 83/150, Loss: 0.0846\n",
            "Epoch 84/150, Loss: 0.0838\n",
            "Epoch 85/150, Loss: 0.0940\n",
            "Epoch 86/150, Loss: 0.0933\n",
            "Epoch 87/150, Loss: 0.0813\n",
            "Epoch 88/150, Loss: 0.0881\n",
            "Epoch 89/150, Loss: 0.0844\n",
            "Epoch 90/150, Loss: 0.0859\n",
            "Epoch 91/150, Loss: 0.0830\n",
            "Epoch 92/150, Loss: 0.0806\n",
            "Epoch 93/150, Loss: 0.0807\n",
            "Epoch 94/150, Loss: 0.0858\n",
            "Epoch 95/150, Loss: 0.0742\n",
            "Epoch 96/150, Loss: 0.0727\n",
            "Epoch 97/150, Loss: 0.0835\n",
            "Epoch 98/150, Loss: 0.0880\n",
            "Epoch 99/150, Loss: 0.0817\n",
            "Epoch 100/150, Loss: 0.0953\n",
            "Epoch 101/150, Loss: 0.0744\n",
            "Epoch 102/150, Loss: 0.0717\n",
            "Epoch 103/150, Loss: 0.0577\n",
            "Epoch 104/150, Loss: 0.0640\n",
            "Epoch 105/150, Loss: 0.0685\n",
            "Epoch 106/150, Loss: 0.0663\n",
            "Epoch 107/150, Loss: 0.0786\n",
            "Epoch 108/150, Loss: 0.0665\n",
            "Epoch 109/150, Loss: 0.0566\n",
            "Epoch 110/150, Loss: 0.0726\n",
            "Epoch 111/150, Loss: 0.0637\n",
            "Epoch 112/150, Loss: 0.0686\n",
            "Epoch 113/150, Loss: 0.0752\n",
            "Epoch 114/150, Loss: 0.0643\n",
            "Epoch 115/150, Loss: 0.0583\n",
            "Epoch 116/150, Loss: 0.0615\n",
            "Epoch 117/150, Loss: 0.0820\n",
            "Epoch 118/150, Loss: 0.0595\n",
            "Epoch 119/150, Loss: 0.0693\n",
            "Epoch 120/150, Loss: 0.0719\n",
            "Epoch 121/150, Loss: 0.0600\n",
            "Epoch 122/150, Loss: 0.0580\n",
            "Epoch 123/150, Loss: 0.0608\n",
            "Epoch 124/150, Loss: 0.0615\n",
            "Epoch 125/150, Loss: 0.0711\n",
            "Epoch 126/150, Loss: 0.0555\n",
            "Epoch 127/150, Loss: 0.0718\n",
            "Epoch 128/150, Loss: 0.0675\n",
            "Epoch 129/150, Loss: 0.0635\n",
            "Epoch 130/150, Loss: 0.0530\n",
            "Epoch 131/150, Loss: 0.0611\n",
            "Epoch 132/150, Loss: 0.0533\n",
            "Epoch 133/150, Loss: 0.0536\n",
            "Epoch 134/150, Loss: 0.0511\n",
            "Epoch 135/150, Loss: 0.0480\n",
            "Epoch 136/150, Loss: 0.0710\n",
            "Epoch 137/150, Loss: 0.0700\n",
            "Epoch 138/150, Loss: 0.0445\n",
            "Epoch 139/150, Loss: 0.0440\n",
            "Epoch 140/150, Loss: 0.0520\n",
            "Epoch 141/150, Loss: 0.0504\n",
            "Epoch 142/150, Loss: 0.0525\n",
            "Epoch 143/150, Loss: 0.0606\n",
            "Epoch 144/150, Loss: 0.0582\n",
            "Epoch 145/150, Loss: 0.0418\n",
            "Epoch 146/150, Loss: 0.0538\n",
            "Epoch 147/150, Loss: 0.0562\n",
            "Epoch 148/150, Loss: 0.0500\n",
            "Epoch 149/150, Loss: 0.0476\n",
            "Epoch 150/150, Loss: 0.0489\n",
            "Iteration 3/10: 447 anomalies detected by GFCN.\n",
            "Iteration 3/10: Number of Nodes after anomaly removal: 1191\n",
            "Evaluating model at iteration 3...\n",
            "Iteration 3 - Evaluation Metrics:\n",
            "Accuracy: 0.9420\n",
            "F1 Score: 0.8988\n",
            "Precision: 0.9441\n",
            "Recall: 0.8577\n",
            "Iteration 4/10: 357 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7434\n",
            "Epoch 2/150, Loss: 0.6797\n",
            "Epoch 3/150, Loss: 0.6332\n",
            "Epoch 4/150, Loss: 0.5930\n",
            "Epoch 5/150, Loss: 0.5696\n",
            "Epoch 6/150, Loss: 0.5500\n",
            "Epoch 7/150, Loss: 0.5279\n",
            "Epoch 8/150, Loss: 0.5075\n",
            "Epoch 9/150, Loss: 0.4976\n",
            "Epoch 10/150, Loss: 0.4775\n",
            "Epoch 11/150, Loss: 0.4636\n",
            "Epoch 12/150, Loss: 0.4488\n",
            "Epoch 13/150, Loss: 0.4489\n",
            "Epoch 14/150, Loss: 0.4325\n",
            "Epoch 15/150, Loss: 0.4122\n",
            "Epoch 16/150, Loss: 0.4109\n",
            "Epoch 17/150, Loss: 0.3879\n",
            "Epoch 18/150, Loss: 0.3819\n",
            "Epoch 19/150, Loss: 0.3655\n",
            "Epoch 20/150, Loss: 0.3533\n",
            "Epoch 21/150, Loss: 0.3557\n",
            "Epoch 22/150, Loss: 0.3345\n",
            "Epoch 23/150, Loss: 0.3282\n",
            "Epoch 24/150, Loss: 0.3050\n",
            "Epoch 25/150, Loss: 0.2978\n",
            "Epoch 26/150, Loss: 0.2922\n",
            "Epoch 27/150, Loss: 0.2793\n",
            "Epoch 28/150, Loss: 0.2812\n",
            "Epoch 29/150, Loss: 0.2576\n",
            "Epoch 30/150, Loss: 0.2413\n",
            "Epoch 31/150, Loss: 0.2297\n",
            "Epoch 32/150, Loss: 0.2181\n",
            "Epoch 33/150, Loss: 0.2142\n",
            "Epoch 34/150, Loss: 0.2127\n",
            "Epoch 35/150, Loss: 0.1913\n",
            "Epoch 36/150, Loss: 0.1948\n",
            "Epoch 37/150, Loss: 0.1842\n",
            "Epoch 38/150, Loss: 0.1766\n",
            "Epoch 39/150, Loss: 0.1589\n",
            "Epoch 40/150, Loss: 0.1747\n",
            "Epoch 41/150, Loss: 0.1553\n",
            "Epoch 42/150, Loss: 0.1483\n",
            "Epoch 43/150, Loss: 0.1446\n",
            "Epoch 44/150, Loss: 0.1420\n",
            "Epoch 45/150, Loss: 0.1367\n",
            "Epoch 46/150, Loss: 0.1440\n",
            "Epoch 47/150, Loss: 0.1180\n",
            "Epoch 48/150, Loss: 0.1143\n",
            "Epoch 49/150, Loss: 0.1121\n",
            "Epoch 50/150, Loss: 0.1000\n",
            "Epoch 51/150, Loss: 0.1043\n",
            "Epoch 52/150, Loss: 0.0969\n",
            "Epoch 53/150, Loss: 0.0965\n",
            "Epoch 54/150, Loss: 0.0962\n",
            "Epoch 55/150, Loss: 0.1109\n",
            "Epoch 56/150, Loss: 0.0724\n",
            "Epoch 57/150, Loss: 0.0924\n",
            "Epoch 58/150, Loss: 0.0978\n",
            "Epoch 59/150, Loss: 0.0830\n",
            "Epoch 60/150, Loss: 0.0928\n",
            "Epoch 61/150, Loss: 0.0820\n",
            "Epoch 62/150, Loss: 0.0737\n",
            "Epoch 63/150, Loss: 0.0742\n",
            "Epoch 64/150, Loss: 0.0857\n",
            "Epoch 65/150, Loss: 0.0928\n",
            "Epoch 66/150, Loss: 0.0631\n",
            "Epoch 67/150, Loss: 0.0837\n",
            "Epoch 68/150, Loss: 0.0567\n",
            "Epoch 69/150, Loss: 0.0792\n",
            "Epoch 70/150, Loss: 0.0625\n",
            "Epoch 71/150, Loss: 0.0488\n",
            "Epoch 72/150, Loss: 0.0706\n",
            "Epoch 73/150, Loss: 0.0651\n",
            "Epoch 74/150, Loss: 0.0703\n",
            "Epoch 75/150, Loss: 0.0522\n",
            "Epoch 76/150, Loss: 0.0577\n",
            "Epoch 77/150, Loss: 0.0693\n",
            "Epoch 78/150, Loss: 0.0513\n",
            "Epoch 79/150, Loss: 0.0603\n",
            "Epoch 80/150, Loss: 0.0617\n",
            "Epoch 81/150, Loss: 0.0644\n",
            "Epoch 82/150, Loss: 0.0535\n",
            "Epoch 83/150, Loss: 0.0693\n",
            "Epoch 84/150, Loss: 0.0437\n",
            "Epoch 85/150, Loss: 0.0507\n",
            "Epoch 86/150, Loss: 0.0454\n",
            "Epoch 87/150, Loss: 0.0471\n",
            "Epoch 88/150, Loss: 0.0417\n",
            "Epoch 89/150, Loss: 0.0473\n",
            "Epoch 90/150, Loss: 0.0540\n",
            "Epoch 91/150, Loss: 0.0414\n",
            "Epoch 92/150, Loss: 0.0457\n",
            "Epoch 93/150, Loss: 0.0522\n",
            "Epoch 94/150, Loss: 0.0465\n",
            "Epoch 95/150, Loss: 0.0415\n",
            "Epoch 96/150, Loss: 0.0453\n",
            "Epoch 97/150, Loss: 0.0435\n",
            "Epoch 98/150, Loss: 0.0502\n",
            "Epoch 99/150, Loss: 0.0452\n",
            "Epoch 100/150, Loss: 0.0485\n",
            "Epoch 101/150, Loss: 0.0498\n",
            "Epoch 102/150, Loss: 0.0391\n",
            "Epoch 103/150, Loss: 0.0602\n",
            "Epoch 104/150, Loss: 0.0453\n",
            "Epoch 105/150, Loss: 0.0425\n",
            "Epoch 106/150, Loss: 0.0517\n",
            "Epoch 107/150, Loss: 0.0375\n",
            "Epoch 108/150, Loss: 0.0469\n",
            "Epoch 109/150, Loss: 0.0342\n",
            "Epoch 110/150, Loss: 0.0373\n",
            "Epoch 111/150, Loss: 0.0475\n",
            "Epoch 112/150, Loss: 0.0357\n",
            "Epoch 113/150, Loss: 0.0371\n",
            "Epoch 114/150, Loss: 0.0356\n",
            "Epoch 115/150, Loss: 0.0411\n",
            "Epoch 116/150, Loss: 0.0411\n",
            "Epoch 117/150, Loss: 0.0425\n",
            "Epoch 118/150, Loss: 0.0440\n",
            "Epoch 119/150, Loss: 0.0308\n",
            "Epoch 120/150, Loss: 0.0257\n",
            "Epoch 121/150, Loss: 0.0399\n",
            "Epoch 122/150, Loss: 0.0425\n",
            "Epoch 123/150, Loss: 0.0363\n",
            "Epoch 124/150, Loss: 0.0377\n",
            "Epoch 125/150, Loss: 0.0345\n",
            "Epoch 126/150, Loss: 0.0381\n",
            "Epoch 127/150, Loss: 0.0403\n",
            "Epoch 128/150, Loss: 0.0304\n",
            "Epoch 129/150, Loss: 0.0279\n",
            "Epoch 130/150, Loss: 0.0309\n",
            "Epoch 131/150, Loss: 0.0334\n",
            "Epoch 132/150, Loss: 0.0279\n",
            "Epoch 133/150, Loss: 0.0317\n",
            "Epoch 134/150, Loss: 0.0381\n",
            "Epoch 135/150, Loss: 0.0341\n",
            "Epoch 136/150, Loss: 0.0325\n",
            "Epoch 137/150, Loss: 0.0314\n",
            "Epoch 138/150, Loss: 0.0367\n",
            "Epoch 139/150, Loss: 0.0310\n",
            "Epoch 140/150, Loss: 0.0278\n",
            "Epoch 141/150, Loss: 0.0403\n",
            "Epoch 142/150, Loss: 0.0305\n",
            "Epoch 143/150, Loss: 0.0380\n",
            "Epoch 144/150, Loss: 0.0277\n",
            "Epoch 145/150, Loss: 0.0300\n",
            "Epoch 146/150, Loss: 0.0345\n",
            "Epoch 147/150, Loss: 0.0412\n",
            "Epoch 148/150, Loss: 0.0270\n",
            "Epoch 149/150, Loss: 0.0321\n",
            "Epoch 150/150, Loss: 0.0220\n",
            "Iteration 4/10: 291 anomalies detected by GFCN.\n",
            "Iteration 4/10: Number of Nodes after anomaly removal: 900\n",
            "Evaluating model at iteration 4...\n",
            "Iteration 4 - Evaluation Metrics:\n",
            "Accuracy: 0.9278\n",
            "F1 Score: 0.8673\n",
            "Precision: 0.9656\n",
            "Recall: 0.7871\n",
            "Iteration 5/10: 270 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6719\n",
            "Epoch 2/150, Loss: 0.6235\n",
            "Epoch 3/150, Loss: 0.5772\n",
            "Epoch 4/150, Loss: 0.5462\n",
            "Epoch 5/150, Loss: 0.5179\n",
            "Epoch 6/150, Loss: 0.4898\n",
            "Epoch 7/150, Loss: 0.4666\n",
            "Epoch 8/150, Loss: 0.4433\n",
            "Epoch 9/150, Loss: 0.4260\n",
            "Epoch 10/150, Loss: 0.4071\n",
            "Epoch 11/150, Loss: 0.3933\n",
            "Epoch 12/150, Loss: 0.3789\n",
            "Epoch 13/150, Loss: 0.3568\n",
            "Epoch 14/150, Loss: 0.3411\n",
            "Epoch 15/150, Loss: 0.3333\n",
            "Epoch 16/150, Loss: 0.3244\n",
            "Epoch 17/150, Loss: 0.3080\n",
            "Epoch 18/150, Loss: 0.2922\n",
            "Epoch 19/150, Loss: 0.2917\n",
            "Epoch 20/150, Loss: 0.2695\n",
            "Epoch 21/150, Loss: 0.2625\n",
            "Epoch 22/150, Loss: 0.2422\n",
            "Epoch 23/150, Loss: 0.2196\n",
            "Epoch 24/150, Loss: 0.2277\n",
            "Epoch 25/150, Loss: 0.2137\n",
            "Epoch 26/150, Loss: 0.1979\n",
            "Epoch 27/150, Loss: 0.1908\n",
            "Epoch 28/150, Loss: 0.1805\n",
            "Epoch 29/150, Loss: 0.1705\n",
            "Epoch 30/150, Loss: 0.1662\n",
            "Epoch 31/150, Loss: 0.1443\n",
            "Epoch 32/150, Loss: 0.1513\n",
            "Epoch 33/150, Loss: 0.1419\n",
            "Epoch 34/150, Loss: 0.1318\n",
            "Epoch 35/150, Loss: 0.1276\n",
            "Epoch 36/150, Loss: 0.1118\n",
            "Epoch 37/150, Loss: 0.1070\n",
            "Epoch 38/150, Loss: 0.1164\n",
            "Epoch 39/150, Loss: 0.0987\n",
            "Epoch 40/150, Loss: 0.1056\n",
            "Epoch 41/150, Loss: 0.0909\n",
            "Epoch 42/150, Loss: 0.0914\n",
            "Epoch 43/150, Loss: 0.0755\n",
            "Epoch 44/150, Loss: 0.0842\n",
            "Epoch 45/150, Loss: 0.0803\n",
            "Epoch 46/150, Loss: 0.0666\n",
            "Epoch 47/150, Loss: 0.0732\n",
            "Epoch 48/150, Loss: 0.0719\n",
            "Epoch 49/150, Loss: 0.0738\n",
            "Epoch 50/150, Loss: 0.0531\n",
            "Epoch 51/150, Loss: 0.0578\n",
            "Epoch 52/150, Loss: 0.0676\n",
            "Epoch 53/150, Loss: 0.0671\n",
            "Epoch 54/150, Loss: 0.0647\n",
            "Epoch 55/150, Loss: 0.0570\n",
            "Epoch 56/150, Loss: 0.0520\n",
            "Epoch 57/150, Loss: 0.0476\n",
            "Epoch 58/150, Loss: 0.0483\n",
            "Epoch 59/150, Loss: 0.0498\n",
            "Epoch 60/150, Loss: 0.0503\n",
            "Epoch 61/150, Loss: 0.0480\n",
            "Epoch 62/150, Loss: 0.0467\n",
            "Epoch 63/150, Loss: 0.0336\n",
            "Epoch 64/150, Loss: 0.0392\n",
            "Epoch 65/150, Loss: 0.0460\n",
            "Epoch 66/150, Loss: 0.0389\n",
            "Epoch 67/150, Loss: 0.0380\n",
            "Epoch 68/150, Loss: 0.0348\n",
            "Epoch 69/150, Loss: 0.0354\n",
            "Epoch 70/150, Loss: 0.0321\n",
            "Epoch 71/150, Loss: 0.0373\n",
            "Epoch 72/150, Loss: 0.0305\n",
            "Epoch 73/150, Loss: 0.0393\n",
            "Epoch 74/150, Loss: 0.0279\n",
            "Epoch 75/150, Loss: 0.0358\n",
            "Epoch 76/150, Loss: 0.0385\n",
            "Epoch 77/150, Loss: 0.0298\n",
            "Epoch 78/150, Loss: 0.0332\n",
            "Epoch 79/150, Loss: 0.0292\n",
            "Epoch 80/150, Loss: 0.0300\n",
            "Epoch 81/150, Loss: 0.0269\n",
            "Epoch 82/150, Loss: 0.0258\n",
            "Epoch 83/150, Loss: 0.0277\n",
            "Epoch 84/150, Loss: 0.0280\n",
            "Epoch 85/150, Loss: 0.0277\n",
            "Epoch 86/150, Loss: 0.0319\n",
            "Epoch 87/150, Loss: 0.0312\n",
            "Epoch 88/150, Loss: 0.0281\n",
            "Epoch 89/150, Loss: 0.0199\n",
            "Epoch 90/150, Loss: 0.0186\n",
            "Epoch 91/150, Loss: 0.0325\n",
            "Epoch 92/150, Loss: 0.0255\n",
            "Epoch 93/150, Loss: 0.0209\n",
            "Epoch 94/150, Loss: 0.0289\n",
            "Epoch 95/150, Loss: 0.0211\n",
            "Epoch 96/150, Loss: 0.0318\n",
            "Epoch 97/150, Loss: 0.0230\n",
            "Epoch 98/150, Loss: 0.0204\n",
            "Epoch 99/150, Loss: 0.0268\n",
            "Epoch 100/150, Loss: 0.0232\n",
            "Epoch 101/150, Loss: 0.0256\n",
            "Epoch 102/150, Loss: 0.0204\n",
            "Epoch 103/150, Loss: 0.0295\n",
            "Epoch 104/150, Loss: 0.0178\n",
            "Epoch 105/150, Loss: 0.0167\n",
            "Epoch 106/150, Loss: 0.0180\n",
            "Epoch 107/150, Loss: 0.0186\n",
            "Epoch 108/150, Loss: 0.0173\n",
            "Epoch 109/150, Loss: 0.0165\n",
            "Epoch 110/150, Loss: 0.0185\n",
            "Epoch 111/150, Loss: 0.0219\n",
            "Epoch 112/150, Loss: 0.0302\n",
            "Epoch 113/150, Loss: 0.0201\n",
            "Epoch 114/150, Loss: 0.0211\n",
            "Epoch 115/150, Loss: 0.0217\n",
            "Epoch 116/150, Loss: 0.0236\n",
            "Epoch 117/150, Loss: 0.0174\n",
            "Epoch 118/150, Loss: 0.0357\n",
            "Epoch 119/150, Loss: 0.0208\n",
            "Epoch 120/150, Loss: 0.0202\n",
            "Epoch 121/150, Loss: 0.0156\n",
            "Epoch 122/150, Loss: 0.0167\n",
            "Epoch 123/150, Loss: 0.0227\n",
            "Epoch 124/150, Loss: 0.0187\n",
            "Epoch 125/150, Loss: 0.0219\n",
            "Epoch 126/150, Loss: 0.0222\n",
            "Epoch 127/150, Loss: 0.0196\n",
            "Epoch 128/150, Loss: 0.0207\n",
            "Epoch 129/150, Loss: 0.0181\n",
            "Epoch 130/150, Loss: 0.0186\n",
            "Epoch 131/150, Loss: 0.0134\n",
            "Epoch 132/150, Loss: 0.0212\n",
            "Epoch 133/150, Loss: 0.0132\n",
            "Epoch 134/150, Loss: 0.0158\n",
            "Epoch 135/150, Loss: 0.0182\n",
            "Epoch 136/150, Loss: 0.0121\n",
            "Epoch 137/150, Loss: 0.0203\n",
            "Epoch 138/150, Loss: 0.0141\n",
            "Epoch 139/150, Loss: 0.0161\n",
            "Epoch 140/150, Loss: 0.0188\n",
            "Epoch 141/150, Loss: 0.0113\n",
            "Epoch 142/150, Loss: 0.0159\n",
            "Epoch 143/150, Loss: 0.0174\n",
            "Epoch 144/150, Loss: 0.0192\n",
            "Epoch 145/150, Loss: 0.0129\n",
            "Epoch 146/150, Loss: 0.0152\n",
            "Epoch 147/150, Loss: 0.0176\n",
            "Epoch 148/150, Loss: 0.0126\n",
            "Epoch 149/150, Loss: 0.0120\n",
            "Epoch 150/150, Loss: 0.0173\n",
            "Iteration 5/10: 217 anomalies detected by GFCN.\n",
            "Iteration 5/10: Number of Nodes after anomaly removal: 683\n",
            "Evaluating model at iteration 5...\n",
            "Iteration 5 - Evaluation Metrics:\n",
            "Accuracy: 0.9122\n",
            "F1 Score: 0.8378\n",
            "Precision: 0.9401\n",
            "Recall: 0.7556\n",
            "Iteration 6/10: 205 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7135\n",
            "Epoch 2/150, Loss: 0.6546\n",
            "Epoch 3/150, Loss: 0.6092\n",
            "Epoch 4/150, Loss: 0.5729\n",
            "Epoch 5/150, Loss: 0.5453\n",
            "Epoch 6/150, Loss: 0.5114\n",
            "Epoch 7/150, Loss: 0.4807\n",
            "Epoch 8/150, Loss: 0.4614\n",
            "Epoch 9/150, Loss: 0.4299\n",
            "Epoch 10/150, Loss: 0.4148\n",
            "Epoch 11/150, Loss: 0.4019\n",
            "Epoch 12/150, Loss: 0.3773\n",
            "Epoch 13/150, Loss: 0.3560\n",
            "Epoch 14/150, Loss: 0.3462\n",
            "Epoch 15/150, Loss: 0.3167\n",
            "Epoch 16/150, Loss: 0.2996\n",
            "Epoch 17/150, Loss: 0.2836\n",
            "Epoch 18/150, Loss: 0.2690\n",
            "Epoch 19/150, Loss: 0.2572\n",
            "Epoch 20/150, Loss: 0.2408\n",
            "Epoch 21/150, Loss: 0.2381\n",
            "Epoch 22/150, Loss: 0.2138\n",
            "Epoch 23/150, Loss: 0.1978\n",
            "Epoch 24/150, Loss: 0.1839\n",
            "Epoch 25/150, Loss: 0.1728\n",
            "Epoch 26/150, Loss: 0.1603\n",
            "Epoch 27/150, Loss: 0.1573\n",
            "Epoch 28/150, Loss: 0.1450\n",
            "Epoch 29/150, Loss: 0.1358\n",
            "Epoch 30/150, Loss: 0.1161\n",
            "Epoch 31/150, Loss: 0.1221\n",
            "Epoch 32/150, Loss: 0.1019\n",
            "Epoch 33/150, Loss: 0.1000\n",
            "Epoch 34/150, Loss: 0.0842\n",
            "Epoch 35/150, Loss: 0.0879\n",
            "Epoch 36/150, Loss: 0.0796\n",
            "Epoch 37/150, Loss: 0.0726\n",
            "Epoch 38/150, Loss: 0.0645\n",
            "Epoch 39/150, Loss: 0.0620\n",
            "Epoch 40/150, Loss: 0.0612\n",
            "Epoch 41/150, Loss: 0.0612\n",
            "Epoch 42/150, Loss: 0.0485\n",
            "Epoch 43/150, Loss: 0.0540\n",
            "Epoch 44/150, Loss: 0.0553\n",
            "Epoch 45/150, Loss: 0.0539\n",
            "Epoch 46/150, Loss: 0.0364\n",
            "Epoch 47/150, Loss: 0.0414\n",
            "Epoch 48/150, Loss: 0.0421\n",
            "Epoch 49/150, Loss: 0.0430\n",
            "Epoch 50/150, Loss: 0.0363\n",
            "Epoch 51/150, Loss: 0.0390\n",
            "Epoch 52/150, Loss: 0.0362\n",
            "Epoch 53/150, Loss: 0.0274\n",
            "Epoch 54/150, Loss: 0.0351\n",
            "Epoch 55/150, Loss: 0.0247\n",
            "Epoch 56/150, Loss: 0.0273\n",
            "Epoch 57/150, Loss: 0.0283\n",
            "Epoch 58/150, Loss: 0.0378\n",
            "Epoch 59/150, Loss: 0.0335\n",
            "Epoch 60/150, Loss: 0.0353\n",
            "Epoch 61/150, Loss: 0.0272\n",
            "Epoch 62/150, Loss: 0.0360\n",
            "Epoch 63/150, Loss: 0.0196\n",
            "Epoch 64/150, Loss: 0.0219\n",
            "Epoch 65/150, Loss: 0.0246\n",
            "Epoch 66/150, Loss: 0.0351\n",
            "Epoch 67/150, Loss: 0.0217\n",
            "Epoch 68/150, Loss: 0.0262\n",
            "Epoch 69/150, Loss: 0.0195\n",
            "Epoch 70/150, Loss: 0.0187\n",
            "Epoch 71/150, Loss: 0.0125\n",
            "Epoch 72/150, Loss: 0.0260\n",
            "Epoch 73/150, Loss: 0.0227\n",
            "Epoch 74/150, Loss: 0.0203\n",
            "Epoch 75/150, Loss: 0.0199\n",
            "Epoch 76/150, Loss: 0.0195\n",
            "Epoch 77/150, Loss: 0.0169\n",
            "Epoch 78/150, Loss: 0.0193\n",
            "Epoch 79/150, Loss: 0.0133\n",
            "Epoch 80/150, Loss: 0.0144\n",
            "Epoch 81/150, Loss: 0.0215\n",
            "Epoch 82/150, Loss: 0.0136\n",
            "Epoch 83/150, Loss: 0.0227\n",
            "Epoch 84/150, Loss: 0.0210\n",
            "Epoch 85/150, Loss: 0.0125\n",
            "Epoch 86/150, Loss: 0.0099\n",
            "Epoch 87/150, Loss: 0.0166\n",
            "Epoch 88/150, Loss: 0.0109\n",
            "Epoch 89/150, Loss: 0.0129\n",
            "Epoch 90/150, Loss: 0.0230\n",
            "Epoch 91/150, Loss: 0.0149\n",
            "Epoch 92/150, Loss: 0.0242\n",
            "Epoch 93/150, Loss: 0.0140\n",
            "Epoch 94/150, Loss: 0.0087\n",
            "Epoch 95/150, Loss: 0.0147\n",
            "Epoch 96/150, Loss: 0.0116\n",
            "Epoch 97/150, Loss: 0.0147\n",
            "Epoch 98/150, Loss: 0.0061\n",
            "Epoch 99/150, Loss: 0.0114\n",
            "Epoch 100/150, Loss: 0.0096\n",
            "Epoch 101/150, Loss: 0.0154\n",
            "Epoch 102/150, Loss: 0.0121\n",
            "Epoch 103/150, Loss: 0.0091\n",
            "Epoch 104/150, Loss: 0.0163\n",
            "Epoch 105/150, Loss: 0.0117\n",
            "Epoch 106/150, Loss: 0.0101\n",
            "Epoch 107/150, Loss: 0.0143\n",
            "Epoch 108/150, Loss: 0.0167\n",
            "Epoch 109/150, Loss: 0.0112\n",
            "Epoch 110/150, Loss: 0.0117\n",
            "Epoch 111/150, Loss: 0.0124\n",
            "Epoch 112/150, Loss: 0.0136\n",
            "Epoch 113/150, Loss: 0.0087\n",
            "Epoch 114/150, Loss: 0.0131\n",
            "Epoch 115/150, Loss: 0.0123\n",
            "Epoch 116/150, Loss: 0.0064\n",
            "Epoch 117/150, Loss: 0.0115\n",
            "Epoch 118/150, Loss: 0.0075\n",
            "Epoch 119/150, Loss: 0.0098\n",
            "Epoch 120/150, Loss: 0.0080\n",
            "Epoch 121/150, Loss: 0.0135\n",
            "Epoch 122/150, Loss: 0.0125\n",
            "Epoch 123/150, Loss: 0.0067\n",
            "Epoch 124/150, Loss: 0.0125\n",
            "Epoch 125/150, Loss: 0.0114\n",
            "Epoch 126/150, Loss: 0.0142\n",
            "Epoch 127/150, Loss: 0.0062\n",
            "Epoch 128/150, Loss: 0.0075\n",
            "Epoch 129/150, Loss: 0.0113\n",
            "Epoch 130/150, Loss: 0.0086\n",
            "Epoch 131/150, Loss: 0.0151\n",
            "Epoch 132/150, Loss: 0.0099\n",
            "Epoch 133/150, Loss: 0.0077\n",
            "Epoch 134/150, Loss: 0.0066\n",
            "Epoch 135/150, Loss: 0.0072\n",
            "Epoch 136/150, Loss: 0.0095\n",
            "Epoch 137/150, Loss: 0.0119\n",
            "Epoch 138/150, Loss: 0.0138\n",
            "Epoch 139/150, Loss: 0.0046\n",
            "Epoch 140/150, Loss: 0.0042\n",
            "Epoch 141/150, Loss: 0.0120\n",
            "Epoch 142/150, Loss: 0.0053\n",
            "Epoch 143/150, Loss: 0.0069\n",
            "Epoch 144/150, Loss: 0.0077\n",
            "Epoch 145/150, Loss: 0.0071\n",
            "Epoch 146/150, Loss: 0.0047\n",
            "Epoch 147/150, Loss: 0.0135\n",
            "Epoch 148/150, Loss: 0.0060\n",
            "Epoch 149/150, Loss: 0.0096\n",
            "Epoch 150/150, Loss: 0.0090\n",
            "Iteration 6/10: 157 anomalies detected by GFCN.\n",
            "Iteration 6/10: Number of Nodes after anomaly removal: 526\n",
            "Evaluating model at iteration 6...\n",
            "Iteration 6 - Evaluation Metrics:\n",
            "Accuracy: 0.8975\n",
            "F1 Score: 0.8066\n",
            "Precision: 0.9299\n",
            "Recall: 0.7122\n",
            "Iteration 7/10: 158 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6988\n",
            "Epoch 2/150, Loss: 0.6400\n",
            "Epoch 3/150, Loss: 0.5902\n",
            "Epoch 4/150, Loss: 0.5445\n",
            "Epoch 5/150, Loss: 0.4990\n",
            "Epoch 6/150, Loss: 0.4693\n",
            "Epoch 7/150, Loss: 0.4425\n",
            "Epoch 8/150, Loss: 0.4108\n",
            "Epoch 9/150, Loss: 0.3894\n",
            "Epoch 10/150, Loss: 0.3705\n",
            "Epoch 11/150, Loss: 0.3481\n",
            "Epoch 12/150, Loss: 0.3223\n",
            "Epoch 13/150, Loss: 0.3048\n",
            "Epoch 14/150, Loss: 0.2787\n",
            "Epoch 15/150, Loss: 0.2631\n",
            "Epoch 16/150, Loss: 0.2495\n",
            "Epoch 17/150, Loss: 0.2262\n",
            "Epoch 18/150, Loss: 0.2258\n",
            "Epoch 19/150, Loss: 0.1933\n",
            "Epoch 20/150, Loss: 0.1839\n",
            "Epoch 21/150, Loss: 0.1764\n",
            "Epoch 22/150, Loss: 0.1587\n",
            "Epoch 23/150, Loss: 0.1451\n",
            "Epoch 24/150, Loss: 0.1327\n",
            "Epoch 25/150, Loss: 0.1256\n",
            "Epoch 26/150, Loss: 0.1082\n",
            "Epoch 27/150, Loss: 0.1125\n",
            "Epoch 28/150, Loss: 0.0971\n",
            "Epoch 29/150, Loss: 0.0855\n",
            "Epoch 30/150, Loss: 0.0726\n",
            "Epoch 31/150, Loss: 0.0565\n",
            "Epoch 32/150, Loss: 0.0626\n",
            "Epoch 33/150, Loss: 0.0578\n",
            "Epoch 34/150, Loss: 0.0581\n",
            "Epoch 35/150, Loss: 0.0545\n",
            "Epoch 36/150, Loss: 0.0525\n",
            "Epoch 37/150, Loss: 0.0426\n",
            "Epoch 38/150, Loss: 0.0419\n",
            "Epoch 39/150, Loss: 0.0406\n",
            "Epoch 40/150, Loss: 0.0407\n",
            "Epoch 41/150, Loss: 0.0287\n",
            "Epoch 42/150, Loss: 0.0395\n",
            "Epoch 43/150, Loss: 0.0305\n",
            "Epoch 44/150, Loss: 0.0279\n",
            "Epoch 45/150, Loss: 0.0280\n",
            "Epoch 46/150, Loss: 0.0196\n",
            "Epoch 47/150, Loss: 0.0228\n",
            "Epoch 48/150, Loss: 0.0214\n",
            "Epoch 49/150, Loss: 0.0188\n",
            "Epoch 50/150, Loss: 0.0158\n",
            "Epoch 51/150, Loss: 0.0204\n",
            "Epoch 52/150, Loss: 0.0235\n",
            "Epoch 53/150, Loss: 0.0194\n",
            "Epoch 54/150, Loss: 0.0260\n",
            "Epoch 55/150, Loss: 0.0227\n",
            "Epoch 56/150, Loss: 0.0173\n",
            "Epoch 57/150, Loss: 0.0151\n",
            "Epoch 58/150, Loss: 0.0208\n",
            "Epoch 59/150, Loss: 0.0116\n",
            "Epoch 60/150, Loss: 0.0175\n",
            "Epoch 61/150, Loss: 0.0173\n",
            "Epoch 62/150, Loss: 0.0092\n",
            "Epoch 63/150, Loss: 0.0194\n",
            "Epoch 64/150, Loss: 0.0102\n",
            "Epoch 65/150, Loss: 0.0110\n",
            "Epoch 66/150, Loss: 0.0159\n",
            "Epoch 67/150, Loss: 0.0155\n",
            "Epoch 68/150, Loss: 0.0150\n",
            "Epoch 69/150, Loss: 0.0075\n",
            "Epoch 70/150, Loss: 0.0082\n",
            "Epoch 71/150, Loss: 0.0119\n",
            "Epoch 72/150, Loss: 0.0126\n",
            "Epoch 73/150, Loss: 0.0115\n",
            "Epoch 74/150, Loss: 0.0092\n",
            "Epoch 75/150, Loss: 0.0126\n",
            "Epoch 76/150, Loss: 0.0186\n",
            "Epoch 77/150, Loss: 0.0104\n",
            "Epoch 78/150, Loss: 0.0061\n",
            "Epoch 79/150, Loss: 0.0091\n",
            "Epoch 80/150, Loss: 0.0131\n",
            "Epoch 81/150, Loss: 0.0091\n",
            "Epoch 82/150, Loss: 0.0077\n",
            "Epoch 83/150, Loss: 0.0102\n",
            "Epoch 84/150, Loss: 0.0111\n",
            "Epoch 85/150, Loss: 0.0108\n",
            "Epoch 86/150, Loss: 0.0071\n",
            "Epoch 87/150, Loss: 0.0106\n",
            "Epoch 88/150, Loss: 0.0068\n",
            "Epoch 89/150, Loss: 0.0129\n",
            "Epoch 90/150, Loss: 0.0109\n",
            "Epoch 91/150, Loss: 0.0065\n",
            "Epoch 92/150, Loss: 0.0065\n",
            "Epoch 93/150, Loss: 0.0075\n",
            "Epoch 94/150, Loss: 0.0068\n",
            "Epoch 95/150, Loss: 0.0087\n",
            "Epoch 96/150, Loss: 0.0085\n",
            "Epoch 97/150, Loss: 0.0087\n",
            "Epoch 98/150, Loss: 0.0096\n",
            "Epoch 99/150, Loss: 0.0081\n",
            "Epoch 100/150, Loss: 0.0096\n",
            "Epoch 101/150, Loss: 0.0067\n",
            "Epoch 102/150, Loss: 0.0081\n",
            "Epoch 103/150, Loss: 0.0105\n",
            "Epoch 104/150, Loss: 0.0107\n",
            "Epoch 105/150, Loss: 0.0048\n",
            "Epoch 106/150, Loss: 0.0048\n",
            "Epoch 107/150, Loss: 0.0067\n",
            "Epoch 108/150, Loss: 0.0065\n",
            "Epoch 109/150, Loss: 0.0100\n",
            "Epoch 110/150, Loss: 0.0082\n",
            "Epoch 111/150, Loss: 0.0102\n",
            "Epoch 112/150, Loss: 0.0089\n",
            "Epoch 113/150, Loss: 0.0063\n",
            "Epoch 114/150, Loss: 0.0061\n",
            "Epoch 115/150, Loss: 0.0051\n",
            "Epoch 116/150, Loss: 0.0109\n",
            "Epoch 117/150, Loss: 0.0033\n",
            "Epoch 118/150, Loss: 0.0068\n",
            "Epoch 119/150, Loss: 0.0098\n",
            "Epoch 120/150, Loss: 0.0058\n",
            "Epoch 121/150, Loss: 0.0041\n",
            "Epoch 122/150, Loss: 0.0039\n",
            "Epoch 123/150, Loss: 0.0031\n",
            "Epoch 124/150, Loss: 0.0077\n",
            "Epoch 125/150, Loss: 0.0076\n",
            "Epoch 126/150, Loss: 0.0032\n",
            "Epoch 127/150, Loss: 0.0036\n",
            "Epoch 128/150, Loss: 0.0088\n",
            "Epoch 129/150, Loss: 0.0035\n",
            "Epoch 130/150, Loss: 0.0080\n",
            "Epoch 131/150, Loss: 0.0103\n",
            "Epoch 132/150, Loss: 0.0056\n",
            "Epoch 133/150, Loss: 0.0067\n",
            "Epoch 134/150, Loss: 0.0056\n",
            "Epoch 135/150, Loss: 0.0060\n",
            "Epoch 136/150, Loss: 0.0031\n",
            "Epoch 137/150, Loss: 0.0027\n",
            "Epoch 138/150, Loss: 0.0047\n",
            "Epoch 139/150, Loss: 0.0065\n",
            "Epoch 140/150, Loss: 0.0044\n",
            "Epoch 141/150, Loss: 0.0037\n",
            "Epoch 142/150, Loss: 0.0056\n",
            "Epoch 143/150, Loss: 0.0073\n",
            "Epoch 144/150, Loss: 0.0072\n",
            "Epoch 145/150, Loss: 0.0046\n",
            "Epoch 146/150, Loss: 0.0069\n",
            "Epoch 147/150, Loss: 0.0043\n",
            "Epoch 148/150, Loss: 0.0065\n",
            "Epoch 149/150, Loss: 0.0023\n",
            "Epoch 150/150, Loss: 0.0036\n",
            "Iteration 7/10: 113 anomalies detected by GFCN.\n",
            "Iteration 7/10: Number of Nodes after anomaly removal: 413\n",
            "Evaluating model at iteration 7...\n",
            "Iteration 7 - Evaluation Metrics:\n",
            "Accuracy: 0.8954\n",
            "F1 Score: 0.7970\n",
            "Precision: 0.9558\n",
            "Recall: 0.6835\n",
            "Iteration 8/10: 124 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6910\n",
            "Epoch 2/150, Loss: 0.6284\n",
            "Epoch 3/150, Loss: 0.5767\n",
            "Epoch 4/150, Loss: 0.5325\n",
            "Epoch 5/150, Loss: 0.4991\n",
            "Epoch 6/150, Loss: 0.4681\n",
            "Epoch 7/150, Loss: 0.4380\n",
            "Epoch 8/150, Loss: 0.4043\n",
            "Epoch 9/150, Loss: 0.3756\n",
            "Epoch 10/150, Loss: 0.3506\n",
            "Epoch 11/150, Loss: 0.3250\n",
            "Epoch 12/150, Loss: 0.2991\n",
            "Epoch 13/150, Loss: 0.2706\n",
            "Epoch 14/150, Loss: 0.2480\n",
            "Epoch 15/150, Loss: 0.2405\n",
            "Epoch 16/150, Loss: 0.2076\n",
            "Epoch 17/150, Loss: 0.1906\n",
            "Epoch 18/150, Loss: 0.1881\n",
            "Epoch 19/150, Loss: 0.1609\n",
            "Epoch 20/150, Loss: 0.1391\n",
            "Epoch 21/150, Loss: 0.1334\n",
            "Epoch 22/150, Loss: 0.1222\n",
            "Epoch 23/150, Loss: 0.1171\n",
            "Epoch 24/150, Loss: 0.0915\n",
            "Epoch 25/150, Loss: 0.0962\n",
            "Epoch 26/150, Loss: 0.0879\n",
            "Epoch 27/150, Loss: 0.0648\n",
            "Epoch 28/150, Loss: 0.0611\n",
            "Epoch 29/150, Loss: 0.0583\n",
            "Epoch 30/150, Loss: 0.0535\n",
            "Epoch 31/150, Loss: 0.0433\n",
            "Epoch 32/150, Loss: 0.0443\n",
            "Epoch 33/150, Loss: 0.0370\n",
            "Epoch 34/150, Loss: 0.0446\n",
            "Epoch 35/150, Loss: 0.0368\n",
            "Epoch 36/150, Loss: 0.0328\n",
            "Epoch 37/150, Loss: 0.0362\n",
            "Epoch 38/150, Loss: 0.0296\n",
            "Epoch 39/150, Loss: 0.0239\n",
            "Epoch 40/150, Loss: 0.0257\n",
            "Epoch 41/150, Loss: 0.0223\n",
            "Epoch 42/150, Loss: 0.0176\n",
            "Epoch 43/150, Loss: 0.0243\n",
            "Epoch 44/150, Loss: 0.0170\n",
            "Epoch 45/150, Loss: 0.0185\n",
            "Epoch 46/150, Loss: 0.0193\n",
            "Epoch 47/150, Loss: 0.0216\n",
            "Epoch 48/150, Loss: 0.0265\n",
            "Epoch 49/150, Loss: 0.0145\n",
            "Epoch 50/150, Loss: 0.0102\n",
            "Epoch 51/150, Loss: 0.0103\n",
            "Epoch 52/150, Loss: 0.0183\n",
            "Epoch 53/150, Loss: 0.0108\n",
            "Epoch 54/150, Loss: 0.0168\n",
            "Epoch 55/150, Loss: 0.0097\n",
            "Epoch 56/150, Loss: 0.0151\n",
            "Epoch 57/150, Loss: 0.0106\n",
            "Epoch 58/150, Loss: 0.0118\n",
            "Epoch 59/150, Loss: 0.0143\n",
            "Epoch 60/150, Loss: 0.0125\n",
            "Epoch 61/150, Loss: 0.0117\n",
            "Epoch 62/150, Loss: 0.0061\n",
            "Epoch 63/150, Loss: 0.0072\n",
            "Epoch 64/150, Loss: 0.0110\n",
            "Epoch 65/150, Loss: 0.0061\n",
            "Epoch 66/150, Loss: 0.0112\n",
            "Epoch 67/150, Loss: 0.0100\n",
            "Epoch 68/150, Loss: 0.0094\n",
            "Epoch 69/150, Loss: 0.0074\n",
            "Epoch 70/150, Loss: 0.0101\n",
            "Epoch 71/150, Loss: 0.0117\n",
            "Epoch 72/150, Loss: 0.0066\n",
            "Epoch 73/150, Loss: 0.0056\n",
            "Epoch 74/150, Loss: 0.0083\n",
            "Epoch 75/150, Loss: 0.0061\n",
            "Epoch 76/150, Loss: 0.0063\n",
            "Epoch 77/150, Loss: 0.0074\n",
            "Epoch 78/150, Loss: 0.0083\n",
            "Epoch 79/150, Loss: 0.0084\n",
            "Epoch 80/150, Loss: 0.0100\n",
            "Epoch 81/150, Loss: 0.0057\n",
            "Epoch 82/150, Loss: 0.0039\n",
            "Epoch 83/150, Loss: 0.0075\n",
            "Epoch 84/150, Loss: 0.0090\n",
            "Epoch 85/150, Loss: 0.0042\n",
            "Epoch 86/150, Loss: 0.0079\n",
            "Epoch 87/150, Loss: 0.0097\n",
            "Epoch 88/150, Loss: 0.0121\n",
            "Epoch 89/150, Loss: 0.0018\n",
            "Epoch 90/150, Loss: 0.0034\n",
            "Epoch 91/150, Loss: 0.0061\n",
            "Epoch 92/150, Loss: 0.0075\n",
            "Epoch 93/150, Loss: 0.0032\n",
            "Epoch 94/150, Loss: 0.0037\n",
            "Epoch 95/150, Loss: 0.0043\n",
            "Epoch 96/150, Loss: 0.0035\n",
            "Epoch 97/150, Loss: 0.0056\n",
            "Epoch 98/150, Loss: 0.0058\n",
            "Epoch 99/150, Loss: 0.0041\n",
            "Epoch 100/150, Loss: 0.0029\n",
            "Epoch 101/150, Loss: 0.0067\n",
            "Epoch 102/150, Loss: 0.0097\n",
            "Epoch 103/150, Loss: 0.0063\n",
            "Epoch 104/150, Loss: 0.0033\n",
            "Epoch 105/150, Loss: 0.0036\n",
            "Epoch 106/150, Loss: 0.0036\n",
            "Epoch 107/150, Loss: 0.0055\n",
            "Epoch 108/150, Loss: 0.0082\n",
            "Epoch 109/150, Loss: 0.0038\n",
            "Epoch 110/150, Loss: 0.0057\n",
            "Epoch 111/150, Loss: 0.0017\n",
            "Epoch 112/150, Loss: 0.0065\n",
            "Epoch 113/150, Loss: 0.0045\n",
            "Epoch 114/150, Loss: 0.0062\n",
            "Epoch 115/150, Loss: 0.0050\n",
            "Epoch 116/150, Loss: 0.0079\n",
            "Epoch 117/150, Loss: 0.0037\n",
            "Epoch 118/150, Loss: 0.0051\n",
            "Epoch 119/150, Loss: 0.0014\n",
            "Epoch 120/150, Loss: 0.0017\n",
            "Epoch 121/150, Loss: 0.0026\n",
            "Epoch 122/150, Loss: 0.0065\n",
            "Epoch 123/150, Loss: 0.0053\n",
            "Epoch 124/150, Loss: 0.0035\n",
            "Epoch 125/150, Loss: 0.0035\n",
            "Epoch 126/150, Loss: 0.0030\n",
            "Epoch 127/150, Loss: 0.0048\n",
            "Epoch 128/150, Loss: 0.0036\n",
            "Epoch 129/150, Loss: 0.0039\n",
            "Epoch 130/150, Loss: 0.0082\n",
            "Epoch 131/150, Loss: 0.0025\n",
            "Epoch 132/150, Loss: 0.0032\n",
            "Epoch 133/150, Loss: 0.0074\n",
            "Epoch 134/150, Loss: 0.0023\n",
            "Epoch 135/150, Loss: 0.0038\n",
            "Epoch 136/150, Loss: 0.0019\n",
            "Epoch 137/150, Loss: 0.0023\n",
            "Epoch 138/150, Loss: 0.0025\n",
            "Epoch 139/150, Loss: 0.0042\n",
            "Epoch 140/150, Loss: 0.0051\n",
            "Epoch 141/150, Loss: 0.0019\n",
            "Epoch 142/150, Loss: 0.0044\n",
            "Epoch 143/150, Loss: 0.0037\n",
            "Epoch 144/150, Loss: 0.0044\n",
            "Epoch 145/150, Loss: 0.0025\n",
            "Epoch 146/150, Loss: 0.0041\n",
            "Epoch 147/150, Loss: 0.0025\n",
            "Epoch 148/150, Loss: 0.0057\n",
            "Epoch 149/150, Loss: 0.0029\n",
            "Epoch 150/150, Loss: 0.0043\n",
            "Iteration 8/10: 83 anomalies detected by GFCN.\n",
            "Iteration 8/10: Number of Nodes after anomaly removal: 330\n",
            "Evaluating model at iteration 8...\n",
            "Iteration 8 - Evaluation Metrics:\n",
            "Accuracy: 0.8910\n",
            "F1 Score: 0.7826\n",
            "Precision: 0.9759\n",
            "Recall: 0.6532\n",
            "Iteration 9/10: 99 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.7457\n",
            "Epoch 2/150, Loss: 0.6768\n",
            "Epoch 3/150, Loss: 0.6118\n",
            "Epoch 4/150, Loss: 0.5723\n",
            "Epoch 5/150, Loss: 0.5140\n",
            "Epoch 6/150, Loss: 0.4750\n",
            "Epoch 7/150, Loss: 0.4369\n",
            "Epoch 8/150, Loss: 0.4117\n",
            "Epoch 9/150, Loss: 0.3784\n",
            "Epoch 10/150, Loss: 0.3517\n",
            "Epoch 11/150, Loss: 0.3265\n",
            "Epoch 12/150, Loss: 0.3026\n",
            "Epoch 13/150, Loss: 0.2858\n",
            "Epoch 14/150, Loss: 0.2792\n",
            "Epoch 15/150, Loss: 0.2238\n",
            "Epoch 16/150, Loss: 0.2200\n",
            "Epoch 17/150, Loss: 0.1917\n",
            "Epoch 18/150, Loss: 0.1817\n",
            "Epoch 19/150, Loss: 0.1512\n",
            "Epoch 20/150, Loss: 0.1355\n",
            "Epoch 21/150, Loss: 0.1206\n",
            "Epoch 22/150, Loss: 0.1149\n",
            "Epoch 23/150, Loss: 0.0920\n",
            "Epoch 24/150, Loss: 0.0790\n",
            "Epoch 25/150, Loss: 0.0787\n",
            "Epoch 26/150, Loss: 0.0703\n",
            "Epoch 27/150, Loss: 0.0594\n",
            "Epoch 28/150, Loss: 0.0586\n",
            "Epoch 29/150, Loss: 0.0512\n",
            "Epoch 30/150, Loss: 0.0500\n",
            "Epoch 31/150, Loss: 0.0496\n",
            "Epoch 32/150, Loss: 0.0410\n",
            "Epoch 33/150, Loss: 0.0316\n",
            "Epoch 34/150, Loss: 0.0281\n",
            "Epoch 35/150, Loss: 0.0232\n",
            "Epoch 36/150, Loss: 0.0257\n",
            "Epoch 37/150, Loss: 0.0217\n",
            "Epoch 38/150, Loss: 0.0213\n",
            "Epoch 39/150, Loss: 0.0209\n",
            "Epoch 40/150, Loss: 0.0160\n",
            "Epoch 41/150, Loss: 0.0202\n",
            "Epoch 42/150, Loss: 0.0177\n",
            "Epoch 43/150, Loss: 0.0116\n",
            "Epoch 44/150, Loss: 0.0197\n",
            "Epoch 45/150, Loss: 0.0152\n",
            "Epoch 46/150, Loss: 0.0120\n",
            "Epoch 47/150, Loss: 0.0117\n",
            "Epoch 48/150, Loss: 0.0117\n",
            "Epoch 49/150, Loss: 0.0120\n",
            "Epoch 50/150, Loss: 0.0084\n",
            "Epoch 51/150, Loss: 0.0101\n",
            "Epoch 52/150, Loss: 0.0112\n",
            "Epoch 53/150, Loss: 0.0072\n",
            "Epoch 54/150, Loss: 0.0090\n",
            "Epoch 55/150, Loss: 0.0110\n",
            "Epoch 56/150, Loss: 0.0051\n",
            "Epoch 57/150, Loss: 0.0073\n",
            "Epoch 58/150, Loss: 0.0052\n",
            "Epoch 59/150, Loss: 0.0045\n",
            "Epoch 60/150, Loss: 0.0073\n",
            "Epoch 61/150, Loss: 0.0070\n",
            "Epoch 62/150, Loss: 0.0047\n",
            "Epoch 63/150, Loss: 0.0081\n",
            "Epoch 64/150, Loss: 0.0034\n",
            "Epoch 65/150, Loss: 0.0062\n",
            "Epoch 66/150, Loss: 0.0049\n",
            "Epoch 67/150, Loss: 0.0036\n",
            "Epoch 68/150, Loss: 0.0034\n",
            "Epoch 69/150, Loss: 0.0061\n",
            "Epoch 70/150, Loss: 0.0028\n",
            "Epoch 71/150, Loss: 0.0048\n",
            "Epoch 72/150, Loss: 0.0076\n",
            "Epoch 73/150, Loss: 0.0045\n",
            "Epoch 74/150, Loss: 0.0039\n",
            "Epoch 75/150, Loss: 0.0048\n",
            "Epoch 76/150, Loss: 0.0043\n",
            "Epoch 77/150, Loss: 0.0067\n",
            "Epoch 78/150, Loss: 0.0086\n",
            "Epoch 79/150, Loss: 0.0086\n",
            "Epoch 80/150, Loss: 0.0081\n",
            "Epoch 81/150, Loss: 0.0040\n",
            "Epoch 82/150, Loss: 0.0033\n",
            "Epoch 83/150, Loss: 0.0062\n",
            "Epoch 84/150, Loss: 0.0027\n",
            "Epoch 85/150, Loss: 0.0035\n",
            "Epoch 86/150, Loss: 0.0036\n",
            "Epoch 87/150, Loss: 0.0029\n",
            "Epoch 88/150, Loss: 0.0016\n",
            "Epoch 89/150, Loss: 0.0039\n",
            "Epoch 90/150, Loss: 0.0045\n",
            "Epoch 91/150, Loss: 0.0034\n",
            "Epoch 92/150, Loss: 0.0034\n",
            "Epoch 93/150, Loss: 0.0063\n",
            "Epoch 94/150, Loss: 0.0053\n",
            "Epoch 95/150, Loss: 0.0024\n",
            "Epoch 96/150, Loss: 0.0022\n",
            "Epoch 97/150, Loss: 0.0032\n",
            "Epoch 98/150, Loss: 0.0029\n",
            "Epoch 99/150, Loss: 0.0054\n",
            "Epoch 100/150, Loss: 0.0034\n",
            "Epoch 101/150, Loss: 0.0018\n",
            "Epoch 102/150, Loss: 0.0047\n",
            "Epoch 103/150, Loss: 0.0041\n",
            "Epoch 104/150, Loss: 0.0022\n",
            "Epoch 105/150, Loss: 0.0020\n",
            "Epoch 106/150, Loss: 0.0027\n",
            "Epoch 107/150, Loss: 0.0028\n",
            "Epoch 108/150, Loss: 0.0027\n",
            "Epoch 109/150, Loss: 0.0020\n",
            "Epoch 110/150, Loss: 0.0050\n",
            "Epoch 111/150, Loss: 0.0034\n",
            "Epoch 112/150, Loss: 0.0022\n",
            "Epoch 113/150, Loss: 0.0039\n",
            "Epoch 114/150, Loss: 0.0021\n",
            "Epoch 115/150, Loss: 0.0046\n",
            "Epoch 116/150, Loss: 0.0022\n",
            "Epoch 117/150, Loss: 0.0010\n",
            "Epoch 118/150, Loss: 0.0034\n",
            "Epoch 119/150, Loss: 0.0015\n",
            "Epoch 120/150, Loss: 0.0037\n",
            "Epoch 121/150, Loss: 0.0026\n",
            "Epoch 122/150, Loss: 0.0016\n",
            "Epoch 123/150, Loss: 0.0037\n",
            "Epoch 124/150, Loss: 0.0013\n",
            "Epoch 125/150, Loss: 0.0015\n",
            "Epoch 126/150, Loss: 0.0019\n",
            "Epoch 127/150, Loss: 0.0013\n",
            "Epoch 128/150, Loss: 0.0015\n",
            "Epoch 129/150, Loss: 0.0018\n",
            "Epoch 130/150, Loss: 0.0025\n",
            "Epoch 131/150, Loss: 0.0016\n",
            "Epoch 132/150, Loss: 0.0019\n",
            "Epoch 133/150, Loss: 0.0051\n",
            "Epoch 134/150, Loss: 0.0012\n",
            "Epoch 135/150, Loss: 0.0015\n",
            "Epoch 136/150, Loss: 0.0010\n",
            "Epoch 137/150, Loss: 0.0017\n",
            "Epoch 138/150, Loss: 0.0030\n",
            "Epoch 139/150, Loss: 0.0020\n",
            "Epoch 140/150, Loss: 0.0020\n",
            "Epoch 141/150, Loss: 0.0032\n",
            "Epoch 142/150, Loss: 0.0015\n",
            "Epoch 143/150, Loss: 0.0022\n",
            "Epoch 144/150, Loss: 0.0010\n",
            "Epoch 145/150, Loss: 0.0014\n",
            "Epoch 146/150, Loss: 0.0024\n",
            "Epoch 147/150, Loss: 0.0011\n",
            "Epoch 148/150, Loss: 0.0012\n",
            "Epoch 149/150, Loss: 0.0039\n",
            "Epoch 150/150, Loss: 0.0012\n",
            "Iteration 9/10: 68 anomalies detected by GFCN.\n",
            "Iteration 9/10: Number of Nodes after anomaly removal: 262\n",
            "Evaluating model at iteration 9...\n",
            "Iteration 9 - Evaluation Metrics:\n",
            "Accuracy: 0.8939\n",
            "F1 Score: 0.7904\n",
            "Precision: 0.9706\n",
            "Recall: 0.6667\n",
            "Iteration 10/10: 79 anomalies detected by Isolation Forest.\n",
            "Epoch 1/150, Loss: 0.6788\n",
            "Epoch 2/150, Loss: 0.6249\n",
            "Epoch 3/150, Loss: 0.5741\n",
            "Epoch 4/150, Loss: 0.5217\n",
            "Epoch 5/150, Loss: 0.4788\n",
            "Epoch 6/150, Loss: 0.4439\n",
            "Epoch 7/150, Loss: 0.4137\n",
            "Epoch 8/150, Loss: 0.3774\n",
            "Epoch 9/150, Loss: 0.3509\n",
            "Epoch 10/150, Loss: 0.3497\n",
            "Epoch 11/150, Loss: 0.3136\n",
            "Epoch 12/150, Loss: 0.2885\n",
            "Epoch 13/150, Loss: 0.2724\n",
            "Epoch 14/150, Loss: 0.2513\n",
            "Epoch 15/150, Loss: 0.2253\n",
            "Epoch 16/150, Loss: 0.1978\n",
            "Epoch 17/150, Loss: 0.1809\n",
            "Epoch 18/150, Loss: 0.1630\n",
            "Epoch 19/150, Loss: 0.1442\n",
            "Epoch 20/150, Loss: 0.1265\n",
            "Epoch 21/150, Loss: 0.1260\n",
            "Epoch 22/150, Loss: 0.1031\n",
            "Epoch 23/150, Loss: 0.0888\n",
            "Epoch 24/150, Loss: 0.0964\n",
            "Epoch 25/150, Loss: 0.0784\n",
            "Epoch 26/150, Loss: 0.0665\n",
            "Epoch 27/150, Loss: 0.0568\n",
            "Epoch 28/150, Loss: 0.0538\n",
            "Epoch 29/150, Loss: 0.0487\n",
            "Epoch 30/150, Loss: 0.0410\n",
            "Epoch 31/150, Loss: 0.0446\n",
            "Epoch 32/150, Loss: 0.0278\n",
            "Epoch 33/150, Loss: 0.0354\n",
            "Epoch 34/150, Loss: 0.0329\n",
            "Epoch 35/150, Loss: 0.0275\n",
            "Epoch 36/150, Loss: 0.0195\n",
            "Epoch 37/150, Loss: 0.0257\n",
            "Epoch 38/150, Loss: 0.0190\n",
            "Epoch 39/150, Loss: 0.0158\n",
            "Epoch 40/150, Loss: 0.0129\n",
            "Epoch 41/150, Loss: 0.0128\n",
            "Epoch 42/150, Loss: 0.0108\n",
            "Epoch 43/150, Loss: 0.0131\n",
            "Epoch 44/150, Loss: 0.0085\n",
            "Epoch 45/150, Loss: 0.0075\n",
            "Epoch 46/150, Loss: 0.0093\n",
            "Epoch 47/150, Loss: 0.0121\n",
            "Epoch 48/150, Loss: 0.0084\n",
            "Epoch 49/150, Loss: 0.0086\n",
            "Epoch 50/150, Loss: 0.0192\n",
            "Epoch 51/150, Loss: 0.0063\n",
            "Epoch 52/150, Loss: 0.0086\n",
            "Epoch 53/150, Loss: 0.0149\n",
            "Epoch 54/150, Loss: 0.0103\n",
            "Epoch 55/150, Loss: 0.0126\n",
            "Epoch 56/150, Loss: 0.0073\n",
            "Epoch 57/150, Loss: 0.0112\n",
            "Epoch 58/150, Loss: 0.0096\n",
            "Epoch 59/150, Loss: 0.0069\n",
            "Epoch 60/150, Loss: 0.0081\n",
            "Epoch 61/150, Loss: 0.0110\n",
            "Epoch 62/150, Loss: 0.0103\n",
            "Epoch 63/150, Loss: 0.0062\n",
            "Epoch 64/150, Loss: 0.0074\n",
            "Epoch 65/150, Loss: 0.0073\n",
            "Epoch 66/150, Loss: 0.0047\n",
            "Epoch 67/150, Loss: 0.0046\n",
            "Epoch 68/150, Loss: 0.0095\n",
            "Epoch 69/150, Loss: 0.0044\n",
            "Epoch 70/150, Loss: 0.0028\n",
            "Epoch 71/150, Loss: 0.0042\n",
            "Epoch 72/150, Loss: 0.0051\n",
            "Epoch 73/150, Loss: 0.0062\n",
            "Epoch 74/150, Loss: 0.0049\n",
            "Epoch 75/150, Loss: 0.0034\n",
            "Epoch 76/150, Loss: 0.0060\n",
            "Epoch 77/150, Loss: 0.0031\n",
            "Epoch 78/150, Loss: 0.0057\n",
            "Epoch 79/150, Loss: 0.0075\n",
            "Epoch 80/150, Loss: 0.0069\n",
            "Epoch 81/150, Loss: 0.0043\n",
            "Epoch 82/150, Loss: 0.0045\n",
            "Epoch 83/150, Loss: 0.0043\n",
            "Epoch 84/150, Loss: 0.0074\n",
            "Epoch 85/150, Loss: 0.0024\n",
            "Epoch 86/150, Loss: 0.0038\n",
            "Epoch 87/150, Loss: 0.0022\n",
            "Epoch 88/150, Loss: 0.0032\n",
            "Epoch 89/150, Loss: 0.0031\n",
            "Epoch 90/150, Loss: 0.0053\n",
            "Epoch 91/150, Loss: 0.0017\n",
            "Epoch 92/150, Loss: 0.0037\n",
            "Epoch 93/150, Loss: 0.0023\n",
            "Epoch 94/150, Loss: 0.0031\n",
            "Epoch 95/150, Loss: 0.0019\n",
            "Epoch 96/150, Loss: 0.0036\n",
            "Epoch 97/150, Loss: 0.0021\n",
            "Epoch 98/150, Loss: 0.0045\n",
            "Epoch 99/150, Loss: 0.0019\n",
            "Epoch 100/150, Loss: 0.0031\n",
            "Epoch 101/150, Loss: 0.0029\n",
            "Epoch 102/150, Loss: 0.0046\n",
            "Epoch 103/150, Loss: 0.0064\n",
            "Epoch 104/150, Loss: 0.0035\n",
            "Epoch 105/150, Loss: 0.0025\n",
            "Epoch 106/150, Loss: 0.0023\n",
            "Epoch 107/150, Loss: 0.0026\n",
            "Epoch 108/150, Loss: 0.0027\n",
            "Epoch 109/150, Loss: 0.0073\n",
            "Epoch 110/150, Loss: 0.0015\n",
            "Epoch 111/150, Loss: 0.0020\n",
            "Epoch 112/150, Loss: 0.0015\n",
            "Epoch 113/150, Loss: 0.0091\n",
            "Epoch 114/150, Loss: 0.0026\n",
            "Epoch 115/150, Loss: 0.0013\n",
            "Epoch 116/150, Loss: 0.0027\n",
            "Epoch 117/150, Loss: 0.0018\n",
            "Epoch 118/150, Loss: 0.0024\n",
            "Epoch 119/150, Loss: 0.0019\n",
            "Epoch 120/150, Loss: 0.0023\n",
            "Epoch 121/150, Loss: 0.0038\n",
            "Epoch 122/150, Loss: 0.0036\n",
            "Epoch 123/150, Loss: 0.0044\n",
            "Epoch 124/150, Loss: 0.0024\n",
            "Epoch 125/150, Loss: 0.0039\n",
            "Epoch 126/150, Loss: 0.0008\n",
            "Epoch 127/150, Loss: 0.0019\n",
            "Epoch 128/150, Loss: 0.0014\n",
            "Epoch 129/150, Loss: 0.0014\n",
            "Epoch 130/150, Loss: 0.0117\n",
            "Epoch 131/150, Loss: 0.0012\n",
            "Epoch 132/150, Loss: 0.0051\n",
            "Epoch 133/150, Loss: 0.0025\n",
            "Epoch 134/150, Loss: 0.0029\n",
            "Epoch 135/150, Loss: 0.0014\n",
            "Epoch 136/150, Loss: 0.0024\n",
            "Epoch 137/150, Loss: 0.0008\n",
            "Epoch 138/150, Loss: 0.0020\n",
            "Epoch 139/150, Loss: 0.0018\n",
            "Epoch 140/150, Loss: 0.0015\n",
            "Epoch 141/150, Loss: 0.0027\n",
            "Epoch 142/150, Loss: 0.0017\n",
            "Epoch 143/150, Loss: 0.0058\n",
            "Epoch 144/150, Loss: 0.0017\n",
            "Epoch 145/150, Loss: 0.0022\n",
            "Epoch 146/150, Loss: 0.0017\n",
            "Epoch 147/150, Loss: 0.0014\n",
            "Epoch 148/150, Loss: 0.0030\n",
            "Epoch 149/150, Loss: 0.0034\n",
            "Epoch 150/150, Loss: 0.0007\n",
            "Iteration 10/10: 51 anomalies detected by GFCN.\n",
            "Iteration 10/10: Number of Nodes after anomaly removal: 211\n",
            "Evaluating model at iteration 10...\n",
            "Iteration 10 - Evaluation Metrics:\n",
            "Accuracy: 0.8855\n",
            "F1 Score: 0.7692\n",
            "Precision: 0.9804\n",
            "Recall: 0.6329\n",
            "Plot saved to /content/drive/MyDrive/Final Project - Boris & Omri/Experiments/CiteSeer/evaluation_scores_plot.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed nodes saved to /content/drive/MyDrive/Final Project - Boris & Omri/Experiments/CiteSeer/removed_nodes_per_iteration.csv\n",
            "\n",
            "Final Evaluation Scores:\n",
            "Iteration 1 - Accuracy: 0.9684, F1 Score: 0.9473, Precision: 0.9487, Recall: 0.9459\n",
            "Iteration 2 - Accuracy: 0.9451, F1 Score: 0.9082, Precision: 0.9121, Recall: 0.9043\n",
            "Iteration 3 - Accuracy: 0.9420, F1 Score: 0.8988, Precision: 0.9441, Recall: 0.8577\n",
            "Iteration 4 - Accuracy: 0.9278, F1 Score: 0.8673, Precision: 0.9656, Recall: 0.7871\n",
            "Iteration 5 - Accuracy: 0.9122, F1 Score: 0.8378, Precision: 0.9401, Recall: 0.7556\n",
            "Iteration 6 - Accuracy: 0.8975, F1 Score: 0.8066, Precision: 0.9299, Recall: 0.7122\n",
            "Iteration 7 - Accuracy: 0.8954, F1 Score: 0.7970, Precision: 0.9558, Recall: 0.6835\n",
            "Iteration 8 - Accuracy: 0.8910, F1 Score: 0.7826, Precision: 0.9759, Recall: 0.6532\n",
            "Iteration 9 - Accuracy: 0.8939, F1 Score: 0.7904, Precision: 0.9706, Recall: 0.6667\n",
            "Iteration 10 - Accuracy: 0.8855, F1 Score: 0.7692, Precision: 0.9804, Recall: 0.6329\n"
          ]
        }
      ],
      "source": [
        "#print(f\"Initial Number of Nodes: {cora_data.num_nodes}\")\n",
        "#node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_cora_from_drive(),node_embeddings, 10)\n",
        "#node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_pubmed_from_drive(),node_embeddings, 10)\n",
        "node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_citeseer_from_drive(),node_embeddings, 10)\n",
        "#node_embeddings_final, removed_nodes=iterative_anomaly_detection(load_snap_from_drive(),node_embeddings, 10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}